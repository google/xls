{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#xls-accelerated-hw-synthesis","title":"XLS: Accelerated HW Synthesis","text":""},{"location":"#what-is-xls","title":"What is XLS?","text":"<p>XLS implements a High Level Synthesis (HLS) toolchain which produces synthesizable designs (Verilog and SystemVerilog) from flexible, high-level descriptions of functionality. It is fully Open Source: Apache 2 licensed and developed via GitHub.</p> <p>XLS (Accelerated HW Synthesis) aims to be the Software Development Kit (SDK) for the End of Moore's Law (EoML) era. In this \"age of specialization\", software and hardware engineers must do more co-design across their domain boundaries -- collaborate on shared artifacts, understand each other's cost models, and share tooling/methodology. XLS attempts to leverage automation, software engineers, and machine cycles to accelerate this overall process.</p> <p>In effect, XLS enables the rapid development of hardware IP that also runs as efficient host software via \"software style\" methodology. A single XLS source program runs at native speeds for use in host software or a simulator, but that source can also be used to generate hardware block output -- the XLS tools' correctness ensures (and provides tools to help formally verify) that they are functionally identical.</p> <p>XLS is used inside of Google for generating feed-forward pipelines from \"building block\" routines / libraries that can be easily retargeted, reused, and composed in a latency-insensitive manner.</p> <p>XLS also supports concurrent processes, in Communicating Sequential Processes (CSP) style, that allow pipelines to communicate with each other and induct over time. This feature is still under active development but today supports base use cases.</p> <p>XLS is still experimental, undergoing rapid development, and not an officially supported Google product. Expect bugs and sharp edges. Please help by trying it out, running through some tutorials, reporting bugs, and letting us know what you think!</p>"},{"location":"#building-from-source","title":"Building From Source","text":"<p>Currently, XLS must be built from source using the Bazel build system.</p> <p>Note: Binary distributions of the XLS library are not currently available, but we hope to enable them via continuous integration, see this issue.</p> <p>The following instructions are for the Ubuntu 20.04 (Focal Fossa) and Ubuntu 22.04 (Jammy Jellyfish) Linux distributions.</p> <p>We start by assuming Bazel has been installed. On an average 8-core VM, a full initial build (including the C++ frontend) may take up to 6 hours. A build without the C++ frontend may take about 2 hours. Please see the two corresponding command lines below:</p> <pre><code>~$ git clone https://github.com/google/xls.git\n~$ cd xls\n\n~/xls$ # Follow the bazel install instructions:\n~/xls$ # https://bazel.build/install/ubuntu\n~/xls$ # Afterwards we observe:\n~/xls$ bazel --version\nbazel 5.2.0\n\n~/xls$ # Note we're going to tell Ubuntu that `/usr/bin/env python` is actually python3\n~/xls$ # here, since that is not the case by default on Ubuntu 20.04.\n~/xls$ # This is important. Without this step, you may experience cryptic error messages:\n~/xls$ sudo apt install python3-distutils python3-dev libtinfo5 python-is-python3\n\n~/xls$ # Now build/test in optimized build mode.\n~/xls$ # If you don't plan on using the C++ frontend, which is not needed to get started,\n~/xls$ # use this command line:\n~/xls$ bazel test -c opt -- //xls/... -//xls/contrib/xlscc/...\n\n~/xls$ # To build everything, including the C++ frontend:\n~/xls$ bazel test -c opt -- //xls/...\n</code></pre> <p>Reference build/test environment setups are also provided via <code>Dockerfile</code>s:</p> <pre><code>~$ git clone https://github.com/google/xls.git\n~$ cd xls\n\n~/xls$ # Several Dockerfiles are available to choose from:\n~/xls$ docker build . -f Dockerfile-ubuntu-20.04 # Performs optimized build and test.\n~/xls$ docker build . -f Dockerfile-ubuntu-20.10\n~/xls$ docker build . -f Dockerfile-ubuntu-22.04\n</code></pre>"},{"location":"#stack-diagram-and-project-layout","title":"Stack Diagram and Project Layout","text":"<p>Navigating a new code base can be daunting; the following description provides a high-level view of the important directories and their intended organization / purpose, and correspond to the components in this XLS stack diagram:</p> <ul> <li><code>dependency_support</code>:   Configuration files that load, build, and expose Bazel targets for external   dependencies of XLS.</li> <li><code>docs</code>: Generated documentation   served via GitHub pages:   https://google.github.io/xls/</li> <li><code>docs_src</code>: Markdown file   sources, rendered to <code>docs</code> via   mkdocs.</li> <li> <p><code>xls</code>: Project-named   subdirectory within the repository, in common Bazel-project style.</p> <ul> <li><code>build</code>: Build macros   that create XLS artifacts; e.g. convert DSL to IR, create test targets for   DSL code, etc.</li> <li><code>codegen</code>: Verilog   AST (VAST) support to generate Verilog/SystemVerilog operations and FSMs.   VAST is built up by components we call generators (e.g.   PipelineGenerator, SequentialGenerator for FSMs) in the translation from XLS   IR.</li> <li><code>common</code>: \"base\"   functionality that layers on top of standard library usage. Generally we use   Abseil versions of base constructs wherever possible.</li> <li><code>contrib/xlscc</code>:   Experimental C++ syntax support that targets XLS IR (alternative path to   DSLX) developed by a sister team at Google, sharing the same open source /   testing flow as the rest of the XLS project. May be of particular interest   for teams with existing C++ HLS code bases.</li> <li><code>data_structures</code>:   Generic data structures used in XLS that augment standard libraries; e.g.   BDDs, union find, min cut, etc.</li> <li><code>delay_model</code>:   Functionality to characterize, describe, and interpolate data delay for   XLS IR operations on a target backend process. Already-characterized   descriptions are placed in <code>xls/delay_model/models</code> and can be referred to via   command line flags.</li> <li><code>dslx</code>: A DSL (called   \"DSLX\") that mimics Rust, while being an immutable expression-language   dataflow DSL with hardware-oriented features; e.g.  arbitrary bitwidths,   entirely fixed size objects, fully analyzeable call graph. XLS team has found   dataflow DSLs are a good fit to describe hardware as compared to languages   designed assume von Neumann style computation.</li> <li><code>fuzzer</code>: A   whole-stack multiprocess fuzzer that generates programs at the DSL level and   cross-compares different execution engines (DSL interpreter, IR interpreter,   IR JIT, code-generated-Verilog simulator). Designed so that it can easily be   run on different nodes in a cluster simultaneously and accumulate shared   findings.</li> <li><code>examples</code>: Example   computations that are tested and executable through the XLS stack.</li> <li><code>experimental</code>:   Artifacts captured from experimental explorations.</li> <li><code>interpreter</code>:   Interpreter for XLS IR - useful for debugging and exploration. For cases   needing throughput, consider using the JIT (below).</li> <li><code>ir</code>:   XLS IR definition, text parser/formatter, and facilities for abstract   evaluation.</li> <li><code>jit</code>:   LLVM-based JIT for XLS IR. Enables native-speed execution of DSLX and XLS IR   programs.</li> <li><code>modules</code>:   Hardware building block DSLX \"libraries\" (outside the DSLX standard library)   that may be easily reused or instantiated in a broader design.</li> <li><code>netlist</code>: Libraries   that parse/analyze/interpret netlist-level descriptions, as are   generally given in simple structural Verilog with an associated cell library.</li> <li><code>passes</code>: Passes that   run on the XLS IR as part of optimization, before scheduling / code   generation.</li> <li><code>scheduling</code>:   Scheduling algorithms, determine when operations execute (e.g. which   pipeline stage) in a clocked design.</li> <li><code>simulation</code>:   Code that wraps Verilog simulators and generates Verilog testbenches for XLS   computations. iverilog is   currently used to simulate as it supports non-synthesizable testbench   constructs.</li> <li><code>solvers</code>:   Converters from XLS IR into SMT solver input, such that formal proofs can be   run on XLS computations; e.g. Logical Equalence Checks between XLS IR and a   netlist description. Z3 is used as the   solver engine.</li> <li><code>synthesis</code>:   Interface that wraps backend synthesis flows, such that tools can be   retargeted e.g. between ASIC and FPGA flows.</li> <li><code>tests</code>:   Integration tests that span various top-level components of the XLS project.</li> <li><code>tools</code>:   Many tools that work with the XLS   system and its libraries in a decomposed way via command line interfaces.</li> <li><code>uncore_rtl</code>:   Helper RTL that interfaces XLS-generated blocks with device top-level for e.g.   FPGA experiments.</li> <li><code>visualization</code>:   Visualization tools to inspect the XLS compiler/system interactively. See   IR visualization.</li> </ul> </li> </ul>"},{"location":"#community","title":"Community","text":"<p>Discussions about XLS - development, debugging, usage, and anything else - should go to the xls-dev mailing list.</p>"},{"location":"#contributors","title":"Contributors","text":"<p>The following are contributors to the XLS project, see our contributing documentation and good first issues!</p> <ul> <li>Albert Magyar</li> <li>Amin Kalantar</li> <li>Balint Christian</li> <li>Blaok</li> <li>Brandon Jiang</li> <li>Brian Searls</li> <li>Chen-hao Chang</li> <li>Chris Drake</li> <li>Chris Leary</li> <li>Dan Killebrew</li> <li>Derek Lockhart</li> <li>Eric Astor</li> <li>Ethan Mahintorabi</li> <li>Felix Zhu</li> <li>Georges Rotival</li> <li>Hans Montero</li> <li>Iliyan Malchev</li> <li>Johan Euphrosine</li> <li>Jonathan Bailey</li> <li>Josh Varga</li> <li>Julian Viera</li> <li>Kevin Harlley</li> <li>Leonardo Romor</li> <li>Manav Kohli</li> <li>Mark Heffernan</li> <li>Paul Rigge</li> <li>Per Gr\u00f6n</li> <li>Ravi Nanavati</li> <li>Rebecca Chen (Pytype)</li> <li>Remy Goldschmidt</li> <li>Robert Hundt</li> <li>Rob Springer</li> <li>Sameer Agarwal</li> <li>Sean Purser-Haskell</li> <li>Ted Hong</li> <li>Ted Xie</li> <li>Vincent Mirian</li> </ul>"},{"location":"adding_ir_operation/","title":"Adding a new IR operation","text":"<p>XLS has about 60 different opcodes and periodically new ones are added to extend functionality or improve the expressiveness of the IR. XLS has many different components and adding a new opcode involves changes to numerous places in the code. These changes, some of which are optional, are described below:</p> <ol> <li> <p>Add operation to     op_specification.py</p> <p>Opcodes and IR node classes are defined in the file <code>op_specification.py</code>.   This Python code generates the C++ header and source files which define   opcodes (<code>op.h</code> and <code>op.cc</code>) and the IR node type hierarchy (<code>nodes.h</code> and   <code>nodes.cc</code>). Every opcode has an associated node subclass derived from the   <code>xls::Node</code> base class. Some opcodes such as <code>Op::kArray</code> have their own   class (<code>Array</code>) because of the unique structure of the operation. Other   opcodes such as the logical operations (<code>Op::kAnd</code>, <code>Op::kOr</code>, etc) share a   common base class (<code>BinOp</code>).</p> <p>The first step to adding a new operations is to add an opcode, and   potentially a new Node class, in <code>op_specification.py</code>. After adding the   opcode numerous files will fail to build because switch statements over the   set of opcodes will no longer be exhaustive. Add the necessary cases to each   switch statement. The exact code in each case will, of course, be   operation-specific. Initially the implementation might return an   <code>absl::UnimplementedError</code> status until later changes add proper support for   the new operation.</p> <p>As part of this change the new operations needs to be added to the DFS   visitor class <code>DfsVisitor</code> by adding a handler method. This class is used   throughout XLS to traverse the IR. This will also adding an implementation   of this new method to many of the subclasses derived from <code>DfsVisitor</code>.</p> <p>(Code example)</p> </li> <li> <p>IR Verifier</p> <p>The IR verifier checks numerous invariants about the IR including   operation-specific properties such as the number and type of operands. Add   an additional handler method for the new operand and add appropriate   operation-specific checks.</p> <p>(Code example)</p> </li> <li> <p>IR Semantics document</p> <p>Describe the semantics and syntax of the new operation in the IR semantics   document.</p> <p>(Code example)</p> </li> <li> <p>Function builder</p> <p>The function builder is the primary API for constructing IR. If appropriate,   add a method to the <code>BuilderBase</code> class which adds an IR node of the new   type to a function.</p> <p>(Code example)</p> </li> <li> <p>IR Parser</p> <p>Add support for parsing of the new operation. The parser tests typically   send a snippet of IR with the operation through the parser and text   serialization and verifies that the output matches the original. Supporting   the new operation may require modifying the <code>xls::Node::ToString</code> method to   emit any special fields required by the operation.</p> <p>(Code example)</p> </li> <li> <p>IR Interpreter</p> <p>The IR interpreter has C++ implementations of all of the operations.   Implement the new operation and add tests.</p> <p>(Code example)</p> </li> <li> <p>IR Matcher</p> <p>The IR matcher is used in tests to enable easy matching of IR expressions.   For example, the following tests that the return value of a function is the   parameter <code>x</code> plus the parameter <code>y</code>:</p> <pre><code>EXPECT_THAT(f-&gt;return_value(), m::Add(m::Param(\"x\", m::Param(\"y\")));\n</code></pre> <p>If the new operation has no named attributed, IR matcher support is   typically a single line using the macro <code>NODE_MATCHER</code>. Otherwise, a custom   matcher should be added to enable matching the attribute as well.</p> <p>(Code example)</p> </li> <li> <p>LLVM JIT</p> <p>The LLVM JIT enables fast simulation of the XLS IR. The JIT constructs LLVM   IR for each XLS operation which is then optimized by LLVM and runs natively   on the host. Implement the new operation in the <code>FunctionBuilderVisitor</code>   class.</p> <p>(Code example)</p> </li> <li> <p>Code generation</p> <p>In XLS \"code generation\" refers to the generation of (System)Verilog from   XLS IR. If the operation can be emitted as a single Verilog expression, then   likely support for the new operation can be added to <code>node_expressions.h</code>,   otherwise if the implementation requires multiple statements then support is   added to <code>module_builder.h</code>.</p> <p>(Code example)</p> </li> <li> <p>Abstract evaluator</p> <p>The abstract evaluator enables evaluation of the XLS IR using different   evaluation systems than Boolean algebra. Users define the semantics of   simple logical operations such as and, or, and not. Then, the abstract   evaluator interprets an IR function using these rules. One example use case   is ternary logic which uses three logic values (true, false, and unknown)   rather than two (true and false) Ternary evaluation is used by the optimizer   to discover statically known bits in the IR graph. The abstract evaluator   can also be used for translation of the IR to other representations. For   example, IR is translated to the Z3 solver representation for formal   verification using the abstract evaluator.</p> <p>If appropriate, the operation should be implemented in   <code>AbstractNodeEvaluator</code> by providing an implementation which decomposes the   operation into fundamental logical operations.</p> <p>(Code example)</p> </li> <li> <p>Z3 solver</p> <p>The Z3 solver is used for theorem proving and logical equivalence checking   between the IR in different stages of compilation and the netlist. To enable   this functionality for the new operation, add a lowering of the operation to   Z3's internal representation.</p> <p>(Code example)</p> </li> <li> <p>Delay model</p> <p>In order to generate efficient circuits which meet timing requirement, XLS   models the delay (in picoseconds) of each operation for different process   technology nodes. This model is constructed by characterizing the process   node using an EDA tool to synthesize the circuit and estimate delay.   Typically, a new operation will need to be characterized by running numerous   permutations of the operation (e.g., with different bit widths) through a   synthesis flow, extracting delay, and building a delay model.</p> <p>(Code example)</p> </li> <li> <p>DSLX frontend</p> <p>Most ops are used by the DSLX frontend in the lowering of DSLX to IR. The   operation may be exposed directly as a builtin (or other operation) or used   in the lowering of other AST nodes. In any case, some changes to the DSLX   frontend will likely be necessary.</p> <p>(Code example)</p> </li> <li> <p>Fuzzer</p> <p>The fuzzer generates random DSLX functions and random inputs to check and   compare different parts of XLS, for example checking that un-optimized and   optimized IR give the same outputs when interpreted. If there is an   operation in DSLX that maps nicely onto the newly added operation, the   fuzzer can be modified to generate functions with DSLX that exercise the   new operation. This is done by adding a handler to <code>AstGenerator</code>. See   here for   more details on how the fuzzer works and how to run it.</p> <p>(Code example)</p> </li> <li> <p>Operation-specific optimizations</p> <p>Typically, a new operation provides optimization opportunities unique to the   node. The details, of course, will be vary for different operations.   However, typically these are at least several easy optimizations which can   be implemented.</p> </li> </ol>"},{"location":"bazel_rules_macros/","title":"Bazel Rules And Macros","text":""},{"location":"bazel_rules_macros/#bazel-rules-and-macros","title":"Bazel Rules And Macros","text":""},{"location":"bazel_rules_macros/#check_sha256sum_frozen","title":"check_sha256sum_frozen","text":"<pre>\ncheck_sha256sum_frozen(name, frozen_file, sha256sum, src)\n</pre> <p>Produces a frozen file if the sha256sum checksum of a source file matches a user-defined checksum.</p> <p>As projects cut releases or freeze, it's important to know that generated (e.g. Verilog) code is never changing without having to actually check in the generated artifact. This rule performs a checksum of a generated file as an integrity check. Users might use this rule to help enable confidence that there is neither:</p> <ul> <li>non-determinism in the toolchain, nor</li> <li>an accidental dependence on a non-released toolchain (e.g. an     accidental dependence on top-of-tree, where the toolchain is     constantly changing)</li> </ul> <p>Say there was a codegen rule producing <code>my_output.v</code>, a user might instantiate something like:</p> <pre><code>check_sha256sum_frozen(\n    name = \"my_output_checksum\",\n    src = \":my_output.v\",\n    sha256sum = \"d1bc8d3ba4afc7e109612cb73acbdddac052c93025aa1f82942edabb7deb82a1\",\n    frozen_file = \"my_output.frozen.x\",\n)\n</code></pre> <p>... and then take a dependency on <code>my_output.frozen.v</code> in the surrounding project, knowing that it had been checksum-verified.</p> <p>Taking a dependence on <code>my_output.v</code> directly may also be ok if the <code>:my_output_checksum</code> target is also built (e.g. via the same wildcard build request), but taking a dependence on the output <code>.frozen.v</code> file ensures that the checking is an integral part of the downstream build-artifact-creation process.</p> <p>At its core, this rule ensure that the contents of a file does not change by verifying that it matches a given checksum. Typically, this rule is used to control the build process. The rule serves as a trigger on rules depending on its output (the frozen file). When the validation of the sha256sum succeed, rules depending on the frozen file are built/executed. When the validation of the sha256sum fails, rules depending on the frozen file are not built/executed.</p> <p>In the example below, when the validation of the sha256sum for target 'generated_file_sha256sum_frozen' succeeds, target 'generated_file_dslx' is built. However, when the validation of the sha256sum for target 'generated_file_sha256sum_frozen' fails, target 'generated_file_dslx' is not built.</p> <p>Examples:</p> <ol> <li>A simple example.<pre><code>check_sha256sum_frozen(\n    name = \"generated_file_sha256sum_frozen\",\n    src = \":generated_file.x\",\n    sha256sum = \"6522799f7b64dbbb2a31eb2862052b8988e78821d8b61fff7f508237a9d9f01d\",\n    frozen_file = \"generated_file.frozen.x\",\n)\n\ndslx_library(\n    name = \"generated_file_dslx\",\n    src = \":generated_file.frozen.x\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required frozen_file The frozen output file. Label required sha256sum The sha256sum of the source file. String required src The source file. Label required <p></p>"},{"location":"bazel_rules_macros/#check_sha256sum_test","title":"check_sha256sum_test","text":"<pre>\ncheck_sha256sum_test(name, sha256sum, src)\n</pre> <p>Validates the sha256sum checksum of a source file with a user-defined checksum.</p> <p>This rule is typically used to ensure that the contents of a file is unchanged.</p> <p>Examples:</p> <ol> <li>A simple example.<pre><code>check_sha256sum_test(\n    name = \"generated_file_sha256sum_test\",\n    src = \":generated_file.x\",\n    sha256sum = \"6522799f7b64dbbb2a31eb2862052b8988e78821d8b61fff7f508237a9d9f01d\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required sha256sum The sha256sum of the source file. String required src The source file. Label required <p></p>"},{"location":"bazel_rules_macros/#proto_data","title":"proto_data","text":"<pre>\nproto_data(name, protobin_file, src)\n</pre> <p>Converts a proto text with a xlscc.HLSBlock message to a proto binary.</p> <p>This rules is used in conjunction with the (e.g. xls_cc_ir and xls_cc_verilog) rules and xls_cc_* (e.g. xls_cc_ir_macro and xls_cc_verilog_macro) macros.</p> <p>Examples:</p> <ol> <li>A simple example.<pre><code>proto_data(\n    name = \"packet_selector_block_pb\",\n    src = \"packet_selector.textproto\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required protobin_file The name of the output file to write binary proto to. If not specified, the target name of the bazel rule followed by an .protobin extension is used. Label optional src The source file. Label required <p></p>"},{"location":"bazel_rules_macros/#xls_benchmark_ir","title":"xls_benchmark_ir","text":"<pre>\nxls_benchmark_ir(name, benchmark_ir_args, src, top)\n</pre> <p>Executes the benchmark tool on an IR file.</p> <p>Examples:</p> <ol> <li> <p>A file as the source.</p> <pre><code>xls_benchmark_ir(\n    name = \"a_benchmark\",\n    src = \"a.ir\",\n)\n</code></pre> </li> <li> <p>An xls_ir_opt_ir target as the source.</p> <pre><code>xls_ir_opt_ir(\n    name = \"a_opt_ir\",\n    src = \"a.ir\",\n)\n\n\nxls_benchmark_ir(\n    name = \"a_benchmark\",\n    src = \":a_opt_ir\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required benchmark_ir_args Arguments of the benchmark IR tool. For details on the arguments, refer to the benchmark_main application at //xls/tools/benchmark_main.cc. Dictionary: String -&gt; String optional {} src The IR source file for the rule. A single source file must be provided. The file must have a '.ir' extension. Label required top The (mangled) name of the entry point. See get_mangled_ir_symbol. Defines the 'top' argument of the IR tool/application. String optional \"\" <p></p>"},{"location":"bazel_rules_macros/#xls_benchmark_verilog","title":"xls_benchmark_verilog","text":"<pre>\nxls_benchmark_verilog(name, verilog_target)\n</pre> <p>Computes and prints various metrics about a Verilog target.</p> <p>Example:     <pre><code>xls_benchmark_verilog(\n    name = \"a_benchmark\",\n    verilog_target = \"a_verilog_target\",\n)\n</code></pre></p> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required verilog_target The verilog target to benchmark. Label optional None <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_library","title":"xls_dslx_library","text":"<pre>\nxls_dslx_library(name, deps, srcs, warnings_as_errors)\n</pre> <p>A build rule that parses and type checks DSLX source files.</p> <p>Examples:</p> <ol> <li> <p>A collection of DSLX source files.</p> <pre><code>xls_dslx_library(\n    name = \"files_123_dslx\",\n    srcs = [\n        \"file_1.x\",\n        \"file_2.x\",\n        \"file_3.x\",\n    ],\n)\n</code></pre> </li> <li> <p>Dependency on other xls_dslx_library targets.</p> <pre><code>xls_dslx_library(\n    name = \"a_dslx\",\n    srcs = [\"a.x\"],\n)\n\n# Depends on target a_dslx.\nxls_dslx_library(\n    name = \"b_dslx\",\n    srcs = [\"b.x\"],\n    deps = [\":a_dslx\"],\n)\n\n# Depends on target a_dslx.\nxls_dslx_library(\n    name = \"c_dslx\",\n    srcs = [\"c.x\"],\n    deps = [\":a_dslx\"],\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required deps Dependency targets for the rule. List of labels optional [] srcs Source files for the rule. Files must have a '.x' extension. List of labels optional [] warnings_as_errors Whether warnings are errors within this library definition. Boolean optional False <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_opt_ir_test","title":"xls_dslx_opt_ir_test","text":"<pre>\nxls_dslx_opt_ir_test(name, benchmark_ir_args, dep, dslx_test_args, input_validator,\n                     input_validator_expr, ir_equivalence_args, ir_eval_args, top)\n</pre> <p>A build rule that tests a xls_dslx_opt_ir target.</p> <p>Executes the test commands for the following rules in the order presented:</p> <ol> <li>xls_dslx_test</li> <li>xls_ir_equivalence_test</li> <li>xls_eval_ir_test</li> <li>xls_benchmark_ir</li> </ol> <p>Examples:</p> <ol> <li>A simple example.<pre><code>xls_dslx_opt_ir(\n    name = \"a_opt_ir\",\n    srcs = [\"a.x\"],\n    dslx_top = \"a\",\n)\n\nxls_dslx_opt_ir_test(\n    name = \"a_opt_ir_test\",\n    dep = \":a_opt_ir\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required benchmark_ir_args Arguments of the benchmark IR tool. For details on the arguments, refer to the benchmark_main application at //xls/tools/benchmark_main.cc. Dictionary: String -&gt; String optional {} dep The xls_dslx_opt_ir target to test. Label optional None dslx_test_args Arguments of the DSLX interpreter executable. For details on the arguments, refer to the interpreter_main application at //xls/dslx/interpreter_main.cc. Dictionary: String -&gt; String optional {} input_validator The DSLX library defining the input validator for this test. Mutually exclusive with \"input_validator_expr\". Label optional None input_validator_expr The expression to validate an input for the test function. Mutually exclusive with \"input_validator\". String optional \"\" ir_equivalence_args Arguments of the IR equivalence tool. For details on the arguments, refer to the check_ir_equivalence_main application at //xls/tools/check_ir_equivalence_main.cc. The 'function' argument is not assigned using this attribute. Dictionary: String -&gt; String optional {} ir_eval_args Arguments of the IR interpreter. For details on the arguments, refer to the eval_ir_main application at //xls/tools/eval_ir_main.cc.The 'top' argument is not assigned using this attribute. Dictionary: String -&gt; String optional {\"random_inputs\": \"100\", \"optimize_ir\": \"true\"} top The (mangled) name of the entry point. See get_mangled_ir_symbol. Defines the 'top' argument of the IR tool/application. String optional \"\" <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_test","title":"xls_dslx_test","text":"<pre>\nxls_dslx_test(name, deps, dslx_test_args, library, srcs)\n</pre> <p>A dslx test executes the tests and quick checks of a DSLX source file.</p> <p>Examples:</p> <ol> <li> <p>xls_dslx_test on DSLX source files.</p> <pre><code># Assume a xls_dslx_library target bc_dslx is present.\nxls_dslx_test(\n    name = \"e_dslx_test\",\n    srcs = [\n        \"d.x\",\n        \"e.x\",\n    ],\n    deps = [\":bc_dslx\"],\n)\n</code></pre> </li> <li> <p>xls_dslx_test on a xls_dslx_library.</p> <pre><code>xls_dslx_library(\n    name = \"b_dslx\",\n    srcs = [\"b.x\"],\n    deps = [\":a_dslx\"],\n)\n\nxls_dslx_test(\n    name = \"b_dslx_test\",\n    library = \"b_dslx\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required deps Dependency targets for the files in the 'srcs' attribute. This attribute is mutually exclusive with the 'library' attribute. List of labels optional [] dslx_test_args Arguments of the DSLX interpreter executable. For details on the arguments, refer to the interpreter_main application at //xls/dslx/interpreter_main.cc. Dictionary: String -&gt; String optional {} library A DSLX library target where the direct (non-transitive) files of the target are tested. This attribute is mutually exclusive with the 'srcs' and 'deps' attribute. Label optional None srcs Source files for the rule. The files must have a '.x' extension. This attribute is mutually exclusive with the 'library' attribute. List of labels optional [] <p></p>"},{"location":"bazel_rules_macros/#xls_eval_ir_test","title":"xls_eval_ir_test","text":"<pre>\nxls_eval_ir_test(name, input_validator, input_validator_expr, ir_eval_args, src, top)\n</pre> <p>Executes the IR interpreter on an IR file.</p> <p>Examples:</p> <ol> <li> <p>A file as the source.</p> <pre><code>xls_eval_ir_test(\n    name = \"a_eval_ir_test\",\n    src = \"a.ir\",\n)\n</code></pre> </li> <li> <p>An xls_ir_opt_ir target as the source.</p> <pre><code>xls_ir_opt_ir(\n    name = \"a_opt_ir\",\n    src = \"a.ir\",\n)\n\n\nxls_eval_ir_test(\n    name = \"a_eval_ir_test\",\n    src = \":a_opt_ir\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required input_validator The DSLX library defining the input validator for this test. Mutually exclusive with \"input_validator_expr\". Label optional None input_validator_expr The expression to validate an input for the test function. Mutually exclusive with \"input_validator\". String optional \"\" ir_eval_args Arguments of the IR interpreter. For details on the arguments, refer to the eval_ir_main application at //xls/tools/eval_ir_main.cc.The 'top' argument is not assigned using this attribute. Dictionary: String -&gt; String optional {\"random_inputs\": \"100\", \"optimize_ir\": \"true\"} src The IR source file for the rule. A single source file must be provided. The file must have a '.ir' extension. Label required top The (mangled) name of the entry point. See get_mangled_ir_symbol. Defines the 'top' argument of the IR tool/application. String optional \"\" <p></p>"},{"location":"bazel_rules_macros/#xls_ir_equivalence_test","title":"xls_ir_equivalence_test","text":"<pre>\nxls_ir_equivalence_test(name, ir_equivalence_args, src_0, src_1, top)\n</pre> <p>Executes the equivalence tool on two IR files.</p> <p>Examples:</p> <ol> <li> <p>A file as the source.</p> <pre><code>xls_ir_equivalence_test(\n    name = \"ab_ir_equivalence_test\",\n    src_0 = \"a.ir\",\n    src_1 = \"b.ir\",\n)\n</code></pre> </li> <li> <p>A target as the source.</p> <pre><code>xls_dslx_ir(\n    name = \"b_ir\",\n    srcs = [\"b.x\"],\n)\n\nxls_ir_equivalence_test(\n    name = \"ab_ir_equivalence_test\",\n    src_0 = \"a.ir\",\n    src_1 = \":b_ir\",\n)\n</code></pre> </li> </ol> <p>ATTRIBUTES</p> Name Description Type Mandatory Default name A unique name for this target. Name required ir_equivalence_args Arguments of the IR equivalence tool. For details on the arguments, refer to the check_ir_equivalence_main application at //xls/tools/check_ir_equivalence_main.cc. The 'function' argument is not assigned using this attribute. Dictionary: String -&gt; String optional {} src_0 An IR source file for the rule. A single source file must be provided. The file must have a '.ir' extension. Label required src_1 An IR source file for the rule. A single source file must be provided. The file must have a '.ir' extension. Label required top The (mangled) name of the entry point. See get_mangled_ir_symbol. Defines the 'top' argument of the IR tool/application. String optional \"\" <p></p>"},{"location":"bazel_rules_macros/#cc_xls_ir_jit_wrapper","title":"cc_xls_ir_jit_wrapper","text":"<pre>\ncc_xls_ir_jit_wrapper(name, src, jit_wrapper_args, kwargs)\n</pre> <p>Invokes the JIT wrapper generator and compiles the result as a cc_library.</p> <p>The macro invokes the JIT wrapper generator on an IR source file. The generated source files are the inputs to a cc_library with its target name identical to this macro.</p> <p>PARAMETERS</p> Name Description Default Value name The name of the cc_library target. none src The path to the IR file. none jit_wrapper_args Arguments of the JIT wrapper tool. Note: argument 'output_name' cannot be defined. <code>{}</code> kwargs Keyword arguments. Named arguments. none <p></p>"},{"location":"bazel_rules_macros/#get_mangled_ir_symbol","title":"get_mangled_ir_symbol","text":"<pre>\nget_mangled_ir_symbol(module_name, function_name, parametric_values, is_implicit_token,\n                      is_proc_next)\n</pre> <p>Returns the mangled IR symbol for the module/function combination.</p> <p>\"Mangling\" is the process of turning nicely namedspaced symbols into \"grosser\" (mangled) flat (non hierarchical) symbol, e.g. that lives on a package after IR conversion. To retrieve/execute functions that have been IR converted, we use their mangled names to refer to them in the IR namespace.</p> <p>PARAMETERS</p> Name Description Default Value module_name The DSLX module name that the function is within. none function_name The DSLX function name within the module. none parametric_values Any parametric values used for instantiation (e.g. for a parametric entry point that is known to be instantiated in the IR converted module). This is generally for more advanced use cases like internals testing. The argument is mutually exclusive with argument 'is_proc_next'. <code>None</code> is_implicit_token A boolean flag denoting whether the symbol contains an implicit token. The argument is mutually exclusive with argument 'is_proc_next'. <code>False</code> is_proc_next A boolean flag denoting whether the symbol is a next proc function. The argument is mutually exclusive with arguments: 'parametric_values' and 'is_implicit_token'. <code>False</code> <p>RETURNS</p> <p>The \"mangled\" symbol string.</p> <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_cpp_type_library","title":"xls_dslx_cpp_type_library","text":"<pre>\nxls_dslx_cpp_type_library(name, src)\n</pre> <p>Creates a cc_library target for transpiled DSLX types.</p> <p>This macros invokes the DSLX-to-C++ transpiler and compiles the result as a cc_library with its target name identical to this macro.</p> <p>PARAMETERS</p> Name Description Default Value name The name of the eventual cc_library. none src The DSLX file whose types to compile as C++. none <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_ir","title":"xls_dslx_ir","text":"<pre>\nxls_dslx_ir(name, dslx_top, srcs, deps, library, ir_conv_args, enable_generated_file,\n            enable_presubmit_generated_file, kwargs)\n</pre> <p>A macro that instantiates a build rule converting a DSLX source file to an IR file.</p> <p>The macro instantiates a rule that converts a DSLX source file to an IR file. The macro also instantiates the 'enable_generated_file_wrapper' function. The generated files are listed in the outs attribute of the rule.</p> <p>Example:</p> <p>An IR conversion with a top entity defined.</p> <pre><code>```\n# Assume a xls_dslx_library target bc_dslx is present.\nxls_dslx_ir(\n    name = \"d_ir\",\n    srcs = [\"d.x\"],\n    deps = [\":bc_dslx\"],\n    dslx_top = \"d\",\n)\n```\n</code></pre> <p>PARAMETERS</p> Name Description Default Value name The name of the rule. none dslx_top The top entity to perform the IR conversion. none srcs Top level source files for the conversion. Files must have a '.x' extension. There must be single source file. <code>None</code> deps Dependency targets for the files in the 'srcs' argument. <code>None</code> library A DSLX library target where the direct (non-transitive) files of the target are tested. This argument is mutually exclusive with the 'srcs' and 'deps' arguments. <code>None</code> ir_conv_args Arguments of the IR conversion tool. For details on the arguments, refer to the ir_converter_main application at //xls/dslx/ir_converter_main.cc. Note: the 'top' argument is not assigned using this attribute. <code>{}</code> enable_generated_file See 'enable_generated_file' from 'enable_generated_file_wrapper' function. <code>True</code> enable_presubmit_generated_file See 'enable_presubmit_generated_file' from 'enable_generated_file_wrapper' function. <code>False</code> kwargs Keyword arguments. Named arguments. none <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_opt_ir","title":"xls_dslx_opt_ir","text":"<pre>\nxls_dslx_opt_ir(name, dslx_top, srcs, deps, library, ir_conv_args, opt_ir_args,\n                enable_generated_file, enable_presubmit_generated_file, kwargs)\n</pre> <p>A macro that instantiates a build rule generating an optimized IR file from a DSLX source file.</p> <p>The macro instantiates a build rule that generates an optimized IR file from a DSLX source file. The build rule executes the core functionality of following macros:</p> <ol> <li>xls_dslx_ir (converts a DSLX file to an IR), and,</li> <li>xls_ir_opt_ir (optimizes the IR).</li> </ol> <p>The macro also instantiates the 'enable_generated_file_wrapper' function. The generated files are listed in the outs attribute of the rule.</p> <p>Examples:</p> <ol> <li>A simple example.<pre><code># Assume a xls_dslx_library target bc_dslx is present.\nxls_dslx_opt_ir(\n    name = \"d_opt_ir\",\n    srcs = [\"d.x\"],\n    deps = [\":bc_dslx\"],\n    dslx_top = \"d\",\n)\n</code></pre> </li> </ol> <p>PARAMETERS</p> Name Description Default Value name The name of the rule. none dslx_top The top entity to perform the IR conversion. none srcs Top level source files for the conversion. Files must have a '.x' extension. There must be single source file. <code>None</code> deps Dependency targets for the files in the 'srcs' argument. <code>None</code> library A DSLX library target where the direct (non-transitive) files of the target are tested. This argument is mutually exclusive with the 'srcs' and 'deps' arguments. <code>None</code> ir_conv_args Arguments of the IR conversion tool. For details on the arguments, refer to the ir_converter_main application at //xls/dslx/ir_converter_main.cc. Note: the 'top' argument is not assigned using this attribute. <code>{}</code> opt_ir_args Arguments of the IR optimizer tool. For details on the arguments, refer to the opt_main application at //xls/tools/opt_main.cc. Note: the 'top' argument is not assigned using this attribute. <code>{}</code> enable_generated_file See 'enable_generated_file' from 'enable_generated_file_wrapper' function. <code>True</code> enable_presubmit_generated_file See 'enable_presubmit_generated_file' from 'enable_generated_file_wrapper' function. <code>False</code> kwargs Keyword arguments. Named arguments. none <p></p>"},{"location":"bazel_rules_macros/#xls_dslx_verilog","title":"xls_dslx_verilog","text":"<pre>\nxls_dslx_verilog(name, dslx_top, verilog_file, srcs, deps, library, ir_conv_args, opt_ir_args,\n                 codegen_args, enable_generated_file, enable_presubmit_generated_file, kwargs)\n</pre> <p>A macro that instantiates a build rule generating a Verilog file from a DSLX source file and tests the build.</p> <p>The macro instantiates a build rule that generates a Verilog file from a DSLX source file. The build rule executes the core functionality of following macros:</p> <ol> <li>xls_dslx_ir (converts a DSLX file to an IR),</li> <li>xls_ir_opt_ir (optimizes the IR), and,</li> <li>xls_ir_verilog (generated a Verilog file).</li> </ol> <p>The macro also instantiates a 'build_test' testing that the build rule generating a Verilog file. If the build is not successful, an error is produced when executing a test command on the target.</p> <p>Examples:</p> <ol> <li>A simple example.<pre><code># Assume a xls_dslx_library target bc_dslx is present.\nxls_dslx_verilog(\n    name = \"d_verilog\",\n    srcs = [\"d.x\"],\n    deps = [\":bc_dslx\"],\n    codegen_args = {\n        \"pipeline_stages\": \"1\",\n    },\n    dslx_top = \"d\",\n)\n</code></pre> </li> </ol> <p>PARAMETERS</p> Name Description Default Value name The name of the rule. none dslx_top The top entity to perform the IR conversion. none verilog_file The filename of Verilog file generated. The filename must have a '.v' extension. none srcs Top level source files for the conversion. Files must have a '.x' extension. There must be single source file. <code>None</code> deps Dependency targets for the files in the 'srcs' argument. <code>None</code> library A DSLX library target where the direct (non-transitive) files of the target are tested. This argument is mutually exclusive with the 'srcs' and 'deps' arguments. <code>None</code> ir_conv_args Arguments of the IR conversion tool. For details on the arguments, refer to the ir_converter_main application at //xls/dslx/ir_converter_main.cc. Note: the 'top' argument is not assigned using this attribute. <code>{}</code> opt_ir_args Arguments of the IR optimizer tool. For details on the arguments, refer to the opt_main application at //xls/tools/opt_main.cc. Note: the 'top' argument is not assigned using this attribute. <code>{}</code> codegen_args Arguments of the codegen tool. For details on the arguments, refer to the codegen_main application at //xls/tools/codegen_main.cc. <code>{}</code> enable_generated_file See 'enable_generated_file' from 'enable_generated_file_wrapper' function. <code>True</code> enable_presubmit_generated_file See 'enable_presubmit_generated_file' from 'enable_generated_file_wrapper' function. <code>False</code> kwargs Keyword arguments. Named arguments. none <p></p>"},{"location":"bazel_rules_macros/#xls_ir_cc_library","title":"xls_ir_cc_library","text":"<pre>\nxls_ir_cc_library(name, src, top, namespaces)\n</pre> <p>Invokes the AOT compiles the input IR into a cc_library.</p> <p>Example:</p> <pre><code>xls_ir_opt_ir(\n    name \"foo\",\n    ...\n)\n\nxls_ir_cc_library_macro(\n    name = \"foo_cc\",\n    src = \":foo.opt.ir\",\n    top = \"bar\",\n    namespaces = \"a,b,c\",\n)\n</code></pre> <p>This will produce a cc_library that will execute the fn <code>bar</code> from the <code>foo</code> IR file. The call itself will be inside the namespace <code>a::b::c</code>.</p> <p>PARAMETERS</p> Name Description Default Value name The name of the resulting library. none src The path to the IR file to compile. none top The entry point in the IR file of interest. <code>None</code> namespaces A comma-separated list of namespaces into which the generated code should go. <code>\"\"</code> <p></p>"},{"location":"bazel_rules_macros/#xls_ir_opt_ir","title":"xls_ir_opt_ir","text":"<pre>\nxls_ir_opt_ir(name, src, opt_ir_args, enable_generated_file, enable_presubmit_generated_file,\n              kwargs)\n</pre> <p>A macro that instantiates a build rule optimizing an IR file.</p> <p>The macro instantiates a build rule that optimizes an IR file. The macro also instantiates the 'enable_generated_file_wrapper' function. The generated files are listed in the outs attribute of the rule.</p> <p>Examples:</p> <ol> <li> <p>A simple example.</p> <pre><code>xls_ir_opt_ir(\n    name = \"a_opt_ir\",\n    src = \"a.ir\",\n)\n</code></pre> </li> <li> <p>Optimizing an IR file with an top entity defined.</p> <pre><code>xls_ir_opt_ir(\n    name = \"a_opt_ir\",\n    src = \"a.ir\",\n    opt_ir_args = {\n        \"inline_procs\" : \"true\",\n    },\n)\n</code></pre> </li> </ol> <p>PARAMETERS</p> Name Description Default Value name The name of the rule. none src The IR source file. A single source file must be provided. The file must have a '.ir' extension. none opt_ir_args Arguments of the IR optimizer tool. For details on the arguments, refer to the opt_main application at //xls/tools/opt_main.cc. Note: the 'top' argument is not assigned using this attribute. <code>{}</code> enable_generated_file See 'enable_generated_file' from 'enable_generated_file_wrapper' function. <code>True</code> enable_presubmit_generated_file See 'enable_presubmit_generated_file' from 'enable_generated_file_wrapper' function. <code>False</code> kwargs Keyword arguments. Named arguments. none <p></p>"},{"location":"bazel_rules_macros/#xls_ir_verilog","title":"xls_ir_verilog","text":"<pre>\nxls_ir_verilog(name, src, verilog_file, codegen_args, enable_generated_file,\n               enable_presubmit_generated_file, kwargs)\n</pre> <p>A macro that instantiates a build rule generating a Verilog file from an IR file and tests the build.</p> <p>The macro instantiates a build rule that generate a Verilog file from an IR file, and a 'build_test' testing that the build rule generating a Verilog file. If the build is not successful, an error is produced when executing a test command on the target.</p> <p>Example:</p> <pre><code>```\nxls_ir_verilog(\n    name = \"a_verilog\",\n    src = \"a.ir\",\n    codegen_args = {\n        \"pipeline_stages\": \"1\",\n        ...\n    },\n)\n```\n</code></pre> <p>PARAMETERS</p> Name Description Default Value name The name of the rule. none src The IR source file. A single source file must be provided. The file must have a '.ir' extension. none verilog_file The filename of Verilog file generated. The filename must have a '.v' or '.sv', extension. none codegen_args Arguments of the codegen tool. For details on the arguments, refer to the codegen_main application at //xls/tools/codegen_main.cc. <code>{}</code> enable_generated_file See 'enable_generated_file' from 'enable_generated_file_wrapper' function. <code>True</code> enable_presubmit_generated_file See 'enable_presubmit_generated_file' from 'enable_generated_file_wrapper' function. <code>False</code> kwargs Keyword arguments. Named arguments. none"},{"location":"build_system/","title":"Build system","text":"<p>XLS uses the Bazel build system for itself and all its dependencies. Bazel is an easy to configure and use, and has powerful extension facilities. (It's also well-documented!) XLS provides a number of Starlark rules and macros to define a build flow.</p> <ul> <li>Build system<ul> <li>Whirlwind Intro To Bazel<ul> <li>Where the output files go</li> </ul> </li> <li>XLS Project Build Rules</li> <li>Bazel queries<ul> <li>Finding transitive dependencies</li> <li>Finding dependees (\"reverse dependencies\")</li> </ul> </li> </ul> </li> </ul>"},{"location":"build_system/#whirlwind-intro-to-bazel","title":"Whirlwind Intro To Bazel","text":"<p>Many developers are familiar with a make-style build flow. Bazel, by contrast, provides more built-in structure for where generated files and binary artifacts are placed, in order to keep the source tree unmodified and the build process fully declarative / repeatable. In Bazel, one of the key principles is \"the user should not need to <code>bazel clean</code>\".</p> <p>A typical build command looks like:</p> <pre><code>$ bazel build -c opt //xls/tools:opt_main\n</code></pre> <p>The <code>-c opt</code> flag is requesting we produce an optimized build. Other options for development are:</p> <ul> <li><code>-c fastbuild</code>: fewer optimizations, quicker turn around time on builds, and</li> <li><code>-c dbg</code>: debug binaries, minimal optimization level and debug information     produced, e.g. for using binaries under <code>gdb</code></li> </ul> <p>Targets are referenced with <code>//</code> as the root of the current repository -- it is generally optional. From there you specify the path to a directory with a <code>BUILD</code> file, and then <code>:target_name</code> to reference a named target within that <code>BUILD</code> file. In the case above, the build target referenced is a C++ binary -- its build definition is described by a <code>cc_binary</code> rule in the <code>xls/tools/BUILD</code> file.</p>"},{"location":"build_system/#where-the-output-files-go","title":"Where the output files go","text":"<p>The above command notes the following in its output:</p> <pre><code>Target //xls/tools:opt_main up-to-date:\n  bazel-bin/xls/tools/opt_main\n</code></pre> <p>We can see binary result files go to <code>bazel-bin</code> within our repository's root directory. (Aside: <code>bazel-bin</code> is a convenient symlink to an out-of-tree location where build artifacts are placed.)</p> <p>Generated files that are intermediate entities in the build process are also visible via a similar symlink, <code>bazel-out</code>. Within the following directory:</p> <pre><code>$ ls bazel-out/host/bin/xls/ir/\n</code></pre> <p>We can see files that were part of the build of the IR library, like <code>op.h</code> and <code>op.cc</code>.</p>"},{"location":"build_system/#xls-project-build-rules","title":"XLS Project Build Rules","text":"<p>XLS provides a set of Bazel build rules and macros that allow users to quickly/easily create XLS-based design artifacts -- analogous to the way C++, Python, etc are done in Bazel. For example, <code>dslx_library</code> lets a user make a library target written in XLS' Domain Specific Language frontend.</p> <p>XLS build rules and macros are defined in xls/build_rules/xls_build_defs.bzl.</p> <p>Examples using the rules and macros are found at xls/build_rules/tests/BUILD.</p> <p>A detailed description of the bazel rules/macros can be found here.</p>"},{"location":"build_system/#bazel-queries","title":"Bazel queries","text":"<p>Understanding the build tree for a new project can be difficult, but fortunately Bazel provides a powerful query mechanism. <code>bazel query</code> enables a user to examine build targets, dependencies between them, and much more. A few usage examples are provided here, but the full documentation (linked above) is comprehensive.</p>"},{"location":"build_system/#finding-transitive-dependencies","title":"Finding transitive dependencies","text":"<p>To understand why, for example, the combinational verilog generator depends on the ABSL container algorithm library, one could run:</p> <pre><code>$ bazel query 'somepath(//xls/codegen:combinational_generator, @com_google_absl//absl/algorithm:container)'\n//xls/codegen:combinational_generator\n//xls/codegen:vast\n@com_google_absl//absl/algorithm:container\n</code></pre> <p>This result shows that one such path goes through the <code>:vast</code> target. Another such path goes through the xls/ir:ir target, then the xls/ir:value target. <code>somepath</code> provides some path, not all paths (that's what <code>allpaths</code> is for).</p>"},{"location":"build_system/#finding-dependees-reverse-dependencies","title":"Finding dependees (\"reverse dependencies\")","text":"<p>Sometimes it's useful to identify the set of targets depending on some other target - the <code>rdeps</code> query performs this:</p> <pre><code>$ bazel query 'rdeps(//xls/codegen:all, //xls/codegen:combinational_generator)'\n//xls/codegen:flattening_test\n//xls/ir:ir_test_base\n//xls/codegen:combinational_generator_test\n//xls/codegen:combinational_generator\n</code></pre> <p>This shows the transitive closure of all dependencies of the combinational generator, with the starting set being all targets in <code>//xls/codegen:all</code>. This set of dependencies can quickly grow to be unmanageable, so keep the initial set (the first argument) as small as possible, and consider specifying a third argument for maximum search depth.</p>"},{"location":"codegen_options/","title":"Codegen Options","text":"<p>This document outlines some useful knobs for running codegen on an XLS design. Codegen is the process of generating RTL from IR and is where operations are scheduled and mapped into RTL constructs. The output of codegen is suitable for simulation or implementation via standard tools that understand Verilog or SystemVerilog.</p> <ul> <li>Codegen Options</li> <li>Input specification</li> <li>Output locations</li> <li>Pipelining and Scheduling Options</li> <li>Naming</li> <li>Reset Signal Configuration</li> <li>Codegen Mapping<ul> <li>Format Strings</li> </ul> </li> <li>I/O Behavior</li> <li>RAMs (experimental)</li> <li>Optimization</li> </ul>"},{"location":"codegen_options/#input-specification","title":"Input specification","text":"<ul> <li><code>&lt;input.ir&gt;</code> is a positional argument giving the path to the ir file.</li> <li><code>--top</code> specifies the top function or proc to codegen.</li> </ul>"},{"location":"codegen_options/#output-locations","title":"Output locations","text":"<p>The following flags control where output files are put. In addition to Verilog, codegen can generate files useful for understanding or integrating the RTL.</p> <ul> <li><code>--output_verilog_path</code> is the path to the output Verilog file.</li> <li><code>--output_schedule_path</code> is the path to a textproto that shows into which     pipeline stage the scheduler put IR ops.</li> <li><code>--output_block_ir_path</code> is the path to the \"block IR\" representation of the     design, a post-scheduling IR that is timed and includes registers, ports,     etc.</li> <li><code>--output_signature_path</code> is the path to the signature textproto. The     signature describes the ports, channels, external memories, etc.</li> <li><code>--output_verilog_line_map_path</code> is the path to the verilog line map     associating lines of verilog to lines of IR.</li> </ul>"},{"location":"codegen_options/#pipelining-and-scheduling-options","title":"Pipelining and Scheduling Options","text":"<p>The following flags control how XLS maps IR operations to RTL, and if applicable control the scheduler.</p> <ul> <li><code>--generator=...</code> controls which generator to use. The options are     <code>pipeline</code> and <code>combinational</code>. The <code>pipeline</code> generator runs a scheduler     that partitions the IR ops into pipeline stages.</li> <li><code>--delay_model=...</code> selects the delay model to use when scheduling. See the     page here for more detail.</li> <li><code>--clock_period_ps=...</code> sets the target clock period. See     scheduling for more details on how scheduling works. Note     that this option is optional, without specifying clock period XLS will     estimate what the clock period should be.</li> <li><code>--pipeline_stages=...</code> sets the number of pipeline stages to use when     <code>--generator=pipeline</code>.</li> <li><code>--clock_margin_percent=...</code> sets the percentage to reduce the target clock     period before scheduling. See scheduling for more details.</li> <li><code>--period_relaxation_percent=...</code> sets the percentage that the computed     minimum clock period is increased. May not be specified with     <code>--clock_period_ps</code>.</li> <li><code>--additional_input_delay_ps=...</code> adds additional input delay to the inputs.     This can be helpful to meet timing when integrating XLS designs with other     RTL.</li> <li><code>--io_constraints=...</code> adds constraints to the scheduler. The flag takes a     comma-separated list of constraints of the form <code>foo:send:bar:recv:3:5</code>     which means that sends on channel <code>foo</code> must occur between 3 and 5 cycles     (inclusive) before receives on channel <code>bar</code>. Note that for a constraint     like <code>foo:send:foo:send:3:5</code>, no constraint will be applied between a node     and itself; i.e.: this means all different pairs of nodes sending on <code>foo</code>     must be in cycles that differ by between 3 and 5. If the special     minimum/maximum value <code>none</code> is used, then the minimum latency will be the     lowest representable <code>int64_t</code>, and likewise for maximum latency.     For an example of the use of this, see     this example     and the associated BUILD rule.</li> </ul>"},{"location":"codegen_options/#naming","title":"Naming","text":"<p>Some names can be set at codegen via the following flags:</p> <ul> <li><code>--module_name=...</code> sets the name of the generated verilog module</li> <li>For functions, <code>--input_valid_signal=...</code> and <code>--output_valid_signal=...</code>     adds and sets the name of valid signals when <code>--generator</code> is set to     <code>pipeline</code>.</li> <li><code>--manual_load_enable_signal=...</code> adds and sets the name of an input that     sets the load-enable signals of each pipeline stage.</li> <li>For procs, <code>--streaming_channel_data_suffix=...</code>,     <code>--streaming_channel_valid_suffix=...</code>, and     <code>--streaming_channel_ready_suffix=...</code> set suffixes to be used on their     respective signals in ready/valid channels. For example,     <code>--streaming_channel_valid_suffix=_vld</code> for a channel named <code>ABC</code> would     result in a valid port called <code>ABC_vld</code>.</li> </ul>"},{"location":"codegen_options/#reset-signal-configuration","title":"Reset Signal Configuration","text":"<ul> <li><code>--reset=...</code> sets the name of the reset signal. If not specified, no reset     signal is used.</li> <li><code>--reset_active_low</code> sets if the reset is active low or high. Active high by     default.</li> <li><code>--reset_asynchronous</code> sets if the reset is synchronous or asynchronous     (synchronous by default).</li> <li><code>--reset_data_path</code> sets if the datapath should also be reset. True by     default.</li> </ul>"},{"location":"codegen_options/#codegen-mapping","title":"Codegen Mapping","text":"<ul> <li><code>--use_system_verilog</code> sets if the output should use SystemVerilog     constructs such as SystemVerilog array assignments, <code>@always_comb</code>,     <code>@always_ff</code>, asserts, covers, etc. True by default.</li> <li><code>--separate_lines</code> causes every subexpression to be emitted on a separate     line. False by default.</li> </ul>"},{"location":"codegen_options/#format-strings","title":"Format Strings","text":"<p>For some XLS ops, flags can override their default codegen behavior via format string. These format strings use placeholders to fill in relevant information.</p> <ul> <li><code>--gate_format=...</code> sets the format string for <code>gate!</code> ops. Supported     placeholders are:<p>-   <code>{condition}</code>: Identifier (or expression) of the gate.   -   <code>{input}</code>: Identifier (or expression) for the data input of the gate.   -   <code>{output}</code>: Identifier for the output of the gate.   -   <code>{width}</code>: The bit width of the gate operation.</p> <p>For example, consider a format string which instantiates a particular custom   AND gate for gating:</p> <pre><code>my_and gated_{output} [{width}-1:0] (.Z({output}), .A({condition}), .B({input}))\n</code></pre> <p>And the IR gate operation is:</p> <p><code>the_result: bits[32] = gate(the_cond, the_data)</code></p> <p>This results in the following emitted Verilog:</p> <p><code>my_and gated_the_result [32-1:0] (.Z(the_result), .A(the cond),   .B(the_data));</code></p> <p>To ensure valid Verilog, the insantiated template must declare a value named   <code>{output}</code> (e.g. <code>the_result</code> in the example).</p> </li> </ul> <ul> <li><code>--assert_format=...</code> sets the format string for assert statements.     Supported placeholders are:<p>-   <code>{message}</code>: Message of the assert operation.   -   <code>{condition}</code>: Condition of the assert.   -   <code>{label}</code>: Label of the assert operation. It is an error not to use the       <code>label</code> placeholder.   -   <code>{clk}</code>: Name of the clock signal. It is an error not to use the <code>clk</code>       placeholder.   -   <code>{rst}</code>: Name of the reset signal. It is an error not to use the <code>rst</code>       placeholder.</p> <p>For example, the format string:</p> <p><code>{label}: `MY_ASSERT({condition}, \"{message}\")</code></p> <p>could result in the following emitted Verilog:</p> <p><code>my_label: `MY_ASSERT(foo &lt; 8'h42, \"Oh noes!\");</code></p> </li> </ul> <ul> <li><code>--smulp_format=...</code> and <code>--umulp_format=...</code> set the format strings for     <code>smulp</code> and <code>umulp</code> ops respectively. These ops perform partial (or split)     multiplies. Supported placeholders are:<p>-   <code>{input0}</code> and <code>{input1}</code>: The two inputs.   -   <code>{input0_width}</code> and <code>{input1_width}</code>: The width of the two inputs   -   <code>{output}</code>: Name of the output. Partial multiply IP generally produces       two outputs with the property that the sum of the two outputs is the       product of the inputs. <code>{output}</code> should be the concatenation of these       two outputs.   -   <code>{output_width}</code>: Width of the output.</p> <p>For example, the format string:</p> <pre><code>multp #(\n    .x_width({input0_width}),\n    .y_width({input1_width}),\n    .z_width({output_width}&gt;&gt;1)\n  ) {output}_inst (\n    .x({input0}),\n    .y({input1}),\n    .z0({output}[({output_width}&gt;&gt;1)-1:0]),\n    .z1({output}[({output_width}&gt;&gt;1)*2-1:({output_width}&gt;&gt;1)})])\n  );\n</code></pre> <p>could result in the following emitted Verilog:</p> <pre><code>multp #(\n  .x_width(16),\n  .y_width(16),\n  .z_width(32&gt;&gt;1)\n) multp_out_inst (\n  .x(lhs),\n  .y(rhs),\n  .z0(multp_out[(32&gt;&gt;1)-1:0]),\n  .z1(multp_out[(32&gt;&gt;1)*2-1:(32&gt;&gt;1)])\n);\n</code></pre> <p>Note the arithmetic performed on <code>output_width</code> to make the two-output   <code>multp</code> block fill the concatenated output expected by XLS.</p> </li> </ul>"},{"location":"codegen_options/#io-behavior","title":"I/O Behavior","text":"<ul> <li><code>--flop_inputs</code> and <code>--flop_outputs</code> control if inputs and outputs should be     flopped respectively. These flags are only used by the pipeline generator.<p>For procs, inputs and outputs are channels with ready/valid signalling and   have additional options controlling how inputs and outputs are registered.   <code>--flop_inputs_kind=...</code> and <code>--flop_outputs_kind=...</code> flags control what   the logic around the outputs and inputs look like respectively. The list   below enumerates the possible kinds of output flopping and shows what logic   is generated in each case.</p> <p>-   <code>flop</code>: Adds a pipeline stage at the beginning or end of the block to       hold inputs or outputs. This is essentially a single-element FIFO.</p> </li> </ul> <p></p> <pre><code>-   `skid`: Adds a skid buffer at the inputs or outputs of the block. The\n    skid buffer can hold 2 entries.\n</code></pre> <p></p> <pre><code>-   `zerolatency`: Adds a zero-latency buffer at the beginning or end of the\n    block. This is essentially a single-element FIFO with bypass.\n</code></pre> <p></p> <ul> <li><code>--flop_single_value_channels</code> control if single-value channels should be     flopped.</li> </ul> <ul> <li><code>--add_idle_output</code> adds an additional output port named <code>idle</code>. <code>idle</code> is     the NOR of:<p>1.  Pipeline registers storing the valid bit for each pipeline stage.   2.  All valid registers stored for the input/output buffers.   3.  All valid signals for the input channels.</p> </li> </ul>"},{"location":"codegen_options/#rams-experimental","title":"RAMs (experimental)","text":"<p>XLS has experimental support for using proc channels to drive an external RAM. For an example usage, see this delay implemented with a single-port RAM (modeled here). Note that receives on the response channel must be conditioned on performing a read, otherwise there will be deadlock.</p> <p>The codegen option <code>--ram_configurations</code> takes a comma-separated list of configurations in the format <code>ram_name:ram_kind[:kind-specific-configuration]</code>. For a <code>1RW</code> RAM, the format is <code>ram_name:1RW:req_channel_name:resp_channel_name[:latency]</code>, where latency is 1 if unspecified. For a <code>1RW</code> RAM, there are several requirements these channels must satisfy:</p> <ul> <li>The request channel must be a tuple type with 4 entries corresponding to     <code>(addr, wr_data, we, re)</code>. All entries must have type <code>bits</code>, and <code>we</code> and     <code>re</code> must be a single bit.</li> <li>The response channel must be a tuple type with a single entry corresponding     to <code>(rd_data)</code>. <code>rd_data</code> must have the same width as <code>wr_data</code>.</li> </ul> <p>Instead of the normal channel ports, the codegen option will produce the following ports:</p> <ul> <li><code>{ram_name}_addr</code></li> <li><code>{ram_name}_wr_data</code></li> <li><code>{ram_name}_we</code></li> <li><code>{ram_name}_re</code></li> <li><code>{ram_name}_rd_data</code></li> </ul> <p>Note that there are no ready/valid signals as RAMs have fixed latency. There is an internal buffer to catch the response and apply backpressure on requests if needed.</p> <p>When using <code>--ram_configurations</code>, you should generally add a scheduling constraint via <code>--io_constraints</code> to ensure the request-send and response-receive are scheduled to match the RAM's latency.</p>"},{"location":"codegen_options/#optimization","title":"Optimization","text":"<ul> <li><code>--gate_recvs</code> emits logic to gate the data value of a receive operation in     Verilog. In the XLS IR, the receive operation has the semantics that the     data value is zero when the predicate is <code>false</code>. Moreover, for a     non-blocking receive, the data value is zero when the data is invalid. When     set to true, the data is gated and has the previously described semantics.     However, the latter does utilize more resource/area. Setting this value to     false may reduce the resource/area utilization, but may also result in     mismatches between IR-level evaluation and Verilog simulation.</li> </ul> <ul> <li><code>--array_index_bounds_checking</code>: With this option set, an out of bounds     array access returns the maximal index element in the array. If this option     is not set, the result relies on the semantics of out-of-bounds array access     in Verilog which is not well-defined. Setting this option to <code>true</code> may     result in more resource/area. Setting this value to <code>false</code> may reduce the     resource/area utilization, but may also result in mismatches between     IR-level evaluation and Verilog simulation.</li> </ul>"},{"location":"contributing/","title":"How to Contribute","text":"<p>We'd love to accept your patches and contributions to this project. There are just a few small guidelines you need to follow.</p>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":"<p>This project follows Google's Open Source Community Guidelines.</p>"},{"location":"contributing/#contributor-license-agreement","title":"Contributor License Agreement","text":"<p>Contributions to this project must be accompanied by a Contributor License Agreement (CLA). You (or your employer) retain the copyright to your contribution; this simply gives us permission to use and redistribute your contributions as part of the project. Head over to https://cla.developers.google.com/ to see your current agreements on file or to sign a new one.</p> <p>You generally only need to submit a CLA once, so if you've already submitted one (even if it was for a different project), you probably don't need to do it again.</p>"},{"location":"contributing/#code-style","title":"Code style","text":"<p>When writing code contributions to the project, please make sure to follow the style guides: The Google C++ Style Guide and the Google Python Style Guide. There are a few small [XLS clarifications] (https://google.github.io/xls/xls_style/) for local style on this project where the style guide is ambiguous.</p>"},{"location":"contributing/#code-reviews","title":"Code reviews","text":"<p>All submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose. Consult GitHub Help for more information on using pull requests.</p>"},{"location":"contributing/#pull-request-style","title":"Pull Request Style","text":"<p>We ask contributors to squash all the commits in the PR into a single one, in order to have a cleaner revision history.</p> <p>Specifically, when you initially send a PR, please ensure it has a single commit. If you'd like to address review comments by adding commits,1 please be sure to squash them into one again once the PR is approved (though squashing continuously is also acceptable).</p> <p>Generally, squashing to a single commit can be accomplished by:</p> <pre><code>proj/xls$ # Here we assume origin points to google/xls.\nproj/xls$ git fetch origin main\nproj/xls$ git merge-base origin/main my-branch-name  # Tells you common ancesor COMMIT_HASH.\nproj/xls$ git reset --soft $COMMIT_HASH\nproj/xls$ git commit -a -m \"My awesome squashed commit message!!!1\"\nproj/xls$ # Now we can more easily rebase our squashed commit on main.\nproj/xls$ git rebase origin/main\n</code></pre> <p>Rebased branches can be pushed to their corresponding PRs with <code>--force</code>.</p> <p>See also this Stack Overflow question.</p>"},{"location":"contributing/#rendering-documentation","title":"Rendering Documentation","text":"<p>XLS uses mkdocs to render its documentation, and serves it via GitHub pages at https://google.github.io/xls. To render documentation locally as a preview, you can set up mkdocs as follows:</p> <pre><code>proj/xls$ mkvirtualenv xls-mkdocs-env\nproj/xls$ pip install mkdocs-material mkdocs-exclude mdx_truly_sane_lists\nproj/xls$ mkdocs serve\n</code></pre> <p>This will start a local server that you can browse to and that will update the documentation on the fly as you make changes.</p> <p>Note that the <code>mkvirtualenv</code> command assumes you're using virtualenvwrapper to manage your Python environment. You'll need to adjust these instrutions if you're doing something different. That can include explicitly adding <code>mkdocs</code> to your path, if locally installed Python binaries aren't available by default.</p>"},{"location":"contributing/#dsl-snippets-in-documentation","title":"DSL snippets in documentation","text":"<p>There are a few different language annotations we use in different circumstances in the Markdown docs:</p> <ul> <li><code>dslx</code>: A full code block that should be parsed/typechecked/tested.</li> <li><code>dslx-snippet</code>: A fragment that should be syntax highlighted, but not   parsed/typechecked/tested.</li> <li><code>dslx-bad</code>: An example of something that we expect to produce an error   when parsing/typechecking/testing.</li> </ul> <p>GitHub issue google/xls#378 tracks a script that does the parse/typecheck/test that ensures our documentation is up to date and correct.</p> <ol> <li> <p>Adding commits preserves the GitHub code review history and makes it   easier to review incremental changes, but causes an additional \"round trip\"   with the reviewer for the final squash after approval, so there is a small   procedural tradeoff.\u00a0\u21a9</p> </li> </ol>"},{"location":"data_layout/","title":"Data layout","text":"<p>For many uses, XLS types exist within their own conceptual space or domain, so \"portability\" concerns don't exist. When interacting with the JIT, however, XLS and host-native types must interact, so the data layouts of both must be understood and possibly reconciled.</p> <ul> <li>Data layout<ul> <li>XLS data layout</li> <li>Host data layout</li> <li>JIT data layout</li> <li>Packed views<ul> <li>Tuple types</li> </ul> </li> </ul> </li> </ul>"},{"location":"data_layout/#xls-data-layout","title":"XLS data layout","text":"<p>The concrete XLS <code>Bits</code> type is the ultimate container of actual data for any XLS IR type: tuples and arrays may be contain any number of tuple, array, or bits types, but whatever the layout of the type tree, all leaf nodes are Bits. When accessing the underlying storage of a <code>Bits</code> via the <code>ToBytes()</code> member function, the results are returned in a little-endian layout, i.e, with the least-significant data elements stored in the lowest addressable location. For example, the 32-bit value 12,345,678 (0xBC614E), would be returned as:</p> <pre><code>High  &lt;--  Low\n0x 00 BC 61 4E\n</code></pre>"},{"location":"data_layout/#host-data-layout","title":"Host data layout","text":"<p>Different architectures can use different native layouts. For example, x86 (and descendants) use little-endian (i.e., <code>0x00 BC 61 4E</code>), and modern ARM can be configurable as either. (There are actually other layouts, but they're best left to the dustbin of history).</p>"},{"location":"data_layout/#jit-data-layout","title":"JIT data layout","text":"<p>From the above, we can see that XLS' native layout differs from that of most modern hosts. When compiling XLS code, the [LLVM] JIT understandably uses the host's native layout. What this means is that any data fed into the JIT from XLS will need to be byte-swapped before ingestion.</p> <p>For Value or unpacked view input, this swapping is handled automatically, in <code>LlvmIrRuntime::PackArgs()</code> (via <code>LlvmIrRuntime::BlitValueToBuffer()</code>) - and the __un__swapping is also automatically performed in <code>LlvmIrRuntime::UnpackBuffer()</code>. Thus, for these uses, no special action is required of the user.</p>"},{"location":"data_layout/#packed-views","title":"Packed views","text":"<p>However, this is not the case for use of packed views. The motivating use case for packed views is to allow users to map native types directly into JIT-usable values - for example, to use an IEEE float32 (e.g., a C <code>float</code>) directly, without needing to be exploded into a <code>bits[1]</code> for the sign, a <code>bits[8]</code> for the exponent, and a <code>bits[23]</code> for the fractional part.</p> <p>When creating a packed view from a C <code>float</code>, no special action is needed - that <code>float</code> is in native host layout, which is the layout used by the JIT. If, however, data is coming from XLS (perhaps a <code>float</code> converted into a Value, manipulated in some way, then passed into the JIT), then the user must un-swap the bits back to native layout. This is because the JIT has no way of knowing the provenance of that data (if it's from a native type or XLS), so it's up to the provider of that data to ensure proper layout.</p> <p>Distilled into a simple rule of thumb: if packed view data is coming from XLS, it needs to be byte swapped before being passed into the JIT.</p>"},{"location":"data_layout/#tuple-types","title":"Tuple types","text":"<p>Another wrinkle is the usage of packed tuple views. When XLS emits a tuple type in Verilog, the first element in the tuple declaration is placed in the most significant bits, and so on, with the last-declared element placed in the least significant bits. To match this layout, PackedTupleView elements must be also declared from most significant to least significant element. This way, when running on a host, the in-memory layout of input data matches that expected by XLS tools. That means, using the usual float32 example, that the packed view declaration is:</p> <pre><code>PackedTupleView&lt;PackedBitsView&lt;1&gt;, PackedBitsView&lt;8&gt;, PackedBitsView&lt;23&gt;&gt;\n</code></pre> <p>(The non-packed-View tuple declaration is much the same, but matters less, as it doesn't directly correspond to in-memory data layout.)</p> <p>Be aware of this layout when accessing elements in a PackedTupleView. In the float32 above, accessing element 0 yields the sign bit (the most significant bit in memory), and accessing element 2 yields the fractional part (the least significant 23 bits in memory), as one would expect given the tuple type declaration order.</p> <p>While this may initially seem confusing, it suffices to remember that PackedTupleView element declaration order is the \"reverse\" of the in-memory order; refer to value_view_test.cc and function_jit_test.cc for test examples, or the [generated] fp32_add_2_jit_wrapper.h/cc and fp32_add_2_test.cc for practical usage.</p>"},{"location":"delay_estimation/","title":"Delay Estimation Methodology","text":""},{"location":"delay_estimation/#context","title":"Context","text":"<p>This doc describes the delay estimation methodology used in XLS and related background.</p> <p>Estimating delays through networks of CMOS gates is a rich topic, and Static Timing Analysis (STA) is used in chip backend flows to ensure that, even for parts operating at the tail end of the distribution, chips continue to function as specified logically in the netlist.</p> <p>In stark contrast to something with very concrete constraints, like a \"post-global routing, high-accuracy parasitics static timing analysis\", the HLS tool needs to estimate at a high level, reasonably near to the user's behavioral specification, what delay HLS operations will have when they are \"stacked on top\" of each other in a data dependent fashion in the design.</p> <p>This information lets the HLS tool schedule operations into cycles without violating timing constraints; e.g. if the user specifies 1GHz (= 1000ps) as their target clock frequency, the HLS tool may choose to pack as much data dependent work into the 1000ps budget (minus clock uncertainty) as it can on any given cycle.</p> <p>Although what we're estimating is a close relative of Static Timing Analysis, the fact it's being analyzed at a very high level presents a different set of tradeoffs, where coarse granularity estimation and conservative bounds are more relevant. Fine-grained / precise analyses are used later in the chip design process, in the backend flows, but the HLS tool acts more like an RTL designer, creating an RTL output that early timing analysis deems acceptable.</p> <p>Notably, we don't want to be too conservative, as being conservative on timing can lead to designs that take more area and consume more power, as the flops introduced by additional pipeline stages are significant. We want to be as accurate as possible while providing a good experience of being able to close timing quickly (say, in a single pass, or with a small number of iterations in case of a pathological design).</p>"},{"location":"delay_estimation/#background","title":"Background","text":""},{"location":"delay_estimation/#what-xls-is-compiling","title":"What XLS is compiling","text":"<p>XLS currently supports feed-forward pipelines -- once the user program is unrolled into a big \"sea of nodes\" we must schedule each of those operations (represented by nodes) to occur in a cycle.</p> <p>It seems clear that an operation like <code>add(bits[32], bits[32]) -&gt; bits[32]</code> takes some amount of time to produce a result -- we need to be able to determine what that amount of time is for packing that operation into a given cycle. 1 Note that XLS operations are parametric in their bitwidth, so <code>add(bits[17], bits[17]) -&gt; bits[17]</code> is just as possible as a value like <code>32</code>. This ain't C code.</p> <p>1: Note that we currently pack operations into cycles atomically -- that is, we don't break an <code>add</code> that would straddle a cycle boundary into <code>add.first_half</code> and <code>add.second_half</code> automatically to pull things as early as possible in the pipeline, but this is future work of interest. Ideally operations would be described structurally in a way that could automatically be cut up according to available delay budget. This would also permit operations in the IR that take more than a single cycle to produce a value (currently they would have to be \"legalized\" into operations that fit within a cycle, but that is not yet done, the user will simply receive a scheduling error).</p> <p>Some operations, such as <code>bit_slice</code> or <code>concat</code> are just wiring \"feng shui\"; however, they still have some relevance for delay calculations! Say we concatenate a value with zeros for zero extension. Even if we could schedule that in \"cycle 0\", if the consumer can only be placed in \"cycle 1\", we would want to \"sink\" the concat down into \"cycle 1\" as well to avoid unnecessary registers being materialized sending the zero values from \"cycle 0\".</p>"},{"location":"delay_estimation/#the-delay-problem","title":"The delay problem","text":"<p>Separately from XLS considerations, there are fundamental considerations in calculating the delay through clouds of functional logic in (generated) RTL.</p> <p>Between each launching and capturing flop is a functional network of logic gates, implemented with standard cells in our ASIC process flows. Chip designs target a particular clock frequency as their operating point, and the functional network has to produce its output value with a delay that meets the timing constraint of the clock frequency. The RTL designer typically has to iterate their design until:</p> <p>timing path delay &lt;= target clock period - clock uncertainty</p> <p>For all timing paths in their design, where clock uncertainty includes setup/hold time constraints, and slop that's built in as margin for later sources of timing variability (like instantiating a clock tree, which can skew the clock signal observed by different flops).</p> <p>In a reasonable model, gate delay is affected by a small handful of properties, as reflected in the \"(Method of) Logical Effort\" book:</p> <ul> <li>The transistor network used to implement a logic function (AKA logical   effort): on an input pin change, the gate of each transistor must be driven to   a point it recognizes whether a 0 or 1 voltage is being presented. More gates   to drive, or larger gates, means more work for the driver.</li> <li>The load being driven by the logic function (AKA electrical effort): fanning   out to more gates generally means more work to drive them all to their   threshold voltages. Being loaded down by bigger gates means more work to drive   it to its threshold voltage.</li> <li>Parasitic delays: RC elements in the system that leech useful work, typically   in a smaller way compared to the efforts listed above.</li> </ul> <p>The logical effort book describes a way to analyze the delays through a network of gates to find the minimal delay, and size transistors in a way that can achieve that minimal delay (namely by geometrically smoothing the ability for gate to drive capacitance).</p> <p>Confounding factors include:</p> <ul> <li>Medium/large wires: sizing transistors to smooth capacitance becomes difficult   as fixed-capacitance elements (wires) are introduced. It seems that small   wires have low enough capacitance they can generally be treated as parasitic.</li> <li>Divergence/reconvergence in the functional logic network (as a DAG). Different   numbers of logic levels and different drive currents may be presented from   different branches of a fork/join the logic graph, which forces delay analysis   into a system of equations to attempt to minimize the overall delay, as   observed by the critical path, with transistor sizing and gate choices. (Some   simplifications are possible, like buffering non-critical paths until they   have the same number of logic levels so they also have plenty of current to   supply at join points.)</li> </ul> <p>Somewhat orthogonal to the analytical modeling problem, there are also several industry standards for supplying process information to Static Timing Analysis engines for determining delay through a netlist. This information is often given in interpolated tables for each standard cell, for example in the NLDM model describing how delay changes as a function of input transition time and load (load capacitance).</p> <p>These models and supplied pieces of data are important to keep in mind for contrast, as we now ignore it all and do something very simple.</p>"},{"location":"delay_estimation/#simple-delay-estimation","title":"Simple Delay Estimation","text":"<p>Currently, XLS delay estimation follows a conceptually simple procedure:</p> <ul> <li>For every operation in XLS (e.g. binary addition):     *   For some relevant-seeming set of bitwidths; e.g. <code>{2, 4, 8, 16, ...,         2048}</code>     *   Find the maximum frequency at which that operation closes timing at that         bitwidth, in 100MHz units as determined by the synthesis tool.         2 Call the clock period for this frequency         <code>t_best</code>. (Note that we currently just use a single process corner /         voltage for this sweep.)     *   Subtract the clock uncertainty from <code>t_best</code>.     *   Record that value in a table (with the keys of the table being operation         / bitwidth).</li> </ul> <p>2: The timing report can provide the delay through a path at any clock frequency, but a wrinkle is that synthesis tools potentially only start using their more aggressive techniques as you bump up against the failure-to-close-timing point -- there it'll be more likely to change the structure of the design to make it more delay friendly. The sweep helps to try to cajole it in that way.</p> <p>Inspecting the data acquired in this way we observe all of the plots consist of one or more the following delay components:</p> <ul> <li>Constant as a function of bitwidth for a given op (e.g. binary-or just     requires a single gate for each bit regardless of the width of the inputs).</li> <li>Logarithmic as a function of bitwidth (e.g. adders may end up using     tree-like structures to minimize delay, single-selector muxes end up using a     tree to fan out the selector to the muxes, etc.).</li> <li>Linear as a function of bitwidth (e.g., ripple-carry adders and some     components of multipliers).</li> </ul> <p>So given this observation we fit a curve of the form:</p> <pre><code>a * bitwidth + b * log_2(bitwidth) + c\n</code></pre> <p>to the sweep data for each operation, giving us <code>(a, b, c)</code> values to use in our XLS delay estimator.</p> <p>The utility <code>delay_model_visualizer</code> under the <code>tools</code> directory renders a graph of the delay model estimate against the measured data points. This graph for add shows a good correspondence to the measured delay.</p> <p></p>"},{"location":"delay_estimation/#sweeping-multiple-dimensions","title":"Sweeping multiple dimensions","text":"<p>Operations with attributes in addition to bitwidth that affect delay are swept across multiple dimensions. An example is <code>Op::kOneHotSelect</code> which has dimensions of bitwidth and number of cases. For the <code>Op::kOneHotSelect</code> example the formula is:</p> <pre><code>a * bitwidth + b * log_2(bitwidth) + c * (# of cases) + d * log_2(# of cases) + c\n</code></pre> <p>Below is plot of delay for <code>Op::kOneHotSelect</code> showing the two dimensions of bitwidth and operand count affecting delay:</p> <p></p>"},{"location":"delay_estimation/#sources-of-pessimismoptimism","title":"Sources of pessimism/optimism","text":"<p>This simple method has both sources of optimism and pessimism, though we hope to employ a method that will be generally conservative, so that users can easily close timing and get a close-to-best-achievable result (say, within tens of percent) with a single HLS iteration.</p> <p>Sources of pessimism (estimate is conservative):</p> <ul> <li>The operation sweeps mentioned are not bisecting to the picosecond, so there     is inherent slop in the measurement on account of sweep granularity.</li> <li>We expect, in cycles where multiple dependent operations are present, there     would be \"K-map style\" logic reductions with adjacent operations. For     example, because we don't do cell library mapping in XLS delay estimation,     something a user wrote that mapped to an AOI21 cell would be the sum of     (and+or+invert) delays.</li> <li>[Unsure] May there be additional logic branch splitting options and     earlier-produced results available to the synthesis tool when there are more     operations in the graph (vs a lone critical path measured for a single     operation)?</li> </ul> <p>Sources of optimism (estimate is overeager):</p> <ul> <li>For purposes of the sweep the outputs of an operation are only loaded by a     single capture flop flop -- when operations have fanout the delay will     increase.<p>Note that we do account for fanout within individual operations as part of   this sweep; e.g. a 128-bit selector fanout (e.g. 128 ways to 128 muxes) for   a select is accounted for the in delay timing of the select operation. It is   the output logic layer that is only loaded by a single flop in our   characterization. Notably because most of these operations turn into trees   of logic, there are \\(\\(log_2(bitcount)\\)\\) layers of logic in which we can   potentially smoothly increase drive strength out to the output logic layer,   and paths can presumably be replicated by synthesis tools to reduce   pointwise fanout when multiple high-level operations are data-dependent   within a cycle. (Is it possible for a user to break up their 32-bit select   into bitwise pieces in their XLS code to mess with our modeling? Sure, but   probably not too expected, so we're currently sort of relying on the notion   people are using high level operations instead of compodecomposing them into   bitwise pieces in our graph.)</p> <p>A potential way to reconcile this output fanout in the future is to do a   delay sweep with a high-capacitive fanout (e.g. four flops of load) and then   ensure the IR has a maximum fanout of four for our delay estimation.</p> </li> </ul> <ul> <li>Wiring delay / load / congestion / length are not estimated. This will need     additional analysis / refinement as we run XLS through synthesis tools with     advanced timing analysis, as it is certainly not viable for arbitrary     designs (tight pipelines may be ok for now, though).</li> </ul>"},{"location":"delay_estimation/#iterative-refinement","title":"Iterative refinement","text":"<p>The caveats mentioned above seem somewhat daunting, but this first cut approach appears to work comfortably at target frequenties, in practice, for the real-world blocks being designed as XLS \"first samples\".</p> <p>Notably, human RTL designers fail to close timing on a first cut as well -- HLS estimations like the above assist in getting a numeric understanding (in lieu of an intuitive guess) of something that may close timing on a first cut. As this early model fails, we will continue to refine it; however, there is also a secondary procedure that can assist as the model improves.</p> <p>Let's call the delay estimation described above applied to a program a prediction of its delays. Let's call the first prediction we make <code>p0</code>: <code>p0</code> will either meet timing or fail to meet timing.</p> <p>When we meet timing with <code>p0</code>, there may be additional wins left on the table. If we're willing to put synthesis tool runs \"in the loop\" (say running a \"tuner\" overnight), we can refine XLS's estimates according to the realities of the current program, and, for example, try to squeeze as much as possible into as few cycles as possible if near-optimality of latency/area/power were a large consideration. This loop would generate <code>p1</code>, <code>p2</code>, ... as it refined its model according to empirical data observed from the synthesis tool's more refined analysis.</p> <p>When we fail to close timing with <code>p0</code>, we can feed back the negative slack delays for comparison with our estimates and relax estimates accordingly. Additionally, an \"aggression\" knob could be implemented that backs off delay estimations geometrically (say via a \"fudge factor\" coefficient) in order to ensure HLS developer time is not wasted unnecessarily to ensure. Once a combination of these mechanisms has obtained a design that closes timing, the \"meeting timing, now refine\" procedure can be employed as described above.</p>"},{"location":"delay_estimation/#on-hints","title":"On Hints","text":"<p>To whatever extent possible, XLS should be the tool that reasons about how to target the backend (vs having a tool that sits on top of it and messes with XLS' input in an attempt to achieve a result). User-facing hint systems are typically very fragile, owing to the fact they don't have easily obeyed semantics. XLS, by contrast, knows about its own internals, so can do things with awareness of what's happened upstream and what remains to happen downstream.</p> <p>By contrast, we should continue to add ways for users to provide more semantic information / intent as part of their program (e.g. via more high-level patterns that make high level structure more clear), and make XLS smarter about how to lower those constructs into hardware (and why it should be lowering them that way) in the face of some prioritized objectives (power/area/latency).</p> <p>That being said, because we're probably trying to produce hardware at a given point in time against a given technology, it likely makes sense to permit human users to specify things directly (at a point in time), even if those specifications might be ignored / handled very differently in the future or against different technology nodes. This would be the moral equivalent of what existing EDA tools do as a \"one-off TCL file\" used in a particular design, vs something carried from design to design. Recall, though, that the intent of XLS is to make things easier to carry from design to design and require fewer one-off modifications!</p>"},{"location":"delay_estimation/#tools","title":"Tools","text":"<p>XLS provides tools for analyzing its delay estimation model. (Note that the given IR should be in a form suitable for code generation; e.g. it has run through the <code>opt_main</code> binary).</p> <pre><code>$ tools/benchmark_main crc32.opt.ir --clock_period_ps=500\n&lt;snip&gt;\nReturn value delay: 1362ps\nCritical path entry count: 42\nCritical path:\n   1362ps (+  5ps): not.29: bits[32] = not(xor.205: bits[32], pos=[(0,29,50)])\n   1357ps (+ 20ps): xor.205: bits[32] = xor(concat.195: bits[32], and.196: bits[32], pos=[(0,24,19)])\n   1337ps (+ 15ps): and.196: bits[32] = and(neg.194: bits[32], literal.304: bits[32], pos=[(0,24,33)])\n   1322ps (+134ps): neg.194: bits[32] = neg(concat.191: bits[32], pos=[(0,23,15)])\n&lt;snip&gt;\n    154ps (+ 15ps): and.133: bits[32] = and(neg.131: bits[32], literal.19: bits[32], pos=[(0,24,33)])\n    139ps (+134ps): neg.131: bits[32] = neg(concat.219: bits[32], pos=[(0,23,15)])\n      5ps (+  0ps): concat.219: bits[32] = concat(literal.297: bits[31], bit_slice.214: bits[1], pos=[(0,23,21)])\n      5ps (+  0ps): bit_slice.214: bits[1] = bit_slice(not.208: bits[8], start=0, width=1, pos=[(0,23,21)])\n      5ps (+  5ps): not.208: bits[8] = not(message: bits[8], pos=[(0,20,16)])\n&lt;snip&gt;\n</code></pre> <p>In addition to the critical path, the cycle-by-cycle breakdown of which operations have been scheduled is provided in stdout.</p>"},{"location":"dslx_bytecode_interpreter/","title":"Bytecode interpreter","text":"<p>DSLX provides a bytecode interpreter for expression evaluation. This style of interpreter can be started, stopped, and resumed more easily than an AST-walking native interpreter, as its full state can be captured as <code>{PC, stack}</code> instead of some traversal state in native execution, which makes it very suitable for modeling independent processes, such as <code>Proc</code>s.</p> <p>NOTE: The bytecode interpreter system is under active construction and does not yet support the full set of DSLX functionality.</p> <ul> <li>Bytecode interpreter<ul> <li>Structure</li> <li>ISA</li> <li>Bytecode generation</li> <li>Implementation details<ul> <li>map builtin</li> </ul> </li> </ul> </li> </ul>"},{"location":"dslx_bytecode_interpreter/#structure","title":"Structure","text":"<p>The interpreter is implemented as a stack virtual machine: it consists of a program counter (PC), a stack of frames, and \"slot\"-based locals within a given stack frame (conceptually part of the stack frame, but tracked separately in our implementation). Both the stack and local storage hold <code>InterpValues</code>, which can hold all DSLX data types: bits, tuples, and arrays (and others), thus there is no fundamental need for lower-level (i.e., byte) type representation. For the purposes of [de]serialization, this may change in the future. Local data is addressed by integer-typed \"slots\", being backed by a simple <code>std::vector</code>: in other words, slot indices are dense. All slots must be pre-allocated to contain all references to locals in the current function stack frame.</p> <p>On each \"tick\", the interpreter reads the current instruction, as given by the PC (conceptually, the only register in the virtual machine), executes the described operation (usually consuming values from the stack), and places the result on the stack.</p>"},{"location":"dslx_bytecode_interpreter/#isa","title":"ISA","text":"<p>Each instruction consists of an opcode plus, optionally, some piece of data, either <code>int64</code>- or <code>InterpValue</code>-typed, depending on the specific opcode.</p> <p>The below opcodes are supported by the interpreter:</p> <ul> <li><code>ADD</code>: Adds the two values at the top of the stack.</li> <li><code>CALL</code>: Invokes the function given as the optional data argument, consuming     a number of arguments from the stack as described by the function signature.     The N'th parameter will be present as the N'th value down the stack (such     that the last parameter will be the value initially on top of the stack.</li> <li><code>CREATE_TUPLE</code>: Groups together N items on the stack (given by the optional     data argument into a single <code>InterpValue</code>.</li> <li><code>EXPAND_TUPLE</code>: Expands the N-tuple at stack top by one level, placing     leading elements at stack top. In other words, expanding the tuple <code>(a, (b,     c))</code> will result in a stack of <code>(b, c), a</code>, where <code>a</code> is on top of the     stack.</li> <li><code>EQ</code>: Compares the two values on top of the stack for equality. Emits a     single-bit value.</li> <li><code>LOAD</code>: Loads the value from locals slot <code>n</code>, where <code>n</code> is given by the     optional data argument.</li> <li><code>LITERAL</code>: Places a literal value (given in the optional data argument) on     top of the stack.</li> <li><code>STORE</code>: Stores the value at stack top into slot <code>n</code> in locals storage.</li> </ul>"},{"location":"dslx_bytecode_interpreter/#bytecode-generation","title":"Bytecode generation","text":"<p>The bytecode emitter is responsible for converting a set of DSLX ASTs (one per function)) into a set of linear bytecode representations. It does this via a postorder traversal of the AST, converting XLS ops into bytecode instructions along the way, e.g., converting a DSLX <code>Binop</code> for adding two <code>NameRef</code>s into two <code>LOAD</code> instructions (one for each <code>NameRef</code>) and one <code>ADD</code> instruction.</p> <p>To do this, the emitter needs access to the full set of resolved type and import information: in other words, it requires a fully-populated <code>ImportData</code> and the top-level <code>TypeInfo</code> for the module containing the function to convert. This places bytecode emission in sequence after typechecking and deduction.</p>"},{"location":"dslx_bytecode_interpreter/#implementation-details","title":"Implementation details","text":""},{"location":"dslx_bytecode_interpreter/#map-builtin","title":"<code>map</code> builtin","text":"<p>The <code>map()</code> function built-in to DSLX accepts an array-typed value <code>x</code> and a mapping function <code>f</code> with the signature <code>T -&gt; U</code>; that is, it accepts a single value of type <code>T</code> and returns a single value with the type <code>U</code>. In operation, <code>map()</code> applies the mapping function <code>f</code> to every element in <code>x</code> and returns a new array containing the results (with element <code>i</code> in the output corresponding to element <code>i</code> in the input).</p> <p>Conceptually, <code>map()</code> destructures to a <code>for</code> loop over the elements in <code>x</code>, and that's essentially what the interpreter does with these opcodes. To avoid modifying the currently executing bytecode, the interpreter instead creates a new BytecodeFunction consisting of just that destructured <code>for</code> loop over the inputs, followed by a CreateArray op to collect the output(s). Finally, the interpreter begins execution of the new function by creating a new <code>Frame</code> on top of the execution stack.</p>"},{"location":"dslx_reference/","title":"DSLX Reference","text":""},{"location":"dslx_reference/#overview","title":"Overview","text":"<p>DSLX is a domain specific, dataflow-oriented functional language used to build hardware that can also run effectively as host software. Within the XLS project, DSLX is also referred to as \"the DSL\". The DSL targets the XLS compiler (via conversion to XLS IR) to enable flows for FPGAs and ASICs.</p> <p>DSLX mimics Rust, while being an immutable expression-based dataflow DSL with hardware-oriented features; e.g. arbitrary bitwidths, entirely fixed size objects, fully analyzeable call graph, etc. To avoid arbitrary new syntax/semantics choices, the DSL mimics Rust where it is reasonably possible; for example, integer conversions all follow the same semantics as Rust.</p> <p>Note: There are some unnecessary differences today from Rust syntax due to early experimentation, but they are quickly being removed to converge on Rust syntax.</p> <p>Note that other frontends to XLS core functionality will become available in the future; e.g. xlscc, for users familiar with the C++-and-pragma style of HLS computation. XLS team develops the DSL as part of the XLS project because we believe it can offer significant advantages over the C++-with-pragmas approach.</p> <p>Dataflow DSLs are a good fit for describing hardware, compared to languages whose design assumes von Neumann style computation (global mutable state, sequential mutation by a sequential thread of control). Using a Domain Specific Language (DSL) provides a more hardware-oriented representation of a given computation that matches XLS compiler (IR) constructs closely. The DSL also allows an exploration of HLS without being encumbered by C++ language or compiler limitations such as non-portable pragmas, magic macros, or semantically important syntactic conventions. The language is still experimental and likely to change, but it is already useful for experimentation and exploration.</p> <p>This document provides a reference for DSLX, mostly by example. Before perusing it in detail, we recommend you first read the DSLX tutorials to understand the broad strokes of the language.</p> <p>In this document we use the function to compute a CRC32 checksum to describe language features. The full code is in <code>examples/dslx_intro/crc32_one_byte.x</code>.</p>"},{"location":"dslx_reference/#comments","title":"Comments","text":"<p>Just as in languages like Rust/C++, comments start with <code>//</code> and last through the end of the line.</p>"},{"location":"dslx_reference/#identifiers","title":"Identifiers","text":"<p>All identifiers, eg., for function names, parameters, and values, follow the typical naming rules of other languages. The identifiers can start with a character or an underscore, and can then contain more characters, underscores, or numbers. Valid examples are:</p> <pre><code>a                 // valid\nCamelCase         // valid\nlike_under_scores // valid\n__also_ok         // valid\n_Ok123_321        // valid\n_                 // valid\n\n2ab               // not valid\n&amp;ade              // not valid\n</code></pre> <p>However, we suggest the following DSLX style rules, which mirror the Rust naming conventions.</p> <ul> <li>Functions are <code>written_like_this</code></li> </ul> <ul> <li>User-defined data types are <code>NamesLikeThis</code></li> </ul> <ul> <li>Constant bindings are <code>NAMES_LIKE_THIS</code></li> </ul> <ul> <li><code>_</code> is the \"black hole\" identifier -- a name that you can bind to but should     never read from, akin to Rust's wildcard pattern match or Python's \"unused     identifier\" convention. It should never be referred to in an expression     except as a \"sink\".</li> </ul> <p>NOTE Since mutable locals are not supported, there is also support for \"tick identifiers\", where a ' character may appear anywhere after the first character of an identifier to indicate \"prime\"; e.g. <code>let state' = update(state);</code>. By convention ticks usually come at the end of an identifier. Since this is not part of Rust's syntax, it is considered experimental at this time.</p>"},{"location":"dslx_reference/#functions","title":"Functions","text":"<p>Function definitions begin with the keyword <code>fn</code>, followed by the function name, a parameter list to the function in parenthesis, followed by an <code>-&gt;</code> and the return type of the function. After this, curly braces denote the begin and end of the function body.</p> <p>The list of parameters can be empty.</p> <p>A single input file can contain many functions.</p> <p>Simple examples:</p> <pre><code>fn ret3() -&gt; u32 {\nu32:3   // This function always returns 3.\n}\n\nfn add1(x: u32) -&gt; u32 {\nx + u32:1  // Returns x + 1, but you knew that!\n}\n</code></pre> <p>Functions return the result of their last computed expression as their return value. There are no explicit return statements. By implication, functions return exactly one expression; they can't return multiple expressions (but this may change in the future as we migrate towards some Rust semantics).</p> <p>Tuples should be returned if a function needs to return multiple values.</p>"},{"location":"dslx_reference/#parameters","title":"Parameters","text":"<p>Parameters are written as pairs <code>name</code> followed by a colon <code>:</code> followed by the <code>type</code> of that parameter. Each parameter needs to declare its own type.</p> <p>Examples:</p> <pre><code>// a simple parameter x of type u32\n   x: u32\n\n// t is a tuple with 2 elements.\n//   the 1st element is of type u32\n//   the 2nd element is a tuple with 3 elements\n//       the 1st element is of type u8\n//       the 2nd element is another tuple with 1 element of type u16\n//       the 3rd element is of type u8\n   t: (u32, (u8, (u16,), u8))\n</code></pre>"},{"location":"dslx_reference/#parametric-functions","title":"Parametric Functions","text":"<p>DSLX functions can be parameterized in terms of the types of its arguments and in terms of types derived from other parametric values. For instance:</p> <pre><code>fn double(n: u32) -&gt; u32 {\nn * u32:2\n}\n\nfn self_append&lt;A: u32, B: u32 = double(A)&gt;(x: bits[A]) -&gt; bits[B] {\nx++x\n}\n\nfn main() -&gt; bits[10] {\nself_append(u5:1)\n}\n</code></pre> <p>In <code>self_append(bits[5]:1)</code>, we see that <code>A = 5</code> based off of formal argument instantiation. Using that value, we can evaluate <code>B = double(A=5)</code>. This derived expression is analogous to C++'s constexpr \u2013 a simple expression that can be evaluated at that point in compilation.</p> <p>See advanced understanding for more information on parametricity.</p>"},{"location":"dslx_reference/#explicit-parametric-instantiation","title":"Explicit parametric instantiation","text":"<p>In some cases, parametric values cannot be inferred from function arguments, such as in the <code>explicit_parametric_simple.x</code> test:</p> <pre><code>fn add_one&lt;E:u32, F:u32, G:u32 = E+F&gt;(lhs: bits[E]) -&gt; bits[G] { ... }\n</code></pre> <p>For this call to instantiable, both <code>E</code> and <code>F</code> must be specified. Since <code>F</code> can't be inferred from an argument, we must rely on explicit parametrics:</p> <pre><code>  add_one&lt;u32:1, {u32:2 + u32:3}&gt;(u1:1);\n</code></pre> <p>This invocation will bind <code>1</code> to <code>E</code>, <code>5</code> to <code>F</code>, and <code>6</code> to <code>G</code>. Note the curly braces around the expression-defined parametric: simple literals and constant references do not need braces (but they can have them), but any other expression requires them.</p>"},{"location":"dslx_reference/#expression-ambiguity","title":"Expression ambiguity","text":"<p>Without curly braces, explicit parametric expressions could be ambiguous; consider the following, slightly changed from the previous example:</p> <pre><code>  add_one&lt;u32:1, u32:2&gt;(u32:3)&gt;(u1:1);\n</code></pre> <p>Is the statement above computing <code>add_one&lt;1, (2 &gt; 3)&gt;(1)</code>, or is it computing <code>(add_one&lt;1, 2&gt;(3)) &gt; 1)</code>? Without additional (and subtle and perhaps surprising) contextual precedence rules, this would be ambiguous and could lead to a parse error or, even worse, unexpected behavior.</p> <p>Fortunately, we can look to Rust for inspiration. Rust's const generics RPF introduced the <code>{ }</code> syntax for disambiguating just this case in generic specifications. With this, any expressions present in a parametric specification must be contained within curly braces, as in the original example.</p> <p>At present, if the braces are omitted, some unpredictable error will occur. Work to improve this is tracked in XLS GitHub issue #321.</p>"},{"location":"dslx_reference/#function-calls","title":"Function Calls","text":"<p>Function calls are expressions and look and feel just like one would expect from other languages. For example:</p> <pre><code>fn callee(x: bits[32], y: bits[32]) -&gt; bits[32] {\nx + y\n}\nfn caller() -&gt; u32 {\ncallee(u32:2, u32:3)\n}\n</code></pre> <p>If more than one value should be returned by a function, a tuple type should be returned.</p>"},{"location":"dslx_reference/#types","title":"Types","text":""},{"location":"dslx_reference/#bit-type","title":"Bit Type","text":"<p>The most fundamental type in DSLX is a variable length bit type denoted as <code>bits[n]</code>, where <code>n</code> is a constant. For example:</p> <pre><code>bits[0]   // possible, but, don't do that\n\nbits[1]   // a single bit\nuN[1]     // explicitly noting single bit is unsigned\nu1        // convenient shorthand for bits[1]\n\nbits[8]   // an 8-bit datatype, yes, a byte\nu8        // convenient shorthand for bits[8]\nbits[32]  // a 32-bit datatype\nu32       // convenient shorthand for bits[32]\nbits[256] // a 256-bit datatype\n</code></pre> <p>DSLX introduces aliases for commonly used types, such as <code>u8</code> for an 8-wide bit type, or <code>u32</code> for a 32-bit wide bit type. These are defined up to <code>u64</code>.</p> <p>All <code>u*</code>, <code>uN[*]</code>, and <code>bits[*]</code> types are interpreted as unsigned integers. Signed integers are specified via <code>s*</code> and <code>sN[*]</code>. Similarly to unsigned numbers, the <code>s*</code> shorthands are defined up to <code>s64</code>. For example:</p> <pre><code>sN[0]\ns0\n\nsN[1]\ns1\n\nsN[64]\ns64\n\nsN[256]\n</code></pre> <p>Signed numbers differ in their behavior from unsigned numbers primarily via operations like comparisons, (variable width) multiplications, and divisions.</p>"},{"location":"dslx_reference/#character-constants","title":"Character Constants","text":"<p>Characters are a special case of bits types: they are implicitly-type as u8. Characters can be used just as traditional bits:</p> <pre><code>fn add_to_null(input: u8) -&gt; u8 {\nlet null:u8 = '\\0';\ninput + null\n}\n\n#[test]\nfn test_main() {\nassert_eq('a', add_to_null('a'))\n}\n</code></pre> <p>DSLX character constants support the full Rust set of escape sequences with the exception of unicode.</p>"},{"location":"dslx_reference/#enum-types","title":"Enum Types","text":"<p>DSLX supports enumerations as a way of defining a group of related, scoped, named constants that do not pollute the module namespace. For example:</p> <pre><code>enum Opcode : u3 {\nFIRE_THE_MISSILES = 0,\nBE_TIRED = 1,\nTAKE_A_NAP = 2,\n}\n\nfn get_my_favorite_opcode() -&gt; Opcode {\nOpcode::FIRE_THE_MISSILES\n}\n</code></pre> <p>Note the use of the double-colon to reference the enum value. This code specifies that the enum behaves like a <code>u3</code>: its storage and extension (via casting) behavior are defined to be those of a <code>u3</code>. Attempts to define an enum value outside of the representable <code>u3</code> range will produce a compile time error.</p> <pre><code>enum Opcode : u3 {\nFOO = 8  // Causes compile time error!\n}\n</code></pre> <p>Enums can be compared for equality/inequality, but they do not permit arithmetic operations, they must be cast to numerical types in order to perform arithmetic:</p> <pre><code>enum Opcode: u3 {\nNOP = 0,\nADD = 1,\nSUB = 2,\nMUL = 3,\n}\n\nfn same_opcode(x: Opcode, y: Opcode) -&gt; bool {\nx == y  // ok\n}\n\nfn next_in_sequence(x: Opcode, y: Opcode) -&gt; bool {\n// x+1 == y // does not work, arithmetic!\nx as u3 + u3:1 == (y as u3)  // ok, casted first\n}\n</code></pre> <p>As mentioned above, casting of enum-values works with the same casting/extension rules that apply to the underlying enum type definition. For example, this cast will sign extend because the source type for the enum is signed. (See numerical conversions for the full description of extension/truncation behavior.)</p> <pre><code>enum MySignedEnum : s3 {\nLOW = -1,\nZERO = 0,\nHIGH = 1,\n}\n\nfn extend_to_32b(x: MySignedEnum) -&gt; u32 {\nx as u32  // Sign-extends because the source type is signed.\n}\n\n#[test]\nfn test_extend_to_32b() {\nassert_eq(extend_to_32b(MySignedEnum::LOW), u32:0xffffffff)\n}\n</code></pre> <p>Casting to an enum is also permitted. However, in most cases errors from invalid casting can only be found at runtime, e.g., in the DSL interpreter or flagging a fatal error from hardware. Because of that, it is recommended to avoid such casts as much as possible.</p>"},{"location":"dslx_reference/#tuple-type","title":"Tuple Type","text":"<p>A tuple is a fixed-size ordered set, containing elements of heterogeneous types. Tuples elements can be any type, e.g. bits, arrays, structs, tuples. Tuples may be empty (an empty tuple is also known as the unit type), or contain one or more types.</p> <p>Examples of tuple values:</p> <pre><code>// The unit type, carries no information.\nlet unit = ();\n\n// A tuple containing two bits-typed elements.\nlet pair = (u3:0b100, u4:0b1101);\n</code></pre> <p>Example of a tuple type:</p> <pre><code>// The type of a tuple with 2 elements.\n//   the 1st element is of type u32\n//   the 2nd element is a tuple with 3 elements\n//       the 1st element is of type u8\n//       the 2nd element is another tuple with 1 element of type u16\n//       the 3rd element is of type u8\ntype MyTuple = (u32, (u8, (u16,), u8));\n</code></pre> <p>To access individual tuple elements use simple indices, starting at 0. For example, to access the second element of a tuple (index 1):</p> <pre><code>#[test]\nfn test_tuple_access() {\nlet t = (u32:2, u8:3);\nassert_eq(u8:3, t.1)\n}\n</code></pre> <p>Such indices can only be numeric literals; parametric symbols are not allowed.</p> <p>Tuples can be \"destructured\", similarly to how pattern matching works in <code>match</code> expressions, which provides a convenient syntax to name elements of a tuple for subsequent use. See <code>a</code> and <code>b</code> in the following:</p> <pre><code>#[test]\nfn test_tuple_destructure() {\nlet t = (u32:2, u8:3);\nlet (a, b) = t;\nlet _ = assert_eq(u32:2, a);\nassert_eq(u8:3, b)\n}\n</code></pre> <p>Just as values can be discarded in a <code>let</code> by using the \"black hole identifier\" <code>_</code>, don't-care values can also be discarded when destructuring a tuple:</p> <pre><code>#[test]\nfn test_black_hole() {\nlet t = (u32:2, u8:3, true);\nlet (_, _, v) = t;\nassert_eq(v, true)\n}\n</code></pre>"},{"location":"dslx_reference/#struct-types","title":"Struct Types","text":"<p>Structures are similar to tuples, but provide two additional capabilities: we name the slots (i.e. struct fields have names while tuple elements only have positions), and we introduce a new type.</p> <p>The following syntax is used to define a struct:</p> <pre><code>struct Point {\nx: u32,\ny: u32\n}\n</code></pre> <p>Once a struct is defined it can be constructed by naming the fields in any order:</p> <pre><code>struct Point {\nx: u32,\ny: u32,\n}\n\n#[test]\nfn test_struct_equality() {\nlet p0 = Point { x: u32:42, y: u32:64 };\nlet p1 = Point { y: u32:64, x: u32:42 };\nassert_eq(p0, p1)\n}\n</code></pre> <p>There is a simple syntax when creating a struct whose field names match the names of in-scope values:</p> <pre><code>struct Point { x: u32, y: u32, }\n\n#[test]\nfn test_struct_equality() {\nlet x = u32:42;\nlet y = u32:64;\nlet p0 = Point { x, y };\nlet p1 = Point { y, x };\nassert_eq(p0, p1)\n}\n</code></pre> <p>Struct fields can also be accessed with \"dot\" syntax:</p> <pre><code>struct Point {\nx: u32,\ny: u32,\n}\n\nfn f(p: Point) -&gt; u32 {\np.x + p.y\n}\n\nfn main() -&gt; u32 {\nf(Point { x: u32:42, y: u32:64 })\n}\n\n#[test]\nfn test_main() {\nassert_eq(u32:106, main())\n}\n</code></pre> <p>Note that structs cannot be mutated \"in place\", the user must construct new values by extracting the fields of the original struct mixed together with new field values, as in the following:</p> <pre><code>struct Point3 {\nx: u32,\ny: u32,\nz: u32,\n}\n\nfn update_y(p: Point3, new_y: u32) -&gt; Point3 {\nPoint3 { x: p.x, y: new_y, z: p.z }\n}\n\nfn main() -&gt; Point3 {\nlet p = Point3 { x: u32:42, y: u32:64, z: u32:256 };\nupdate_y(p, u32:128)\n}\n\n#[test]\nfn test_main() {\nlet want = Point3 { x: u32:42, y: u32:128, z: u32:256 };\nassert_eq(want, main())\n}\n</code></pre>"},{"location":"dslx_reference/#struct-update-syntax","title":"Struct Update Syntax","text":"<p>The DSL has syntax for conveniently producing a new value with a subset of fields updated to reduce verbosity. The \"struct update\" syntax is:</p> <pre><code>struct Point3 {\nx: u32,\ny: u32,\nz: u32,\n}\n\nfn update_y(p: Point3) -&gt; Point3 {\nPoint3 { y: u32:42, ..p }\n}\n\nfn update_x_and_y(p: Point3) -&gt; Point3 {\nPoint3 { x: u32:42, y: u32:42, ..p }\n}\n</code></pre>"},{"location":"dslx_reference/#parametric-structs","title":"Parametric Structs","text":"<p>DSLX also supports parametric structs. For more information on how type-parametricity works, see the parametric functions section.</p> <pre><code>fn double(n: u32) -&gt; u32 { n * u32:2 }\n\nstruct Point&lt;N: u32, M: u32 = double(N)&gt; {\nx: bits[N],\ny: bits[M],\n}\n\nfn make_point&lt;A: u32, B: u32&gt;(x: bits[A], y: bits[B]) -&gt; Point&lt;A, B&gt; {\nPoint{ x, y }\n}\n\n#[test]\nfn test_struct_construction() {\nlet p = make_point(u16:42, u32:42);\nassert_eq(u16:42, p.x)\n}\n</code></pre>"},{"location":"dslx_reference/#understanding-nominal-typing","title":"Understanding Nominal Typing","text":"<p>As mentioned above, a struct definition introduces a new type. Structs are nominally typed, as opposed to structurally typed (note that tuples are structurally typed). This means that structs with different names have different types, regardless of whether those structs have the same structure (i.e. even when all the fields of two structures are identical, those structures are a different type when they have a different name).</p> <pre><code>struct Point {\nx: u32,\ny: u32,\n}\n\nstruct Coordinate {\nx: u32,\ny: u32,\n}\n\nfn f(p: Point) -&gt; u32 {\np.x + p.y\n}\n\n#[test]\nfn test_ok() {\nassert_eq(f(Point { x: u32:42, y: u32:64 }), u32:106)\n}\n</code></pre> <pre><code>#[test]\nfn test_type_checker_error() {\nassert_eq(f(Coordinate { x: u32:42, y: u32:64 }), u32:106)\n}\n</code></pre>"},{"location":"dslx_reference/#array-type","title":"Array Type","text":"<p>Arrays can be constructed via bracket notation. All values that make up the array must have the same type. Arrays can be indexed with indexing notation (<code>a[i]</code>) to retrieve a single element.</p> <pre><code>fn main(a: u32[2], i: u1) -&gt; u32 {\na[i]\n}\n\n#[test]\nfn test_main() {\nlet x = u32:42;\nlet y = u32:64;\n// Make an array with \"bracket notation\".\nlet my_array: u32[2] = [x, y];\nlet _ = assert_eq(main(my_array, u1:0), x);\nlet _ = assert_eq(main(my_array, u1:1), y);\n()\n}\n</code></pre> <p>Because arrays with repeated trailing elements are common, the DSL supports ellipsis (<code>...</code>) at the end of an array to fill the remainder of the array with the last noted element. Because the compiler must know how many elements to fill, in order to use the ellipsis the type must be annotated explicitly as shown.</p> <pre><code>fn make_array(x: u32) -&gt; u32[3] {\nu32[3]:[u32:42, x, ...]\n}\n\n#[test]\nfn test_make_array() {\nlet _ = assert_eq(u32[3]:[u32:42, u32:42, u32:42], make_array(u32:42));\nlet _ = assert_eq(u32[3]:[u32:42, u32:64, u32:64], make_array(u32:64));\n()\n}\n</code></pre> <p>TODO(meheff): Explain arrays and the intricacies of our bits type interpretation and how it affects arrays of bits etc.</p>"},{"location":"dslx_reference/#character-string-constants","title":"Character String Constants","text":"<p>Character strings are a special case of array types, being implicitly-sized arrays of u8 elements. String constants can be used just as traditional arrays:</p> <pre><code>fn add_one&lt;N: u32&gt;(input: u8[N]) -&gt; u8[N] {\nfor (i, result) : (u32, u8[N]) in u32:0..N {\nupdate(result, i, result[i] + u8:1)\n}(input)\n}\n\n#[test]\nfn test_main() {\nassert_eq(\"bcdef\", add_one(\"abcde\"))\n}\n</code></pre> <p>DSLX string constants support the full Rust set of escape sequences - note that unicode escapes get encoded to their UTF-8 byte sequence. In other words, the sequence <code>\\u{10CB2F}</code> will result in an array with hexadecimal values <code>F4 8C AC AF</code>.</p> <p>Moreover, string can be composed of characters.</p> <pre><code>fn string_composed_characters() -&gt; u8[10] {\n['X', 'L', 'S', ' ', 'r', 'o', 'c', 'k', 's', '!']\n}\n\n#[test]\nfn test_main() {\nassert_eq(\"XLS rocks!\", string_composed_characters())\n}\n</code></pre>"},{"location":"dslx_reference/#type-aliases","title":"Type Aliases","text":"<p>DLSX supports the definition of type aliases.</p> <p>Type aliases can be used to provide a more human-readable name for an existing type. The new name is on the left, the existing name on the right:</p> <pre><code>type Weight = u6;\n</code></pre> <p>We can create an alias for an imported type:</p> <pre><code>// Note: this imports an external file in the codebase.\nimport xls.dslx.tests.mod_imported\n\ntype MyEnum = mod_imported::MyEnum;\n\nfn main(x: u8) -&gt; MyEnum {\nx as MyEnum\n}\n\n#[test]\nfn test_main() {\nlet _ = assert_eq(main(u8:42), MyEnum::FOO);\nlet _ = assert_eq(main(u8:64), MyEnum::BAR);\n()\n}\n</code></pre> <p>Type aliases can also provide a descriptive name for a tuple type (which is otherwise anonymous). For example, to define a tuple type that represents a float number with a sign bit, an 8-bit mantissa, and a 23-bit mantissa, one would write:</p> <pre><code>type F32 = (u1, u8, u23);\n</code></pre> <p>After this definition, the <code>F32</code> may be used as a type annotation interchangeably with <code>(u1, u8, u23)</code>.</p> <p>Note, however, that structs are generally preferred for this purpose, as they are more readable and users do not need to rely on tuple elements having a stable order in the future (i.e., they are resilient to refactoring).</p>"},{"location":"dslx_reference/#type-casting","title":"Type Casting","text":"<p>Bit types can be cast from one bit-width to another with the <code>as</code> keyword. Types can be widened (increasing bit-width), narrowed (decreasing bit-width) and/or changed between signed and unsigned. Some examples are found below. See Numerical Conversions for a description of the semantics.</p> <pre><code>#[test]\nfn test_narrow_cast() {\nlet twelve = u4:0b1100;\nassert_eq(twelve as u2, u2:0)\n}\n\n#[test]\nfn test_widen_cast() {\nlet three = u2:0b11;\nassert_eq(three as u4, u4:3)\n}\n\n#[test]\nfn test_narrow_signed_cast() {\nlet negative_seven = s4:0b1001;\nassert_eq(negative_seven as u2, u2:1)\n}\n\n#[test]\nfn test_widen_signed_cast() {\nlet negative_one = s2:0b11;\nassert_eq(negative_one as s4, s4:-1)\n}\n\n#[test]\nfn test_widen_to_unsigned() {\nlet negative_one = s2:0b11;\nassert_eq(negative_one as u3, u3:0b111)\n}\n\n#[test]\nfn test_widen_to_signed() {\nlet three = u2:0b11;\nassert_eq(three as u3, u3:0b011)\n}\n</code></pre>"},{"location":"dslx_reference/#type-checking-and-inference","title":"Type Checking and Inference","text":"<p>DSLX performs type checking and produces an error if types in an expression don't match up.</p> <p><code>let</code> expressions also perform type inference, which is quite convenient. For example, instead of writing:</p> <pre><code>let ch: u32 = (e &amp; f) ^ ((!e) &amp; g);\nlet (h, g, f): (u32, u32, u32) = (g, f, e);\n</code></pre> <p>one can write the following, as long as the types can be properly inferred:</p> <pre><code>let ch = (e &amp; f) ^ ((!e) &amp; g);\nlet (h, g, f) = (g, f, e);\n</code></pre> <p>Note that type annotations can still be added and be used for program understanding, as they they will be checked by DSLX.</p>"},{"location":"dslx_reference/#type-inference-details","title":"Type Inference Details","text":""},{"location":"dslx_reference/#type-inference-background","title":"Type Inference Background","text":"<p>All expressions in the language's expression grammar have a deductive type inference rule. The types must be known for inputs to an operator/function1 and every expression has a way to determine its type from its operand expressions.</p> <p>DSLX uses deductive type inference to check the types present in the program. Deductive type inference is a set of (typically straight-forward) deduction rules: Hindley-Milner style deductive type inference determines the result type of a function with a rule that only observes the input types to that function. (Note that operators like '+' are just slightly special functions in that they have pre-defined special-syntax-rule names.)</p>"},{"location":"dslx_reference/#bindings-and-environment","title":"Bindings and Environment","text":"<p>In DSLX code, the \"environment\" where names are bound (sometimes also referred to as a symbol table) is called the <code>Bindings</code> -- it maps identifiers to the AST node that defines the name (<code>{string: AstNode}</code>), which can be combined with a mapping from AST node to its deduced type (<code>{AstNode: ConcreteType}</code>) to resolve the type of an identifier in the program. <code>Let</code> is one of the key nodes that populates these <code>Bindings</code>, but anything that creates a bound name does as well (e.g. parameters, for loop induction variables, etc.).</p>"},{"location":"dslx_reference/#operator-example","title":"Operator Example","text":"<p>For example, consider the binary (meaning takes two operands) / infix (meaning it syntactically is placed in the center of its operands) '+' operator. The simple deductive type inference rule for '+' is:</p> <p><code>(T, T) -&gt; T</code></p> <p>Meaning that the left hand side operand to the '+' operator is of some type (call it T), the right hand side operand to the '+' operator must be of that same type, T, and the result of that operator is then (deduced) to be of the same type as its operands, T.</p> <p>Let's instantiate this rule in a function:</p> <pre><code>fn add_wrapper(x: bits[2], y: bits[2]) -&gt; bits[2] {\nx + y\n}\n</code></pre> <p>This function wraps the '+' operator. It presents two arguments to the '+' operator and then checks that the annotated return type on <code>add_wrapper</code> matches the deduced type for the body of that function; that is, we ask the following question of the '+' operator (since the type of the operands must be known at the point the add is performed):</p> <p><code>(bits[2], bits[2]) -&gt; ?</code></p> <p>To resolve the '?' the following procedure is being used:</p> <ul> <li>Pattern match the rule given above <code>(T, T) -&gt; T</code> to determine the type T:     the left hand side operand is <code>bits[2]</code>, called T.</li> <li>Check that the right hand side is also that same T, which it is: another     <code>bits[2]</code>.</li> <li>Deduce that the result type is that same type T: <code>bits[2]</code>.</li> <li>That becomes the return type of the body of the function. Check that it is     the same type as the annotated return type for the function, and it is!</li> </ul> <p>The function is annotated to return <code>bits[2]</code>, and the deduced type of the body is also <code>bits[2]</code>. Qed.</p>"},{"location":"dslx_reference/#type-errors","title":"Type errors","text":"<p>A type error would occur in the following:</p> <pre><code>fn add_wrapper(x: bits[2], y: bits[3]) -&gt; bits[2] {\nx + y\n}\n</code></pre> <p>Applying the type deduction rule for '+' finds an inconsistency. The left hand side operand has type <code>bits[2]</code>, called T, but the right hand side is <code>bits[3]</code>, which is not the same as T. Because the deductive type inference rule does not say what to do when the operand types are different, it results in a type error which is flagged at this point in the program.</p>"},{"location":"dslx_reference/#let-bindings-names-and-the-environment","title":"Let Bindings, Names, and the Environment","text":"<p>In the DSL, <code>let</code> is an expression. It may not seem obvious at a glance, but it is! As a primer see the type inference background and how names are resolved in an environment.</p> <p>\"let\" expressions are of the (Rust-inspired) form:</p> <p><code>let $name: $annotated_type = $expr; $subexpr</code></p> <p><code>$name</code> gets \"bound\" to a value of type <code>$annotated_type</code>. The <code>let</code> typecheck rule must both check that <code>$expr</code> is of type <code>$annotated_type</code>, as well as determine the type of <code>$subexpr</code>, which is the type of the overall \"let expression\".</p> <p>In this example, the result of the <code>let</code> expression is the return value -- <code>$subexpr</code> (<code>x+x</code>) can use the <code>$name</code> (<code>x</code>) which was \"bound\":</p> <pre><code>fn main(y: u32) -&gt; u64 {\nlet x: u64 = y as u64;\nx+x\n}\n</code></pre> <p>If we invoke <code>main(u32:2)</code> we will the evaluate <code>let</code> expression -- it creates a binding of <code>x</code> to the value <code>u64:2</code>, and then evaluates the expression <code>x+x</code> in that environment, so the result of the <code>let</code> expression's <code>$subexpr</code> is <code>u64:4</code>.</p>"},{"location":"dslx_reference/#statements","title":"Statements","text":""},{"location":"dslx_reference/#imports","title":"Imports","text":"<p>DSLX modules can import other modules via the <code>import</code> keyword. Circular imports are not permitted (the dependencies among DSLX modules must form a DAG, as in languages like Go).</p> <p>The import statement takes the following form (note the lack of semicolon):</p> <pre><code>import path.to.my.imported_module\n</code></pre> <p>With that statement, the module will be accessible as (the trailing identifier after the last dot) <code>imported_module</code>; e.g. the program can refer to <code>imported_module::IMPORTED_MODULE_PUBLIC_CONSTANT</code>.</p> <p>NOTE Imports are relative to the Bazel \"depot root\" -- for external use of the tools a <code>DSLX_PATH</code> will be exposed, akin to a <code>PYTHONPATH</code>, for users to indicate paths where were should attempt module discovery.</p> <p>NOTE Importing does not introduce any names into the current file other than the one referred to by the import statement. That is, if <code>imported_module</code> had a constant defined in it <code>FOO</code>, this is referred to via <code>imported_module::FOO</code>, <code>FOO</code> does not \"magically\" get put in the current scope. This is analogous to how wildcard imports are discouraged in other languages (e.g. <code>from import *</code> in Python) on account of leading to \"namespace pollution\" and needing to specify what happens when names conflict.</p> <p>If you want to change the name of the imported module (for reference inside of the importing file) you can use the <code>as</code> keyword:</p> <pre><code>import path.to.my.imported_module as im\n</code></pre> <p>Just using the above construct, <code>imported_module::IMPORTED_MODULE_PUBLIC_CONSTANT</code> is not valid, only <code>im::IMPORTED_MODULE_PUBLIC_CONSTANT</code>. However, both statements can be used on different lines:</p> <pre><code>import path.to.my.imported_module\nimport path.to.my.imported_module as im\n</code></pre> <p>In this case, either <code>im::IMPORTED_MODULE_PUBLIC_CONSTANT</code> or <code>imported_module::IMPORTED_MODULE_PUBLIC_CONSTANT</code> can be used to refer to the same thing.</p> <p>Here is an example using the same function via two different aliases for the same module:</p> <pre><code>// Note: this imports an external file in the codebase under two different\n// names.\nimport xls.dslx.tests.mod_imported\nimport xls.dslx.tests.mod_imported as mi\n\nfn main(x: u3) -&gt; u1 {\nmod_imported::my_lsb(x) || mi::my_lsb(x)\n}\n\n#[test]\nfn test_main() {\nassert_eq(u1:0b1, main(u3:0b001))\n}\n</code></pre>"},{"location":"dslx_reference/#public-module-members","title":"Public module members","text":"<p>Module members are private by default and not accessible from any importing module. To make a member public/visible to importing modules, the <code>pub</code> keyword must be added as a prefix; e.g.</p> <pre><code>const FOO = u32:42;      // Not accessible to importing modules.\npub const BAR = u32:64;  // Accessible to importing modules.\n</code></pre> <p>This applies to other things defined at module scope as well: functions, enums, type aliases, etc.</p> <pre><code>import xls.dslx.tests.mod_imported\nimport xls.dslx.tests.mod_imported as mi\n\nfn main(x: u3) -&gt; u1 {\nmod_imported::my_lsb(x) || mi::my_lsb(x)\n}\n\n#[test]\nfn test_main() {\nassert_eq(u1:0b1, main(u3:0b001))\n}\n</code></pre>"},{"location":"dslx_reference/#const","title":"Const","text":"<p>The <code>const</code> keyword is used to define module-level constant values. Named constants should be usable anywhere a literal value can be used:</p> <pre><code>const FOO = u8:42;\n\nfn match_const(x: u8) -&gt; u8 {\nmatch x {\nFOO =&gt; u8:0,\n_ =&gt; u8:42,\n}\n}\n\n#[test]\nfn test_match_const_not_binding() {\nlet _ = assert_eq(u8:42, match_const(u8:0));\nlet _ = assert_eq(u8:42, match_const(u8:1));\nlet _ = assert_eq(u8:0, match_const(u8:42));\n()\n}\n\nfn h(t: (u8, (u16, u32))) -&gt; u32 {\nmatch t {\n(FOO, (x, y)) =&gt; (x as u32) + y,\n(_, (y, u32:42)) =&gt; y as u32,\n_ =&gt; u32:7,\n}\n}\n\n#[test]\nfn test_match_nested() {\nlet _ = assert_eq(u32:3, h((u8:42, (u16:1, u32:2))));\nlet _ = assert_eq(u32:1, h((u8:0, (u16:1, u32:42))));\nlet _ = assert_eq(u32:7, h((u8:0, (u16:1, u32:0))));\n()\n}\n</code></pre>"},{"location":"dslx_reference/#expressions","title":"Expressions","text":""},{"location":"dslx_reference/#literals","title":"Literals","text":"<p>DSLX supports construction of literals using the syntax <code>Type:Value</code>. For example <code>u16:1</code> is a 16-wide bit array with its least significant bit set to one. Similarly <code>s8:12</code> is an 8-wide bit array with its least significant four bits set to <code>1100</code>.</p> <p>DSLX supports initializing using binary, hex or decimal syntax. So</p> <pre><code>#[test]\nfn test_literal_initialization() {\nlet _ = assert_eq(u8:12, u8:0b00001100);\nlet _ = assert_eq(u8:12, u8:0x0c);\n()\n}\n</code></pre> <p>When constructing literals DSLX will trigger an error if the constant will not fit in a bit array of the annotated sized, so for example trying to construct the literal <code>u8:256</code> will trigger an error of the form:</p> <p><code>TypeInferenceError: uN[8] Value '256' does not fit in the bitwidth of a uN[8] (8)</code></p> <p>But what about <code>s8:128</code> ? This is a valid literal, even though a signed 8-bit integer cannot represent it. The following code offers a clue.</p> <pre><code>#[test]\nfn test_signed_literal_initialization() {\nlet _ = assert_eq(s8:128, s8:-128);\nlet _ = assert_eq(s8:128, s8:0b10000000);\n()\n}\n</code></pre> <p>What is happening here is that, 128 is being used as a bit pattern rather than as the number 128 to initialize the literal. It is only when the bit pattern cannot fit in the width of the literal that an error is triggered.</p> <p>Note that behaviour is different from Rust, where it will trigger an error, and the fact that DSLX considers this valid may change in the future.</p>"},{"location":"dslx_reference/#unary-expressions","title":"Unary Expressions","text":"<p>DSLX supports three types of unary expressions:</p> <ul> <li>bit-wise not (the <code>!</code> operator)</li> <li>negate (the <code>-</code> operator, computes the two's complement negation)</li> </ul>"},{"location":"dslx_reference/#binary-expressions","title":"Binary Expressions","text":"<p>DSLX supports a familiar set of binary expressions. There are two categories of binary expressions. A category where both operands to the expression must be of the same bit type (i.e., not arrays or tuples), and a category where the operands can be of arbitrary bit types (i.e. shift expressions).</p> <ul> <li>shift-right (<code>&gt;&gt;</code>)</li> <li>shift-left (<code>&lt;&lt;</code>)</li> <li>bit-wise or (<code>|</code>)</li> <li>bit-wise and (<code>&amp;</code>)</li> <li>add (<code>+</code>)</li> <li>subtract (<code>-</code>)</li> <li>xor (<code>^</code>)</li> <li>multiply (<code>*</code>)</li> <li>logical or (<code>||</code>)</li> <li>logical and (<code>&amp;&amp;</code>)</li> </ul>"},{"location":"dslx_reference/#shift-expressions","title":"Shift Expressions","text":"<p>Shift expressions include: shift-right (logical) and shift-left. These are binary operations that don't require the same type on the left and right hand side. The right hand side must be unsigned, but it does not need to be the same type or width as the left hand side, i.e. the type signature for these operations is: <code>(xN[M], uN[N]) -&gt; xN[M]</code>. If the right hand side is a literal value it does not need to be type annotated. For example:</p> <pre><code>fn shr_two(x: s32) -&gt; s32 {\nx &gt;&gt; 2\n}\n</code></pre> <p>Note that, as in Rust, the semantics of the shift-right (<code>&gt;&gt;</code>) operation depends on the signedness of the left hand side. For a signed-type left hand side, the shift-right (<code>&gt;&gt;</code>) operation performs a shift-right arithmetic and, for a unsigned-type left hand side, the shift-right (<code>&gt;&gt;</code>) operation performs a shift-right (logical).</p>"},{"location":"dslx_reference/#comparison-expressions","title":"Comparison Expressions","text":"<p>For comparison expressions the types of both operands must match. However these operations return a result of type <code>bits[1]</code>, aka <code>bool</code>.</p> <ul> <li>equal (<code>==</code>)</li> <li>not-equal (<code>!=</code>)</li> <li>greater-equal (<code>&gt;=</code>)</li> <li>greater (<code>&gt;</code>)</li> <li>less-equal (<code>&lt;=</code>)</li> <li>less (<code>&lt;</code>)</li> </ul>"},{"location":"dslx_reference/#concat-expression","title":"Concat Expression","text":"<p>Bitwise concatenation is performed with the <code>++</code> operator. The value on the left hand side becomes the most significant bits, the value on the right hand side becomes the least significant bits. These may be chained together as shown below:</p> <pre><code>#[test]\nfn test_bits_concat() {\nlet _ = assert_eq(u8:0b11000000, u2:0b11 ++ u6:0b000000);\nlet _ = assert_eq(u8:0b00000111, u2:0b00 ++ u6:0b000111);\nlet _ = assert_eq(u6:0b100111, u1:1 ++ u2:0b00 ++ u3:0b111);\nlet _ = assert_eq(u6:0b001000, u1:0 ++ u2:0b01 ++ u3:0b000);\nlet _ = assert_eq(u32:0xdeadbeef, u16:0xdead ++ u16:0xbeef);\n()\n}\n</code></pre>"},{"location":"dslx_reference/#block-expressions","title":"Block Expressions","text":"<p>Block expressions enable subordinate scopes to be defined, e.g.:</p> <pre><code>let a = {\n  let b = u32:1;\n  b + u32:3\n};\n</code></pre> <p>The value of a block expression is that of its last contained expression, or (), if a final expression is omitted:</p> <pre><code>let a = { let b = u32:1; };\n</code></pre> <p>In the above case, <code>a</code> is equal to <code>()</code>.</p> <p>Since DSLX does not currently have the concept of lifetimes, and since names can be rebound (i.e., there's no concept of mutability, allowing <code>let a = u32:0; let a = u32:1;</code>), blocks are primarily for readability at this time, (side from their use as the \"body\" of functions and loops).</p>"},{"location":"dslx_reference/#match-expression","title":"Match Expression","text":"<p>Match expressions permit \"pattern matching\" on data, like a souped-up switch statement. It can both test for values (like a conditional guard) and bind values to identifiers for subsequent use. For example:</p> <pre><code>fn f(t: (u8, u32)) -&gt; u32 {\nmatch t {\n(u8:42, y) =&gt; y,\n(_, y) =&gt; y+u32:77\n}\n}\n</code></pre> <p>If the first member of the tuple is the value is <code>42</code>, we pass the second tuple member back as-is from the function. Otherwise, we add <code>77</code> to the value and return that. The <code>_</code> symbolizes \"I don't care about this value\".</p> <p>Just like literal constants, pattern matching can also match via named constants; For example, consider this variation on the above:</p> <pre><code>const MY_FAVORITE_NUMBER = u8:42;\nfn f(t: (u8, u32)) -&gt; u32 {\nmatch t {\n(MY_FAVORITE_NUMBER, y) =&gt; y,\n(_, y) =&gt; y+u32:77\n}\n}\n</code></pre> <p>This also works with nested tuples; for example:</p> <pre><code>const MY_FAVORITE_NUMBER = u8:42;\nfn f(t: (u8, (u16, u32))) -&gt; u32 {\nmatch t {\n(MY_FAVORITE_NUMBER, (y, z)) =&gt; y as u32 + z,\n(_, (y, u32:42)) =&gt; y as u32,\n_ =&gt; u32:7\n}\n}\n</code></pre> <p>Here we use a \"catch all\" wildcard pattern in the last match arm to ensure the match expression always matches the input somehow.</p>"},{"location":"dslx_reference/#redundant-patterns","title":"Redundant Patterns","text":"<p><code>match</code> will flag an error if a syntactically identical pattern is typed twice; e.g.</p> <pre><code>const FOO = u32:42;\nfn f(x: u32) -&gt; u2 {\nmatch x {\nFOO =&gt; u2:0,\nFOO =&gt; u2:1,  // Identical pattern!\n_ =&gt; u2:2,\n}\n}\n</code></pre> <p>Only the first pattern will ever match, so it is fully redundant (and therefore likely a user error they'd like to be informed of). Note that equivalent but not syntactically identical patterns will not be flagged in this way.</p> <pre><code>const FOO = u32:42;\nconst BAR = u32:42;  // Compares `==` to `FOO`.\nfn f(x: u32) -&gt; u2 {\nmatch x {\nFOO =&gt; u2:0,\nBAR =&gt; u2:1,  // _Equivalent_ pattern, but not syntactically identical.\n_ =&gt; u2:2,\n}\n}\n</code></pre>"},{"location":"dslx_reference/#let-expression","title":"<code>let</code> Expression","text":"<p>let expressions work the same way as let expressions in other functional languages (such as the ML family languages). let expressions provide a nested, lexically-scoped, list of binding definitions. The scope of the binding is the expression on the right hand side of the declaration. For example:</p> <pre><code>let a: u32 = u32:1 + u32:2;\nlet b: u32 = a + u32:3;\nb\n</code></pre> <p>would bind (and return as a value) the value <code>6</code> which corresponds to <code>b</code> when evaluated. In effect there is little difference to other languages like C/C++ or Python, where the same result would be achieved with code similar to this:</p> <pre><code>a = 1 + 2\nb = a + 3\nreturn b\n</code></pre> <p>However, <code>let</code> expressions are lexically scoped. In above example, the value <code>3</code> is bound to <code>a</code> only during the combined let expression sequence. There is no other type of scoping in DSLX.</p>"},{"location":"dslx_reference/#if-expression","title":"If Expression","text":"<p>DSLX offers an <code>if</code> expression, which is very similar to the Rust <code>if</code> expression. Blueprint:</p> <pre><code>if condition { consequent } else { alternate }\n</code></pre> <p>This corresponds to the C/C++ ternary <code>?:</code> operator:</p> <pre><code>condition ? consequent : alternate\n</code></pre> <p>Note: both the <code>if</code> and <code>else</code> are required to be present, as with the <code>?:</code> operator, unlike a C++ <code>if</code> statement. This is because it is an expression that produces a result value, not a statement that causes a mutating effect.</p> <p>Furthermore, you can have multiple branches via <code>else if</code>:</p> <pre><code>if condition0 { consequent0 } else if condition1 { consequent1 } else { alternate }\n</code></pre> <p>which corresponds to the C/C++:</p> <pre><code>condition0 ? consequent0 : (contition1 ? consequent1 : alternate)\n</code></pre> <p>Note: a <code>match</code> expression can often be a better choice than having a long <code>if/else if/.../else</code> chain.</p> <p>For example, in the FP adder module (modules/fp32_add_2.x), there is code like the following:</p> <pre><code>[...]\nlet result_fraction = if wide_exponent &lt; u9:255 { result_fraction } else { u23:0 };\nlet result_exponent = if wide_exponent &lt; u9:255 { wide_exponent as u8 } else { u8:255 };\n</code></pre>"},{"location":"dslx_reference/#iterable-expression","title":"Iterable Expression","text":"<p>Iterable expressions are used in counted for loops. DSLX currently supports two types of iterable expressions, <code>range</code> and <code>enumerate</code>.</p> <p>The range expression <code>m..n</code> represents a range of values from m to n-1. This example will run from 0 to 4 (exclusive):</p> <pre><code>for (i, accum): (u32, u32) in u32:0..u32:4 {\n</code></pre> <p>There also exists a <code>range()</code> builtin function that performs the same operation.</p> <p><code>enumerate</code> iterates over the elements of an array type and produces pairs of <code>(index, value)</code>, similar to enumeration constructs in languages like Python or Go.</p> <p>In the example below, the loop will iterate 8 times, following the array dimension of <code>x</code>. Each iteration produces a tuple with the current index (<code>i</code> ranging from 0 to 7) and the value at the index (<code>e = x[i]</code>).</p> <pre><code>fn prefix_scan_eq(x: u32[8]) -&gt; bits[8,3] {\n  let (_, _, result) =\n    for ((i, e), (prior, count, result)): ((u32, u32), (u32, u3, bits[8,3]))\n        in enumerate(x) {...\n</code></pre>"},{"location":"dslx_reference/#for-expression","title":"for Expression","text":"<p>DSLX currently supports synthesis of \"counted\" for loops (loops that have a clear upper bound on their number of iterations). These loops are capable of being generated as unrolled pipeline stages: when generating a pipeline, the XLS compiler will unroll and specialize the iterations.</p> <p>NOTE In the future support for loops with an unbounded number of iterations may be permitted, but will only be possible to synthesize as a time-multiplexed implementation, since pipelines cannot be unrolled indefinitely.</p>"},{"location":"dslx_reference/#blueprint","title":"Blueprint","text":"<pre><code>for (index, accumulator): (type-of-index, type-of-accumulator) in iterable {\n   body-expression\n} (initial-accumulator-value)\n</code></pre> <p>The type annotation in the above \"blueprint\" is optional, but often helpful to include for increased clarity.</p> <p>Because DSLX is a pure dataflow description, a for loop is an expression that produces a value. As a result, you grab the output of a for loop just like any other expression:</p> <pre><code>let final_accum = for (i, accum) in u32:0..u32:8 {\nlet new_accum = f(accum);\nnew_accum\n}(init_accum);\n</code></pre> <p>Conceptually the for loop \"evolves\" the accumulator as it iterates, and ultimately pops it out as the result of its evaluation.</p>"},{"location":"dslx_reference/#examples","title":"Examples","text":"<p>Add up all values from 0 to 4 (exclusive). Note that we pass the accumulator's initial value in as a parameter to this expression.</p> <pre><code>for (i, accum): (u32, u32) in u32:0..u32:4 {\naccum + i\n}(u32:0)\n</code></pre> <p>To add up values from 7 to 11 (exclusive), one would write:</p> <pre><code>let base = u32:7;\nfor (i, accum): (u32, u32) in u32:0..u32:4 {\naccum + base + i\n}(u32:0)\n</code></pre> <p>\"Loop invariant\" values (values that do not change as the loop runs) can be used in the loop body, for example, note the use of <code>outer_thing</code> below:</p> <pre><code>let outer_thing: u32 = u32:42;\nfor (i, accum): (u32, u32) in u32:0..u32:4 {\naccum + i + outer_thing\n}(u32:0)\n</code></pre> <p>Both the index and accumulator can be of any valid type, in particular, the accumulator can be a tuple type, which is useful for evolving a bunch of values. For example, this for loop \"evolves\" two arrays:</p> <pre><code>for (i, (xs, ys)): (u32, (u16[3], u8[3])) in u32:0..u32:4 {\n...\n}((init_xs, init_ys))\n</code></pre> <p>Note in the above example arrays are dataflow values just like anything else. To conditionally update an array every other iteration:</p> <pre><code>let result: u4[8] = for (i, array) in u32:0..u32:8 {\n// Update every other cell with the square of the index.\nif i % 2 == 0 { update(array, i, i*i) } else { array }\n}(u4[8]:[0, ...]);\n</code></pre>"},{"location":"dslx_reference/#numerical-conversions","title":"Numerical Conversions","text":"<p>DSLX adopts the Rust rules for semantics of numeric casts:</p> <ul> <li>Casting from larger bit-widths to smaller bit-widths will truncate (to the     LSbs).     *   This means that truncating signed values does not preserve the previous         value of the sign bit.</li> <li>Casting from a smaller bit-width to a larger bit-width will zero-extend if     the source is unsigned, sign-extend if the source is signed.</li> <li>Casting from a bit-width to its own bit-width, between signed/unsigned, is a     no-op.</li> </ul> <pre><code>#[test]\nfn test_numerical_conversions() {\nlet s8_m2 = s8:-2;\nlet u8_m2 = u8:0xfe;\n// Sign extension (source type is signed).\nlet _ = assert_eq(s32:-2, s8_m2 as s32);\nlet _ = assert_eq(u32:0xfffffffe, s8_m2 as u32);\nlet _ = assert_eq(s16:-2, s8_m2 as s16);\nlet _ = assert_eq(u16:0xfffe, s8_m2 as u16);\n// Zero extension (source type is unsigned).\nlet _ = assert_eq(u32:0xfe, u8_m2 as u32);\nlet _ = assert_eq(s32:0xfe, u8_m2 as s32);\n// Nop (bitwidth is unchanged).\nlet _ = assert_eq(s8:-2, s8_m2 as s8);\nlet _ = assert_eq(s8:-2, u8_m2 as s8);\nlet _ = assert_eq(u8:0xfe, u8_m2 as u8);\nlet _ = assert_eq(s8:-2, u8_m2 as s8);\n()\n}\n</code></pre>"},{"location":"dslx_reference/#array-conversions","title":"Array Conversions","text":"<p>Casting to an array takes bits from the MSb to the LSb; that is, the group of bits including the MSb ends up as element 0, the next group ends up as element 1, and so on.</p> <p>Casting from an array to bits performs the inverse operation: element 0 becomes the MSbs of the resulting value.</p> <p>All casts between arrays and bits must have the same total bit count.</p> <pre><code>fn cast_to_array(x: u6) -&gt; u2[3] {\nx as u2[3]\n}\n\nfn cast_from_array(a: u2[3]) -&gt; u6 {\na as u6\n}\n\nfn concat_arrays(a: u2[3], b: u2[3]) -&gt; u2[6] {\na ++ b\n}\n\n#[test]\nfn test_cast_to_array() {\nlet a_value: u6 = u6:0b011011;\nlet a: u2[3] = cast_to_array(a_value);\nlet a_array = u2[3]:[1, 2, 3];\nlet _ = assert_eq(a, a_array);\n// Note: converting back from array to bits gives the original value.\nlet _ = assert_eq(a_value, cast_from_array(a));\n\nlet b_value: u6 = u6:0b111001;\nlet b_array: u2[3] = u2[3]:[3, 2, 1];\nlet b: u2[3] = cast_to_array(b_value);\nlet _ = assert_eq(b, b_array);\nlet _ = assert_eq(b_value, cast_from_array(b));\n\n// Concatenation of bits is analogous to concatenation of their converted\n// arrays. That is:\n//\n//  convert(concat(a, b)) == concat(convert(a), convert(b))\nlet concat_value: u12 = a_value ++ b_value;\nlet concat_array: u2[6] = concat_value as u2[6];\nlet _ = assert_eq(concat_array, concat_arrays(a_array, b_array));\n\n// Show a few classic \"endianness\" example using 8-bit array values.\nlet x = u32:0xdeadbeef;\nlet _ = assert_eq(x as u8[4], u8[4]:[0xde, 0xad, 0xbe, 0xef]);\nlet y = u16:0xbeef;\nlet _ = assert_eq(y as u8[2], u8[2]:[0xbe, 0xef]);\n\n()\n}\n</code></pre>"},{"location":"dslx_reference/#bit-slice-expressions","title":"Bit Slice Expressions","text":"<p>DSLX supports Python-style bit slicing over unsigned bits types. Note that bits are numbered 0..N starting \"from the right (as you would write it on paper)\" -- least significant bit, AKA LSb -- for example, for the value <code>u7:0b100_0111</code>:</p> <pre><code>    Bit    6 5 4 3 2 1 0\n  Value    1 0 0 0 1 1 1\n</code></pre> <p>A slice expression <code>[N:M]</code> means to get from bit <code>N</code> (inclusive) to bit <code>M</code> exclusive. The start and limit in the slice expression must be signed integral values.</p> <p>Aside: This can be confusing, because the <code>N</code> stands to the left of <code>M</code> in the expression, but bit <code>N</code> would be to the 'right' of <code>M</code> in the classical bit numbering. Additionally, this is not the case in the classical array visualization, where element 0 is usually drawn on the left.</p> <p>For example, the expression <code>[0:2]</code> would yield:</p> <pre><code>    Bit    6 5 4 3 2 1 0\n  Value    1 0 0 0 1 1 1\n                     ^ ^  included\n                   ^      excluded\n\n  Result:  0b11\n</code></pre> <p>Note that, as of now, the indices for this <code>[N:M]</code> form must be literal numbers (so the compiler can determine the width of the result). To perform a slice with a non-literal-number start position, see the <code>+:</code> form described below.</p> <p>The slicing operation also support the python style slices with offsets from start or end. To visualize, one can think of <code>x[ : -1]</code> as the equivalent of <code>x[from the start : bitwidth - 1]</code>. Correspondingly, <code>x[-1 : ]</code> can be visualized as <code>[ bitwidth - 1 : to the end]</code>.</p> <p>For example, to get all bits, except the MSb (from the beginning, until the top element minus 1):</p> <pre><code>x[:-1]\n</code></pre> <p>Or to get the two most significant bits:</p> <pre><code>x[-2:]\n</code></pre> <p>This results in the nice property that a the original complete value can be sliced into complementary slices such as <code>:-2</code> (all but the two most significant bits) and <code>-2:</code> (the two most significant bits):</p> <pre><code>#[test]\nfn slice_into_two_pieces() {\nlet x = u5:0b11000;\nlet (lo, hi): (u3, u2) = (x[:-2], x[-2:]);\nlet _ = assert_eq(hi, u2:0b11);\nlet _ = assert_eq(lo, u3:0b000);\n()\n}\n</code></pre>"},{"location":"dslx_reference/#width-slice","title":"Width Slice","text":"<p>There is also a \"width slice\" form <code>x[start +: bits[N]]</code> - starting from a specified bit, slice out the next <code>N</code> bits. This is equivalent to: <code>bits[N]:(x &gt;&gt; start)</code>. The type can be specified as either signed or unsigned; e.g. <code>[start +: s8]</code> will produce an 8-bit signed value starting at <code>start</code>, whereas <code>[start +: u4]</code> will produce a 4-bit unsigned number starting at <code>start</code>.</p> <p>Here are many more examples:</p>"},{"location":"dslx_reference/#bit-slice-examples","title":"Bit Slice Examples","text":"<pre><code>// Identity function helper.\nfn id&lt;N: u32&gt;(x: bits[N]) -&gt; bits[N] { x }\n\n#[test]\nfn test_bit_slice_syntax() {\nlet x = u6:0b100111;\n// Slice out two bits.\nlet _ = assert_eq(u2:0b11, x[0:2]);\nlet _ = assert_eq(u2:0b11, x[1:3]);\nlet _ = assert_eq(u2:0b01, x[2:4]);\nlet _ = assert_eq(u2:0b00, x[3:5]);\n\n// Slice out three bits.\nlet _ = assert_eq(u3:0b111, x[0:3]);\nlet _ = assert_eq(u3:0b011, x[1:4]);\nlet _ = assert_eq(u3:0b001, x[2:5]);\nlet _ = assert_eq(u3:0b100, x[3:6]);\n\n// Slice out from the end.\nlet _ = assert_eq(u1:0b1, x[-1:]);\nlet _ = assert_eq(u1:0b1, x[-1:6]);\nlet _ = assert_eq(u2:0b10, x[-2:]);\nlet _ = assert_eq(u2:0b10, x[-2:6]);\nlet _ = assert_eq(u3:0b100, x[-3:]);\nlet _ = assert_eq(u3:0b100, x[-3:6]);\nlet _ = assert_eq(u4:0b1001, x[-4:]);\nlet _ = assert_eq(u4:0b1001, x[-4:6]);\n\n// Slice both relative to the end (MSb).\nlet _ = assert_eq(u2:0b01, x[-4:-2]);\nlet _ = assert_eq(u2:0b11, x[-6:-4]);\n\n// Slice out from the beginning (LSb).\nlet _ = assert_eq(u5:0b00111, x[:-1]);\nlet _ = assert_eq(u4:0b0111, x[:-2]);\nlet _ = assert_eq(u3:0b111, x[:-3]);\nlet _ = assert_eq(u2:0b11, x[:-4]);\nlet _ = assert_eq(u1:0b1, x[:-5]);\n\n// Slicing past the end just means we hit the end (as in Python).\nlet _ = assert_eq(u1:0b1, x[5:7]);\nlet _ = assert_eq(u1:0b1, x[-7:1]);\nlet _ = assert_eq(bits[0]:0, x[-7:-6]);\nlet _ = assert_eq(bits[0]:0, x[-6:-6]);\nlet _ = assert_eq(bits[0]:0, x[6:6]);\nlet _ = assert_eq(bits[0]:0, x[6:7]);\nlet _ = assert_eq(u1:1, x[-6:-5]);\n\n// Slice of a slice.\nlet _ = assert_eq(u2:0b11, x[:4][1:3]);\n\n// Slice of an invocation.\nlet _ = assert_eq(u2:0b01, id(x)[2:4]);\n\n// Explicit-width slices.\nlet _ = assert_eq(u2:0b01, x[2+:u2]);\nlet _ = assert_eq(s3:0b100, x[3+:s3]);\nlet _ = assert_eq(u3:0b001, x[5+:u3]);\n()\n}\n</code></pre>"},{"location":"dslx_reference/#advanced-understanding-parametricity-constraints-and-unification","title":"Advanced Understanding: Parametricity, Constraints, and Unification","text":"<p>An infamous wrinkle is introduced for parametric functions: consider the following function:</p> <pre><code>// (Note: DSLX does not currently support the `T: type` construct shown here,\n// it is for example purposes only.)\nfn add_wrapper&lt;T: type, U: type&gt;(x: T, y: U) -&gt; T {\nx + y\n}\n</code></pre> <p>Based on the inference rule, we know that '+' can only type check when the operand types are the same. This means we can conclude that type <code>T</code> is the same as type <code>U</code>. Once we determine this, we need to make sure anywhere <code>U</code> is used it is consistent with the fact it is the same as <code>T</code>. In a sense the + operator is \"adding a constraint\" that <code>T</code> is equivalent to <code>U</code>, and trying to check that fact is valid is under the purview of type inference. The fact that the constraint is added that <code>T</code> and <code>U</code> are the same type is referred to as \"unification\", as what was previously two entities with potentially different constraints now has a single set of constraints that comes from the union of its operand types.</p> <p>DSLX's typechecker will go through the body of parametric functions per invocation. As such, the typechecker will always have the invocation's parametric values for use in asserting type consistency against \"constraints\" such as derived parametric expressions, body vs. annotated return type equality, and expression inference rules.</p>"},{"location":"dslx_reference/#operator-precedence","title":"Operator Precedence","text":"<p>DSLX's operator precedence matches Rust's. Listed below are DSLX's operators in descending precedence order. Binary operators at the same level share the same associativity and will be grouped accordingly.</p> Operator Associativity Unary <code>-</code> <code>!</code> n/a <code>as</code> Left to right <code>*</code> <code>/</code> <code>%</code> Left to right <code>+</code> <code>-</code> Left to right <code>&lt;&lt;</code> <code>&gt;&gt;</code> <code>&gt;&gt;&gt;</code> Left to right <code>&amp;</code> Left to right <code>^</code> Left to right <code>\\|</code> Left to right <code>==</code> <code>!=</code> <code>&lt;</code> <code>&gt;</code> <code>&lt;=</code> <code>&gt;=</code> Left to right <code>&amp;&amp;</code> Left to right <code>\\|\\|</code> Left to right"},{"location":"dslx_reference/#builtins","title":"Builtins","text":"<p>This section describes the built-in functions provided for use in the DSL that do not need to be explicitly imported.</p> <p>A note on \"Parallel Primitives\": the DSL is expected to grow additional support for use of high-level parallel primitives over time, adding operators for order-insensitive reductions, scans, groupings, and similar. By making these operations known to the compiler in their high level form, we potentially enable optimizations and analyses on their higher level (\"lifted\") form. As of now, <code>map</code> is the sole parallel-primitive-oriented built-in.</p>"},{"location":"dslx_reference/#add_with_carry","title":"<code>add_with_carry</code>","text":"<p>Operation that produces the result of the add, as well as the carry bit as an output. The binary add operators works similar to software programming languages, preserving the length of the input operands, so this builtin can assist when easy access to the carry out value is desired. Has the following signature:</p> <pre><code>fn add_with_carry&lt;N&gt;(x: uN[N], y: uN[N]) -&gt; (u1, uN[N])\n</code></pre>"},{"location":"dslx_reference/#smulp-and-umulp","title":"<code>smulp</code> and <code>umulp</code>","text":"<p><code>smulp</code> and <code>umulp</code> perform signed and unsigned partial multiplications. These operations return a two-element tuple with the property that the sum of the two elements is equal to the product of the original inputs. Performing a partial multiplication allows for a pipeline stage in the middle of a multiply. These operations have the following signatures:</p> <pre><code>fn smulp&lt;N&gt;(lhs: sN[N], rhs: sN[N]) -&gt; (sN[N], sN[N])\nfn umulp&lt;N&gt;(lhs: uN[N], rhs: uN[N]) -&gt; (uN[N], uN[N])\n</code></pre>"},{"location":"dslx_reference/#map","title":"<code>map</code>","text":"<p><code>map</code>, similarly to other languages, executes a transformation function on all the elements of an original array to produce the resulting \"mapped' array. For example: taking the absolute value of each element in an input array:</p> <pre><code>import std\n\nfn main(x: s3[3]) -&gt; s3[3] {\nlet y: s3[3] = map(x, std::abs);\ny\n}\n\n#[test]\nfn main_test() {\nlet got: s3[3] = main(s3[3]:[-1, 1, 0]);\nassert_eq(s3[3]:[1, 1, 0], got)\n}\n</code></pre> <p>Note that map is special, in that we can pass it a callee as if it were a value. As a function that \"takes\" a function as an argument, <code>map</code> is a special builtin -- in language implementor parlance it is a higher order function.</p> <p>Implementation note: Functions are not first class values in the DSL, so the name of the function must be referred to directly.</p> <p>Note: Novel higher order functions (e.g. if a user wanted to write their own <code>map</code>) cannot currently be written in user-level DSL code.</p>"},{"location":"dslx_reference/#clz-ctz","title":"<code>clz</code>, <code>ctz</code>","text":"<p>DSLX provides the common \"count leading zeroes\" and \"count trailing zeroes\" functions:</p> <pre><code>  let x0 = u32:0x0FFFFFF8;\nlet x1 = clz(x0);\nlet x2 = ctz(x0);\nlet _ = assert_eq(u32:4, x1);\nassert_eq(u32:3, x2)\n</code></pre>"},{"location":"dslx_reference/#one_hot","title":"<code>one_hot</code>","text":"<p>Converts a value to one-hot form. Has the following signature:</p> <pre><code>fn one_hot&lt;N, NP1=N+1&gt;(x: uN[N], lsb_is_prio: bool) -&gt; uN[NP1]\n</code></pre> <p>When <code>lsb_is_prio</code> is true, the least significant bit that is set becomes the one-hot bit in the result. When it is false, the most significant bit that is set becomes the one-hot bit in the result.</p> <p>When all bits in the input are unset, the additional bit present in the output value (MSb) becomes set.</p> <p>Example usage: <code>dslx/tests/one_hot.x</code>.</p> <p>See also the IR semantics for the <code>one_hot</code> op.</p>"},{"location":"dslx_reference/#signex","title":"signex","text":"<p>Casting has well-defined extension rules, but in some cases it is necessary to be explicit about sign-extensions, if just for code readability. For this, there is the <code>signex</code> builtin.</p> <p>To invoke the <code>signex</code> builtin, provide it with the operand to sign extend (lhs), as well as the target type to extend to: these operands may be either signed or unsigned. Note that the value of the right hand side is ignored, only its type is used to determine the result type of the sign extension.</p> <pre><code>#[test]\nfn test_signex() {\nlet x = u8:0xff;\nlet s: s32 = signex(x, s32:0);\nlet u: u32 = signex(x, u32:0);\nassert_eq(s as u32, u)\n}\n</code></pre> <p>Note that both <code>s</code> and <code>u</code> contain the same bits in the above example.</p>"},{"location":"dslx_reference/#slice","title":"slice","text":"<p>Array-slice builtin operation. Note that the \"want\" argument is not used as a value, but is just used to reflect the desired slice type. (Prior to constexprs being passed to builtin functions, this was the canonical way to reflect a constexpr in the type system.) Has the following signature:</p> <pre><code>fn slice&lt;T: type, N, M, S&gt;(xs: T[N], start: uN[M], want: T[S]) -&gt; T[S]\n</code></pre>"},{"location":"dslx_reference/#rev","title":"rev","text":"<p><code>rev</code> is used to reverse the bits in an unsigned bits value. The LSb in the input becomes the MSb in the result, the 2nd LSb becomes the 2nd MSb in the result, and so on.</p> <pre><code>// (Dummy) wrapper around reverse.\nfn wrapper&lt;N: u32&gt;(x: bits[N]) -&gt; bits[N] {\nrev(x)\n}\n\n// Target for IR conversion that works on u3s.\nfn main(x: u3) -&gt; u3 {\nwrapper(x)\n}\n\n// Reverse examples.\n#[test]\nfn test_reverse() {\nlet _ = assert_eq(u3:0b100, main(u3:0b001));\nlet _ = assert_eq(u3:0b001, main(u3:0b100));\nlet _ = assert_eq(bits[0]:0, rev(bits[0]:0));\nlet _ = assert_eq(u1:1, rev(u1:1));\nlet _ = assert_eq(u2:0b10, rev(u2:0b01));\nlet _ = assert_eq(u2:0b00, rev(u2:0b00));\n()\n}\n</code></pre>"},{"location":"dslx_reference/#bit_slice_update","title":"<code>bit_slice_update</code>","text":"<p><code>bit_slice_update(subject, start, value)</code> returns a copy of the bits-typed value <code>subject</code> where the contiguous bits starting at index <code>start</code> (where 0 is the least-significant bit) are replaced with <code>value</code>. The bit-width of the returned value is the same as the bit-width of <code>subject</code>. Any updated bit indices which are out of bounds (if <code>start + bit-width(value) &gt;= bit-width(subject)</code>) are ignored. Example usage: <code>dslx/tests/bit_slice_update.x</code>.</p>"},{"location":"dslx_reference/#bitwise-reduction-builtins-and_reduce-or_reduce-xor_reduce","title":"Bitwise reduction builtins: and_reduce, or_reduce, xor_reduce","text":"<p>These are unary reduction operations applied to a bits-typed value:</p> <ul> <li><code>and_reduce</code>: evaluates to bool:1 if all bits of the input are set, and 0     otherwise.</li> <li><code>or_reduce</code>: evaluates to bool:1 if any bit of the input is set, and 0     otherwise.</li> <li><code>xor_reduce</code>: evaluates to bool:1 if there is an odd number of bits set in     the input, and 0 otherwise.</li> </ul> <p>These functions return the identity element of the respective operation for trivial (0 bit wide) inputs:</p> <pre><code>#[test]\nfn test_trivial_reduce() {\nlet _ = assert_eq(and_reduce(bits[0]:0), true);\nlet _ = assert_eq(or_reduce(bits[0]:0), false);\nlet _ = assert_eq(xor_reduce(bits[0]:0), false);\n()\n}\n</code></pre>"},{"location":"dslx_reference/#update","title":"update","text":"<p><code>update(array, index, new_value)</code> returns a copy of <code>array</code> where <code>array[index]</code> has been replaced with <code>new_value</code>, and all other elements are unchanged. Note that this is not an in-place update of the array, it is an \"evolution\" of <code>array</code>. It is the compiler's responsibility to optimize by using mutation instead of copying, when it's safe to do. The compiler makes a best effort to do this, but can't guarantee the optimization is always made.</p>"},{"location":"dslx_reference/#assert_eq-assert_lt","title":"assert_eq, assert_lt","text":"<p>In a unit test pseudo function all valid DSLX code is allowed. To evaluate test results DSLX provides the <code>assert_eq</code> primitive (we'll add more of those in the future). Here is an example of a <code>divceil</code> implementation with its corresponding tests:</p> <pre><code>fn divceil(x: u32, y: u32) -&gt; u32 {\n(x-u32:1) / y + u32:1\n}\n\n#[test]\nfn test_divceil() {\nlet _ = assert_eq(u32:3, divceil(u32:5, u32:2));\nlet _ = assert_eq(u32:2, divceil(u32:4, u32:2));\nlet _ = assert_eq(u32:2, divceil(u32:3, u32:2));\nlet _ = assert_eq(u32:1, divceil(u32:2, u32:2));\n_\n}\n</code></pre> <p>Note that in this example, the final <code>let _ = ... in _</code> construct could be omitted.</p> <p><code>assert_eq</code> cannot be synthesized into equivalent Verilog. Because of that it is recommended to use it within <code>test</code> constructs (interpretation) only.</p>"},{"location":"dslx_reference/#trace_fmt","title":"trace_fmt!","text":"<p>DSLX supports printf-style debugging via the <code>trace_fmt!</code> builtin, which allows dumping of current values to stdout. For example:</p> <pre><code>// Note: to see `trace_fmt!` output you need to be seeing `INFO` level logging,\n// enabled by adding the '--alsologtostderr' flag to the command line (among\n// other means). For example:\n// bazel run -c opt //xls/dslx:interpreter_main  /path/to/dslx/file.x -- --alsologtostderr\n\nfn shifty(x: u8, y: u3) -&gt; u8 {\nlet _ = trace_fmt!(\"x: {:x} y: {}\", x, y);\n// Note: y looks different as a negative number when the high bit is set.\nlet _ = trace_fmt!(\"y as s8: {}\", y as s2);\nx &lt;&lt; y\n}\n\n#[test]\nfn test_shifty() {\nlet _ = assert_eq(shifty(u8:0x42, u3:4), u8:0x20);\nlet _ = assert_eq(shifty(u8:0x42, u3:7), u8:0);\n()\n}\n</code></pre> <p>would produce the following output, with each trace being annotated with its corresponding source position:</p> <pre><code>[...]\n[ RUN UNITTEST  ] test_shifty\nI0510 14:31:17.516227 1247677 bytecode_interpreter.cc:994] x: 42 y: 4\nI0510 14:31:17.516227 1247677 bytecode_interpreter.cc:994] y as s8: 4\nI0510 14:31:17.516227 1247677 bytecode_interpreter.cc:994] x: 42 y: 7\nI0510 14:31:17.516227 1247677 bytecode_interpreter.cc:994] y as s8: -1\n[            OK ]\n[...]\n</code></pre> <p>Note: <code>trace!</code> currently exists as a builtin but is in the process of being removed, as it provided the user with only a \"global flag\" way of specifying the desired format for output values -- <code>trace_fmt!</code> is more powerful.</p>"},{"location":"dslx_reference/#fail","title":"fail!","text":"<p>NOTE: this section describes work-in-progress functionality, currently <code>fail!</code> will only trigger in DSL interpretation (it is discarded in IR conversion). Support for converting <code>fail!</code> to XLS <code>assert</code> IR is tracked in #232 -- support for indicating the assertion was triggered in the JIT is tracked in #308</p> <p>The <code>fail!</code> builtin indicates dataflow that should not be occurring in practice. Its general signature is:</p> <pre><code>fail!(label, fallback_value)\n</code></pre> <p>The <code>fail!</code> builtin can be thought of as a \"fatal assertion macro\". It is used to annotate dataflow that should not occur in practice and, if triggered, should raise a fatal error in simulation (e.g. via a JIT-execution failure status or a Verilog assertion when running in RTL simulation).</p> <p>Note, however, that XLS will permit users to avoid inserting fatal-error-signaling hardware that correspond to this <code>fail!</code> -- assuming it will not be triggered in practice minimizes its cost in synthesized form. In this situation, when it is \"erased\", it acts as the identity function, propagating the <code>fallback_value</code>. This allows XLS to keep well defined semantics even when fatal assertion hardware is not present.</p> <p>Example: if only these two enum values shown should be possible (say, as a documented precondition for <code>main</code>):</p> <pre><code>enum EnumType: u2 {\nFIRST = 0,\nSECOND = 1,\n}\n\nfn main(x: EnumType) -&gt; u32 {\nmatch x {\nEnumType::FIRST =&gt; u32:0,\nEnumType::SECOND =&gt; u32:1,\n_ =&gt; fail!(\"unknown_EnumType\", u32:0),\n}\n}\n</code></pre> <p>The <code>fail!(\"unknown_EnumType\", u32:0)</code> above indicates that a) that match arm should not be reached (and if it is in the JIT or RTL simulation it will cause an error status or assertion failure respectively), but b) provides a fallback value to use (of the appropriate type) in case it were to happen in synthesized gates which did not insert fatal-error-indicating hardware.</p> <p>The associated label (the first argument) must be a valid Verilog identifier and is used for identifying the failure when lowered to SystemVerilog. At higher levels in the stack, it's unused.</p>"},{"location":"dslx_reference/#cover","title":"cover!","text":"<p>NOTE: Currently, <code>cover!</code> has no effect in RTL simulators supported in XLS open source (i.e. iverilog). See google/xls#436.</p> <p>The <code>cover!</code> builtin tracks how often some condition is satisfied. It desugars into SystemVerilog cover points. Its signature is:</p> <pre><code>cover!(&lt;name&gt;, &lt;condition&gt;);\n</code></pre> <p>Where <code>name</code> is a function-unique literal string identifying the coverpoint and <code>condition</code> is a boolean element. When <code>condition</code> is true, a counter with the given name is incremented that can be inspected upon program termination. Coverpoints can be used to give an indication of code \"coverage\", i.e. to see what paths of a design are exercised in practice. The name of the coverpoint must begin with either a letter or underscore, and its remainder must consist of letters, digits, underscores, or dollar signs.</p>"},{"location":"dslx_reference/#gate","title":"gate!","text":"<p>The <code>gate!</code> builtin is used for operand gating, of the form:</p> <pre><code>let gated_value = gate!(&lt;pass_value&gt;, &lt;value&gt;);\n</code></pre> <p>This will generally use a special Verilog macro to avoid the underlying synthesis tool doing boolean optimization, and will turn <code>gated_value</code> to <code>0</code> when the predicate <code>pass_value</code> is <code>false</code>. This can be used in attempts to manually avoid toggles based on the gating predicate.</p> <p>It is expected that XLS will grow facilities to inserting gating ops automatically, but manual user insertion is a practical step in this direction. Additionally, it is expected that if, in the resulting Verilog, gating occurs on a value that originates from a flip flop, the operand gating may be promoted to register-based load-enable gating.</p>"},{"location":"dslx_reference/#testing-and-debugging","title":"Testing and Debugging","text":"<p>DSLX allows specifying tests right in the implementation file via the <code>test</code> and <code>quickcheck</code> directives.</p> <p>Having key test code in the implementation file serves two purposes. It helps to ensure the code behaves as expected. Additionally it serves as 'executable' documentation, similar in spirit to Python doc strings.</p>"},{"location":"dslx_reference/#unit-tests","title":"Unit Tests","text":"<p>Unit tests are specified by the <code>test</code> directive, as seen below:</p> <pre><code>#[test]\nfn test_reverse() {\nlet _ = assert_eq(u1:1, rev(u1:1));\nlet _ = assert_eq(u2:0b10, rev(u2:0b01));\nlet _ = assert_eq(u2:0b00, rev(u2:0b00));\n()\n}\n</code></pre> <p>The DSLX interpreter will execute all functions that are proceeded by a <code>test</code> directive. These functions should be non-parametric, take no arguments, and should return a unit-type.</p> <p>Unless otherwise specified in the implementation's build configs, functions called by unit tests are also converted to XLS IR and run through the toolchain's LLVM JIT. The resulting values from the DSLX interpreter and the LLVM JIT are compared against each other to assert equality. This is to ensure DSLX implementations are IR-convertable and that IR translation is correct.</p>"},{"location":"dslx_reference/#quickcheck","title":"QuickCheck","text":"<p>QuickCheck is a testing framework concept founded on property-based testing. Instead of specifying expected and test values, QuickCheck asks for properties of the implementation that should hold true against any input of the specified type(s). In DSLX, we use the <code>quickcheck</code> directive to designate functions to be run via the toolchain's QuickCheck framework. Here is an example that complements the unit testing of DSLX's <code>rev</code> implementation from above:</p> <pre><code>// Reversing a value twice gets you the original value.\n\n#[quickcheck]\nfn prop_double_reverse(x: u32) -&gt; bool {\nx == rev(rev(x))\n}\n</code></pre> <p>The DSLX interpreter will also execute all functions that are proceeded by a <code>quickcheck</code> directive. These functions should be non-parametric and return a <code>bool</code>. The framework will provide randomized input based on the types of the arguments to the function (e.g. above, the framework will provided randomized <code>u32</code>'s as <code>x</code>).</p> <p>By default, the framework will run the function against 1000 sets of randomized inputs. This default may be changed by specifying the <code>test_count</code> key in the <code>quickcheck</code> directive before a particular test:</p> <pre><code>#[quickcheck(test_count=50000)]\n</code></pre> <p>The framework also allows programmers to specify a seed to use in generating the random inputs, as opposed to letting the framework pick one. The seed chosen for production can be found in the execution log.</p> <p>For determinism, the DSLX interpreter should be run with the <code>seed</code> flag: <code>./interpreter_main --seed=1234 &lt;DSLX source file&gt;</code></p> <ol> <li> <p>Otherwise there'd be a use-before-definition error.\u00a0\u21a9</p> </li> </ol>"},{"location":"dslx_std/","title":"Standard Library","text":"<p>This page documents the DSLX standard library.</p> <ul> <li>Standard Library</li> <li>std.x<ul> <li>std::bounded_minus_1</li> <li>std::abs</li> <li>std::is_pow2</li> <li>std::?mul</li> <li>std::iterative_div</li> <li>std::div_pow2</li> <li>std::mod_pow2</li> <li>std::ceil_div</li> <li>std::round_up_to_nearest</li> <li>std::?pow</li> <li>std::clog2</li> <li>std::?max</li> <li>std::umin</li> <li>Signed comparison</li> <li>std::find_index</li> <li>std::lsb</li> <li>std::convert_to_bits</li> <li>std::mask_bits</li> <li>std::concat3</li> <li>std::rrot</li> </ul> </li> <li>acm_random.x<ul> <li>acm_random::rng_deterministic_seed</li> <li>acm_random::rng_new</li> <li>acm_random::rng_next</li> <li>acm_random::rng_next64</li> </ul> </li> </ul>"},{"location":"dslx_std/#stdx","title":"<code>std.x</code>","text":""},{"location":"dslx_std/#stdbounded_minus_1","title":"<code>std::bounded_minus_1</code>","text":"<pre><code>pub fn bounded_minus_1&lt;N: u32&gt;(x: uN[N]) -&gt; uN[N]\n</code></pre> <p>Returns the value of <code>x - 1</code> with saturation at <code>0</code>.</p>"},{"location":"dslx_std/#stdabs","title":"<code>std::abs</code>","text":"<pre><code>pub fn abs&lt;BITS: u32&gt;(x: sN[BITS]) -&gt; sN[BITS]\n</code></pre> <p>Returns the absolute value of <code>x</code> as a signed number.</p>"},{"location":"dslx_std/#stdis_pow2","title":"<code>std::is_pow2</code>","text":"<pre><code>pub fn is_pow2&lt;N: u32&gt;(x: uN[N]) -&gt; bool\n</code></pre> <p>Returns true when x is a non-zero power-of-two.</p>"},{"location":"dslx_std/#stdmul","title":"<code>std::?mul</code>","text":"<pre><code>pub fn umul&lt;N: u32, M: u32, R: u32 = N + M&gt;(x: uN[N], y: uN[M]) -&gt; uN[R]\npub fn smul&lt;N: u32, M: u32, R: u32 = N + M&gt;(x: sN[N], y: sN[M]) -&gt; sN[R]\n</code></pre> <p>Returns product of <code>x</code> (<code>N</code> bits) and <code>y</code> (<code>M</code> bits) as an <code>N+M</code> bit value.</p>"},{"location":"dslx_std/#stditerative_div","title":"<code>std::iterative_div</code>","text":"<pre><code>pub fn iterative_div&lt;N: u32, DN: u32 = N * u32:2&gt;(x: uN[N], y: uN[N]) -&gt; uN[N]\n</code></pre> <p>Calculate <code>x / y</code> one bit at a time. This is an alternative to using the division operator '/' which may not synthesize nicely.</p>"},{"location":"dslx_std/#stddiv_pow2","title":"<code>std::div_pow2</code>","text":"<pre><code>pub fn div_pow2&lt;N: u32&gt;(x: bits[N], y: bits[N]) -&gt; bits[N]\n</code></pre> <p>Returns <code>x / y</code> where <code>y</code> must be a non-zero power-of-two.</p>"},{"location":"dslx_std/#stdmod_pow2","title":"<code>std::mod_pow2</code>","text":"<pre><code>pub fn mod_pow2&lt;N: u32&gt;(x: bits[N], y: bits[N]) -&gt; bits[N]\n</code></pre> <p>Returns <code>x % y</code> where <code>y</code> must be a non-zero power-of-two.</p>"},{"location":"dslx_std/#stdceil_div","title":"<code>std::ceil_div</code>","text":"<pre><code>pub fn ceil_div&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; uN[N]\n</code></pre> <p>Returns the ceiling of (x divided by y).</p>"},{"location":"dslx_std/#stdround_up_to_nearest","title":"<code>std::round_up_to_nearest</code>","text":"<pre><code>pub fn round_up_to_nearest(x: u32, y: u32) -&gt; u32\n</code></pre> <p>Returns <code>x</code> rounded up to the nearest multiple of <code>y</code>.</p>"},{"location":"dslx_std/#stdpow","title":"<code>std::?pow</code>","text":"<pre><code>pub fn upow&lt;N: u32&gt;(x: uN[N], n: uN[N]) -&gt; uN[N]\npub fn spow&lt;N: u32&gt;(x: sN[N], n: uN[N]) -&gt; sN[N]\n</code></pre> <p>Performs integer exponentiation as in Hacker's Delight, Section 11-3. Only non-negative exponents are allowed, hence the uN parameter for spow.</p>"},{"location":"dslx_std/#stdclog2","title":"<code>std::clog2</code>","text":"<pre><code>pub fn clog2&lt;N: u32&gt;(x: bits[N]) -&gt; bits[N]\n</code></pre> <p>Returns <code>ceiling(log2(x))</code>, with one exception: When <code>x = 0</code>, this function differs from the true mathematical function: <code>clog2(0) = 0</code> where as <code>ceil(log2(0)) = -infinity</code></p> <p>This function is frequently used to calculate the number of bits required to represent <code>x</code> possibilities. With this interpretation, it is sensible to define <code>clog2(0) = 0</code>.</p> <p>Example: <code>clog2(7) = 3</code>.</p>"},{"location":"dslx_std/#stdmax","title":"<code>std::?max</code>","text":"<pre><code>pub fn smax&lt;N: u32&gt;(x: sN[N], y: sN[N]) -&gt; sN[N]\npub fn umax&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; uN[N]\n</code></pre> <p>Returns the maximum of two integers.</p>"},{"location":"dslx_std/#stdumin","title":"<code>std::umin</code>","text":"<pre><code>pub fn umin&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; uN[N]\n</code></pre> <p>Returns the minimum of two unsigned integers.</p>"},{"location":"dslx_std/#signed-comparison","title":"<code>Signed comparison</code>","text":"<pre><code>pub fn sge&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; bool\npub fn sgt&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; bool\npub fn sle&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; bool\npub fn slt&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; bool\n</code></pre> <p>Explicit signed comparison helpers for working with unsigned values, can be a bit more convenient and a bit more explicit intent than doing casting of left hand side and right hand side.</p>"},{"location":"dslx_std/#stdfind_index","title":"<code>std::find_index</code>","text":"<pre><code>pub fn find_index&lt;BITS: u32, ELEMS: u32&gt;( array: uN[BITS][ELEMS], x: uN[BITS]) -&gt; (bool, u32)\n</code></pre> <p>Returns (<code>found</code>, <code>index</code>) given an array and the element to find within the array.</p> <p>Note that when <code>found</code> is false, the <code>index</code> is <code>0</code> -- <code>0</code> is provided instead of a value like <code>-1</code> to prevent out-of-bounds accesses from occurring if the index is used in a match expression (which will eagerly evaluate all of its arms), to prevent it from creating an error at simulation time if the value is ultimately discarded from the unselected match arm.</p>"},{"location":"dslx_std/#stdlsb","title":"<code>std::lsb</code>","text":"<pre><code>pub fn lsb&lt;N: u32&gt;(x: uN[N]) -&gt; u1\n</code></pre> <p>Extracts the LSB (Least Significant Bit) from the value <code>x</code> and returns it.</p>"},{"location":"dslx_std/#stdconvert_to_bits","title":"<code>std::convert_to_bits</code>","text":"<pre><code>pub fn convert_to_bits&lt;N: u32&gt;(x: bool[N]) -&gt; uN[N]\n</code></pre> <p>Converts an array of <code>N</code> bools to a <code>bits[N]</code> value.</p> <p>Note well: the boolean value at index 0 of the array becomes the most significant bit in the resulting bit value. Similarly, the last index of the array becomes the least significant bit in the resulting bit value.</p> <pre><code>import std\n\n#[test]\nfn convert_to_bits_test() {\nlet _ = assert_eq(u3:0b001, convert_to_bits(bool[3]:[false, false, true]));\nlet _ = assert_eq(u3:0b100, convert_to_bits(bool[3]:[true, false, false]));\n()\n}\n</code></pre> <p>There's always a source of confusion in these orderings:</p> <ul> <li>Mathematically we often indicate the least significant digit as \"digit 0\"</li> <li>But, in a number as we write the digits from left-to-right on a piece of   paper, if you made an array from the written characters, the digit at \"array   index 0\" would be the most significant bit.</li> </ul> <p>So, it's somewhat ambiguous whether \"index 0\" in the array would become the least significant bit or the most significant bit. This routine uses the \"as it looks on paper\" conversion; e.g. <code>[true, false, false]</code> becomes <code>0b100</code>.</p>"},{"location":"dslx_std/#stdmask_bits","title":"<code>std::mask_bits</code>","text":"<pre><code>pub fn mask_bits&lt;X: u32&gt;() -&gt; bits[X]\n</code></pre> <p>Returns a value with X bits set (of type bits[X]).</p>"},{"location":"dslx_std/#stdconcat3","title":"<code>std::concat3</code>","text":"<pre><code>pub fn concat3&lt;X: u32, Y: u32, Z: u32, R: u32 = X + Y + Z&gt;(x: bits[X], y: bits[Y], z: bits[Z]) -&gt; bits[R]\n</code></pre> <p>Concatenates 3 values of arbitrary bitwidths to a single value.</p>"},{"location":"dslx_std/#stdrrot","title":"<code>std::rrot</code>","text":"<pre><code>pub fn rrot&lt;N: u32&gt;(x: bits[N], y: bits[N]) -&gt; bits[N]\n</code></pre> <p>Rotate <code>x</code> right by <code>y</code> bits.</p>"},{"location":"dslx_std/#acm_randomx","title":"<code>acm_random.x</code>","text":"<p>Port of ACM random number generator to DSLX.</p> <p>DO NOT use <code>acm_random.x</code> for any application where security -- unpredictability of subsequent output and previous output -- is needed. ACMRandom is in NO WAY a cryptographically secure pseudorandom number generator, and using it where recipients of its output may wish to guess earlier/later output values would be very bad.</p>"},{"location":"dslx_std/#acm_randomrng_deterministic_seed","title":"<code>acm_random::rng_deterministic_seed</code>","text":"<pre><code>pub fn rng_deterministic_seed() -&gt; u32\n</code></pre> <p>Returns a fixed seed for use in the random number generator.</p>"},{"location":"dslx_std/#acm_randomrng_new","title":"<code>acm_random::rng_new</code>","text":"<pre><code>pub fn rng_new(seed: u32) -&gt; State\n</code></pre> <p>Create the state for a new random number generator using the given seed.</p>"},{"location":"dslx_std/#acm_randomrng_next","title":"<code>acm_random::rng_next</code>","text":"<pre><code>pub fn rng_next(s: State) -&gt; (State, u32)\n</code></pre> <p>Returns a pseudo-random number in the range <code>[1, 2^31-2]</code>.</p> <p>Note that this is one number short on both ends of the full range of non-negative 32-bit integers, which range from <code>0</code> to <code>2^31-1</code>.</p>"},{"location":"dslx_std/#acm_randomrng_next64","title":"<code>acm_random::rng_next64</code>","text":"<pre><code>pub fn rng_next(s: State) -&gt; (State, u64)\n</code></pre> <p>Returns a pseudo random number in the range <code>[1, (2^31-2)^2]</code>.</p> <p>Note that this does not cover all non-negative values of int64, which range from <code>0</code> to <code>2^63-1</code>. The top two bits are ALWAYS ZERO.</p>"},{"location":"floating_point/","title":"Floating-point routines","text":"<p>XLS provides implementations of several floating-point operations and may add more at any time. Here are listed notable details of our implementations or of floating-point operations in general. Unless otherwise specified, not possible or out-of-scope, all operations and types should be IEEE-754 compliant.</p> <p>For example, floating-point exceptions have not been implemented; they're outside our current scope. The numeric results of multiplication, on the other hand, should exactly match those of any other compliant implementation.</p>"},{"location":"floating_point/#apfloat","title":"APFloat","text":"<p>Floating-point operations are, in general, defined by the same sequence of steps regardless of their underlying bit widths: fractional parts must be expanded then aligned, then an operation (add, multiply, etc.) must be performed, interpreting the fractions as integral types, followed by rounding, special case handling, and reconstructing an output FP type.</p> <p>This observation leads to the possibility of generic floating-point routines: a fully parameterized add, for example, which can be instantiated with and 8-bit exponent and 23-bit fractional part for binary32 types, and an 11-bit exponent and 52-bit fractional part for binary64 types. Even more interesting, a hypothetical bfloat32 type could immediately be supported by, say, instantiating that adder with, say, 15 exponent bits and 16 fractional ones.</p> <p>As much as possible, XLS implements FP operations in terms of its <code>APFloat</code> (arbitrary-precision floating-point) type. <code>APFloat</code> is a parameterized floating-point structure with a fixed one-bit sign and specifiable exponent and fractional part size. For ease of use, common types, such as <code>float32</code>, are defined in terms of those <code>APFloat</code> types.</p> <p>For example, the generic \"is X infinite\" operation is defined in <code>apfloat.x</code> as:</p> <pre><code>// Returns whether or not the given APFloat represents an infinite quantity.\npub fn is_inf&lt;EXP_SZ:u32, FRACTION_SZ:u32&gt;(x: APFloat&lt;EXP_SZ, FRACTION_SZ&gt;) -&gt; u1 {\n(x.bexp == std::mask_bits&lt;EXP_SZ&gt;() &amp;&amp; x.fraction == bits[FRACTION_SZ]:0)\n}\n</code></pre> <p>Whereas in <code>float32.x</code>, <code>F32</code> is defined as:</p> <pre><code>pub type F32 = apfloat::APFloat&lt;u32:8, u32:23&gt;;\n</code></pre> <p>and <code>is_inf</code> is exposed as:</p> <pre><code>pub fn is_inf(f: F32) -&gt; u1 { apfloat::is_inf&lt;u32:8, u32:23&gt;(f) }\n</code></pre> <p>In this way, users can refer to <code>F32</code> types and can use them as and with <code>float32::is_inf(f)</code>, giving them simplified access to a generic operation.</p> <p>More complex functionality such as addition and multiplication are defined in standalone modules, e.g, <code>apfloat_add_2.x</code> defining <code>apfloat_add_2::add</code> for the <code>APFloat</code> type <code>fp32_add_2.x</code> instantiating the operation for the <code>float32</code> type.</p>"},{"location":"floating_point/#supported-operations","title":"Supported operations","text":"<p>Here are listed the routines so far implemented in XLS. Unless otherwise specified, operations are implemented in terms of APFloats such that they can support any precisions (aside from corner cases, such as a zero-byte fractional part).</p>"},{"location":"floating_point/#operation-details","title":"Operation details","text":""},{"location":"floating_point/#addsub","title":"Add/sub","text":"<p>Floating-point addition, like any FP operation, is much more complicated than integer addition, and has many more steps. Being the first operation described, we'll take extra care to explain floating-point addition:</p> <ol> <li>Expand fractions: Floating-point operations are computed with bits     beyond that in their normal representations for increased precision. For     IEEE 754 numbers, there are three extra, called the guard, rounding and     sticky bits. The first two behave normally, but the last, the \"sticky\" bit,     is special. During shift operations (below), if a \"1\" value is ever shifted     into the sticky bit, it \"sticks\" - the bit will remain \"1\" through any     further shift operations. In this step, the fractions are expanded by these     three bits.</li> <li>Align fractions: To ensure that fractions are added with appropriate     magnitudes, they must be aligned according to their exponents. To do so, the     smaller significant needs to be shifted to the right (each right shift is     equivalent to increasing the exponent by one).     -   The extra precision bits are populated in this shift.     -   As part of this step, the leading 1 bit... and a sign bit Note: The         sticky bit is calculated and applied in this step.</li> <li>Sign-adjustment: if the fractions differ in sign, then the fraction with     the smaller initial exponent needs to be (two's complement) negated.</li> <li>Add the fractions and capture the carry bit. Note that, if the signs of     the fractions differs, then this could result in higher bits being cleared.</li> <li>Normalize the fractions: Shift the result so that the leading '1' is     present in the proper space. This means shifting right one place if the     result set the carry bit, and to the left some number of places if high bits     were cleared.     -   The sticky bit must be preserved in any of these shifts!</li> <li>Rounding: Here, the extra precision bits are examined to determine if     the result fraction's last bit should be rounded up. IEEE 754 supports five     rounding modes:     -   Round towards 0: just chop off the extra precision bits.     -   Round towards +infinity: round up if any extra precision bits are set.     -   Round towards -infinity: round down if any extra precision bits are set.     -   Round to nearest, ties away from zero: Rounds to the nearest value. In         cases where the extra precision bits are halfway between values, i.e.,         0b100, then the result is rounded up for positive numbers and down for         negative ones.     -   Round to nearest, ties to even: Rounds to the nearest value. In cases         where the extra precision bits are halfway between values, then the         result is rounded in whichever direction causes the LSB of the result         significant to be 0.         -   This is the most commonly-used rounding mode.         -   This is [currently] the only supported mode by the DSLX             implementation.</li> <li>Special case handling: The results are examined for special cases such     as NaNs, infinities, or (optionally) subnormals.</li> </ol>"},{"location":"floating_point/#result-sign-determination","title":"Result sign determination","text":"<p>The sign of the result will normally be the same as the sign of the operand with the greater exponent, but there are two extra cases to consider. If the operands have the same exponent, then the sign will be that of the greater fraction, and if the result is 0, then we favor positive 0 vs. negative 0 (types are as for a C <code>float</code> implementation):</p> <pre><code>  let fraction = (addend_x as s29) + (addend_y as s29);\nlet fraction_is_zero = fraction == s29:0;\nlet result_sign = match (fraction_is_zero, fraction &lt; s29:0) {\n(true, _) =&gt; u1:0,\n(false, true) =&gt; !greater_exp.sign,\n_ =&gt; greater_exp.sign,\n};\n</code></pre>"},{"location":"floating_point/#rounding","title":"Rounding","text":"<p>As complicated as rounding is to describe, its implementation is relatively straightforward (types are as for a C <code>float</code> implementation):</p> <pre><code>  let normal_chunk = shifted_fraction[0:3];\nlet half_way_chunk = shifted_fraction[2:4];\nlet do_round_up =\nu1:1 if (normal_chunk &gt; u3:0x4) | (half_way_chunk == u2:0x3)\nelse u1:0;\n\n// We again need an extra bit for carry.\nlet rounded_fraction = (shifted_fraction as u28) + u28:0x8 if do_round_up\nelse (shifted_fraction as u28);\nlet rounding_carry = rounded_fraction[-1:];\n</code></pre>"},{"location":"floating_point/#mul","title":"Mul","text":"<p>TODO(rspringer): 2021-04-06: This.</p>"},{"location":"floating_point/#fma","title":"FMA","text":"<p>The <code>fma</code> operation (again, fused multiply-add) is a three-operand operation that computes the product of the first two and the sum of that with the third. The IEEE 754-2008 description of the operation states that the operation should be performed \"as if with unbounded range and precision\", limited only by rounding of the final result. In other words, this differs from a sequence of a separate multiply followed by an add in that there is only a single rounding step (instead of the two involved in separate operations).</p> <p>In practice, this means A) that the precision of an FMA is higher than individual ops, and thus that B) an FMA requires significantly more internal precision bits than naively expected.</p> <p>For binary32 inputs, to achieve the standard-specified precision, the initial mul requires the usual 48 ((23 fraction + 1 \"hidden\") * 2) fraction bits. When performing the subsequent add step, though, it is necessary to maintain 72 fraction bits ((23 fraction + 1 \"hidden\") * 3). Fortunately, this sum includes the guard, round, and sticky bits (so we don't need 75). The mathematical derivation of the exact amount will not be given here (as I've not done it), but the same calculated size would apply for other data types (i.e., 54 * 2 = 108 and 54 * 3 = 162 for binary64).</p> <p>Aside from determining the necessary precision bits, the FMA implementation is rather straightforward, especially after reviewing the adder and multiplier.</p>"},{"location":"floating_point/#testing","title":"Testing","text":"<p>Several different methods are used to test these routines, depending on applicability. These are:</p> <ul> <li>Reference comparison: exhaustive testing</li> <li>Reference comparison: space-sampling</li> <li>Formal proving</li> </ul> <p>When comparing to a reference, a natural question is the stability of the reference, i.e., is the reference answer the same across all versions or environments? Will the answer given by glibc/libm on AArch64 be the same as one given by a hardware FMA unit on a GPU? Fortunately, all \"correct\" implementations will give the same results for the same inputs.* In addition, POSIX has the same result-precision language. It's worth noting that -ffast-math doesn't currently affect FMA emission/fusion/fission/etc.</p> <p>* - There are operations for which this is not true. Transcendental ops may differ between implementations due to the table maker's dilemma.</p>"},{"location":"floating_point/#exhaustive-testing","title":"Exhaustive testing","text":"<p>This is the happiest case - where the input space is so small that we can iterate over every possible input, effectively treating the input as a binary iteration counter. Sadly, this is uncommon (except, perhaps for ML math), as binary32 is the precision floor for most problems, and a 64-bit input space is well beyond our current abilities. Still - if your problem can be exhaustively tested (with respect to a trusted reference), it should be exhaustively tested!</p> <p>None of our current ops are tested in this way, although the bf16 cases could/should be.</p>"},{"location":"floating_point/#space-sampling","title":"Space-sampling","text":"<p>When the problem input space is too large for exhaustive testing, then random samples can be tested instead. This approach can't give complete verification of an implementation, but, given enough samples, it can yield a high degree of confidence.</p> <p>The existing modules are tested in this way. This could be improved by preventing re-testing of any given sample (at the cost of memory and, perhaps, atomic/locking costs) and by identifying interesting \"corner cases\" of the input space and focusing on those.</p>"},{"location":"floating_point/#formal-verification","title":"Formal verification","text":"<p>This sort of testing utilizes our formal solver infrastructure to prove correctness with the solver's internal FP implementation. This is fully described in the solvers documentation.</p>"},{"location":"fpga_characterization/","title":"FPGA Characterization","text":"<p>Note that right now the in-tree yosys and nextpnr-ice40 builds plugins aren't registering properly, see issue #188. As a result, we have to use out-of-tree <code>yosys</code> and <code>nextpnr-ice40</code> builds for the moment.</p> <pre><code>$ bazel build -c opt //xls/synthesis/yosys:yosys_server_main\n$ ./bazel-bin/xls/synthesis/yosys/yosys_server_main \\\n    --yosys_path $(which yosys) \\\n    --nextpnr_path $(which nextpnr-ice40) \\\n    --synthesis_target=ice40 \\\n    --alsologtostderr\n</code></pre> <p>The above runs a gRPC service, so in another terminal pane, we run the characterization driver:</p> <pre><code>$ bazel run -c opt //xls/synthesis:timing_characterization_client_main\n$ ./bazel-bin/xls/synthesis/timing_characterization_client_main \\\n    &gt; ./xls/delay_model/models/ice40.textproto\n</code></pre> <p>This produces a textual representation of the delay model protobuf.</p>"},{"location":"fpga_characterization/#building-in-tree-binaries","title":"Building In-Tree Binaries","text":"<p>Note that these cannot currently be used for the above characterization flow, see issue #188</p> <p>Build <code>yosys</code> and <code>nextpnr-ice40</code>:</p> <pre><code>$ bazel build -c opt @at_clifford_yosys//:yosys @nextpnr//:nextpnr-ice40\n</code></pre>"},{"location":"fuzzer/","title":"XLS Fuzzer","text":"<ul> <li>XLS Fuzzer<ul> <li>Crashers Directory<ul> <li>Single-file reproducers</li> </ul> </li> <li>IR minimization</li> <li>Summaries</li> <li>Debugging a failing sample<ul> <li>Debugging a tool crash</li> <li>Result miscomparison: unoptimized IR</li> <li>Result miscomparison: optimized IR<ul> <li>Debugging the LLVM JIT</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>To execute the XLS fuzz driver simply run a command line like the following:</p> <pre><code>bazel run -c opt \\\n  //xls/fuzzer:run_fuzz_multiprocess \\\n  -- --crash_path=/tmp/crashers-$(date +'%Y-%m-%d') --seed=0 --duration=8h\n</code></pre> <p>The XLS fuzzer generates a sequence of randomly generated DSLX functions and a set of random inputs to each function often with interesting bit patterns.</p> <p>Given that stimulus, the fuzz driver performs the following actions some of which may be disabled/enabled via flags (run with <code>--help</code> for more details):</p> <ul> <li>Runs the DSLX program through the DSLX interpreter with the batch of     arguments</li> <li>Converts the DSLX program to IR</li> <li>Optimizes the converted IR</li> <li>Interprets the pre-optimized and optimized IR with the batch of arguments</li> <li>Generates the Verilog from the IR with randomly selected codegen options</li> <li>Simulates the generated Verilog using the batch of arguments</li> <li>Performs a multi-way comparison of the DSLX interpreter results, the     pre-optimized IR interpreter results, post-optimized IR interpreter results,     and the simulator results</li> <li>If an issue is observed, the fuzz driver attempts to minimize the IR that     causes an issue to occur.</li> </ul> <p>The above actions are coordinated and run by the SampleRunner class. Many actions are performed by invoking a separate binary which isolates any crashes.</p> <p>When miscompares in results occur or the generated function crashes part of XLS, all artifacts generated by the fuzzer for that sample are written into a uniquely-named subdirectory under the <code>--crash_path</code> given in the command line. The fuzzer also writes a crasher file which is a single file for reproducing the issue. See below for instructions on debugging a failing sample.</p>"},{"location":"fuzzer/#crashers-directory","title":"Crashers Directory","text":"<p>The crashers directory includes a subdirectory created for each failing sample. To avoid collisions the subdirectory is named using a hash of the DSLX code. Each crasher subdirectory has the following contents:</p> <pre><code>$ ls /tmp/crashers-2019-06-25/05adbd50\nargs.txt                   ir_converter_main.stderr   run.sh\ncl.txt                     ir_minimizer.options.json  sample.ir\ncrasher_2020-04-23_9b05.x  ir_minimizer_test.sh       sample.ir.results\neval_ir_main.stderr        options.json               sample.x\nexception.txt              opt_main.stderr            sample.x.results\n</code></pre> <p>The directory includes the problematic DSLX sample (<code>sample.x</code>) and the input arguments (<code>args.txt</code>) as well as all artifacts generated and stderr output emitted by the various utilities invoked to test the sample. Notable files include:</p> <ul> <li><code>options.json</code> : Options used to run the sample.</li> <li><code>sample.ir</code> : Unoptimized IR generated from the DSLX sample.</li> <li><code>sample.opt.ir</code> : IR after optimizations.</li> <li><code>sample.v</code> : Generated Verilog.</li> <li><code>*.results</code> : The results (numeric values) produced by interpreting or     simulating the respective input (DSLX, IR, or Verilog).</li> <li><code>exception.txt</code> : The exception raised when running the sample. Typically     this will indicate either a result miscomparison or a tool return non-zero     status (for example, the IR optimizer crashed).</li> <li><code>crasher_*.x</code>: A single file reproducer which includes the DSLX code,     arguments, and options. See below for details.</li> </ul> <p>Typically the exact nature of the failure can be identified by reading the file <code>exception.txt</code> and possibly the stderr outputs of the various tools.</p> <p>The fuzzer can optionally produce a minimized IR reproduction of the problem. This will be written to <code>minimized.ir</code>. See below for details.</p>"},{"location":"fuzzer/#reproducers","title":"Single-file reproducers","text":"<p>When the fuzzer encounters an issue it will create a single-file reproducer:</p> <pre><code>--- Worker 14 observed an exception, noting\n--- Worker 14 noted crasher #1 for sampleno 42 at /tmp/crashers/095fb405\n</code></pre> <p>Copying that file to the directory <code>//xls/fuzzer/crashers</code> will automatically create a bazel test target for it and add it to the regression suite. Tests can also be added as known failures in <code>//xls/fuzzer/build_defs.bzl</code> as they're being triaged / investigated like so:</p> <pre><code>generate_crasher_regression_tests(\n    srcs = glob([\"crashers/*\"]),\n    prefix = \"xls/fuzzer\",\n    # TODO(xls-team): 2019-06-30 Triage and fix these.\n    failing = [\n        \"crashers/crasher_2019-06-29_129987.x\",\n        \"crashers/crasher_2019-06-29_402110.x\",\n    ],\n)\n</code></pre> <p>Known-failures are marked as manual and excluded from continuous testing.</p> <p>To run the regression suite:</p> <pre><code>bazel test //xls/fuzzer:all\n</code></pre> <p>To run the regression suite including known-failures, run the regression target directly:</p> <pre><code>bazel test //xls/fuzzer:regression_tests\n</code></pre> <p>To reproduce from that single-file reproducer there is a command line tool:</p> <pre><code>bazel run //xls/fuzzer:run_crasher -- \\\n  crasher_2019-06-26_3354.x\n</code></pre>"},{"location":"fuzzer/#minimization","title":"IR minimization","text":"<p>By default the fuzzer attempts to generate a minimal IR reproducer for the problem identified by the DSLX sample. Starting with the unoptimized IR the fuzzer invokes <code>ir_minimizer_main</code> to reduce the size of the input IR. It uses various simplification strategies to minimize the number of nodes in the IR. See the usage description in the tool source code for detailed information.</p> <p>The minimized IR is written to a file <code>minimized.ir</code> in the crasher directory for the sample. Note that minimization is only possible if the problem (crash, result miscomparison, etc.) occurs after conversion from DSLX to XLS IR.</p>"},{"location":"fuzzer/#summaries","title":"Summaries","text":"<p>To monitor progress of the fuzzer and to determine op coverage the fuzzer can optionally (with <code>--summary_path</code>) write summary information to files. The summary files are Protobuf files containing the proto <code>SampleSummaryProto</code> defined in <code>//xls/fuzzer/sample_summary.proto</code>. The summary information about the IR generated from the DSLX sample such as the number and type of each IR op as well as the bit width and number of operands.</p> <p>The summary information also includes a timing breakdown of the various operations performed for each sample (sample generation, IR conversion, etc). This can be used to identify performance bottlenecks in the fuzzer.</p> <p>The summaries can be read with the tool <code>//xls/fuzzer/read_summary_main</code>. See usage description in the code for more details.</p>"},{"location":"fuzzer/#debugging","title":"Debugging a failing sample","text":"<p>A generated sample can fail in one of two ways: a tool crash or a result miscomparison. A tool crash occurred if one of the tools invoked by the fuzzer (e.g., <code>opt_main</code> which optimizes the IR) returned a non-zero status. A result miscomparison occurred if there is not perfect correspondence between the results produced by various ways in which the generated function is evaluated:</p> <ol> <li>Interpreted DSLX</li> <li>Evaluated unoptimized IR</li> <li>Evaluated optimized IR</li> <li>Simulation of the generated (System)Verilog</li> </ol> <p>Generally, the results produced by the interpretation of the DSLX serves are the reference results for comparisons.</p> <p>To identify the underlying cause of the sample failure inspect the <code>exception.txt</code> file in the crasher directory. The file contains the text of the exception raised in <code>SampleRunner</code> which clearly identifies the kind of failure (result miscomparison or tool crash) and details about which evaluation resulted in a miscompare or which tool crashed, respectively. Consult the following sections on how to debug particular kinds of failures.</p>"},{"location":"fuzzer/#debugging-a-tool-crash","title":"Debugging a tool crash","text":"<p>The <code>exception.txt</code> file includes the invocation of the tool for reproducing the failure. Generally, this is a straightforward debugging process.</p> <p>If the failing tool is the IR optimizer binary <code>opt_main</code> the particular pass causing the failure should be in the backtrace. To retrieve the input to this pass, run <code>opt_main</code> with <code>--ir_dump_path</code> to dump the IR between each pass. The last IR file produced (the files are numbered sequentially) is the input to the failing pass.</p>"},{"location":"fuzzer/#result-miscomparison-unoptimized-ir","title":"Result miscomparison: unoptimized IR","text":"<p>The evaluation of the unoptimized IR is the first point at which result comparison occurs (DSLX interpretation versus unoptimized IR evaluation). A miscomparison here can indicate a bug in one of several places:</p> <ol> <li>DSLX interpreter</li> <li>DSLX to IR conversion</li> <li>IR interpreter or IR JIT. The error message in <code>exception.txt</code> indicates     whether the JIT or the interpreter was used.</li> </ol> <p>To help narrow this down, the IR interpreter can be compared against the JIT with the <code>eval_ir_main</code> tool:</p> <pre><code>  eval_ir_main --test_llvm_jit --input_file=args.txt sample.ir\n</code></pre> <p>This runs both the JIT and the interpreter on the unoptimized IR file (<code>sample.ir</code>) using the arguments in <code>args.txt</code> and compares the results. If this is successful, then likely the IR interpreter and the JIT are correct and problem lies earlier in the pipeline (DSLX interpretation or DSLX to IR conversion). Otherwise, there is definitely a bug in either the interpreter or the JIT as their results should always be equal.</p> <p>If a minimized IR file exists (<code>minimized.ir</code>) this may be a better starting point for isolating the failure.</p>"},{"location":"fuzzer/#result-miscomparison-optimized-ir","title":"Result miscomparison: optimized IR","text":"<p>This can indicate a bug in IR evaluation (interpreter or JIT) or in the optimizer. In this case, a comparison of the evaluation of the unoptimized IR against the DSLX interpreter has already succeeds so DSLX interpretation or conversion is unlikely to be the underlying cause.</p> <p>As with miscomparison involving the unoptimized IR, <code>eval_ir_main</code> can be used to compare the JIT results against the interpreter results:</p> <pre><code>  eval_ir_main --test_llvm_jit --input_file=args.txt sample.opt.ir\n</code></pre> <p>If the above invocation fails there is a bug in the JIT or the interpreter. Otherwise, there may be a bug in the optimizer. The tool <code>eval_ir_main</code> can help isolate the problematic optimization pass by running with the options <code>--optimize_ir</code> and <code>--eval_after_each_pass</code>. With these flags, the tool runs the optimization pipeline on the given IR and evaluates the IR after each pass is run. The first pass which results in a miscompare against the unoptimized input IR is flagged. Invocation:</p> <pre><code>  eval_ir_main --input_file=args.txt \\\n    --optimize_ir \\\n    --eval_after_each_pass \\\n    sample.ir\n</code></pre>"},{"location":"fuzzer/#debugging-the-llvm-jit","title":"Debugging the LLVM JIT","text":"<p>To help isolate bugs in the JIT, LLVM's optimization level can be set using the <code>--llvm_opt_level</code> flag:</p> <pre><code>  eval_ir_main --test_llvm_jit \\\n    --llvm_opt_level=0 \\\n    --input_file=args.txt sample.opt.ir\n</code></pre> <p>If the results match (pass) with the optimization level set to zero but fail with the default optimization level of 3, there is likely a bug in the LLVM optimizer or the XLS-generated LLVM program has undefined behavior.</p> <p>Unoptimized and optimized LLVM IR are dumped by the JIT with vlog level of 2 or higher, and the assembly is dumped at level 3 or higher. For example:</p> <pre><code>  eval_ir_main -v=3 --logtostderr --random_inputs=1 sample.opt.ir\n</code></pre> <p>Extract the unoptimized LLVM IR to file to enable working with it in isolation. Copy the text from <code>Optimized module IR:</code> to <code>Generated ASM:</code> into <code>sample.ll</code>. Execute the following command to remove the logging prefix text. <pre><code>  sed -i 's/^.*\\] //g' sample.ll```\n\n##### Building LLVM tools\n\nThe various LLVM tools such as `opt` and `lli` can be built with:\n</code></pre>   bazel build /llvm/llvm-project/llvm:all <pre><code>Build in fastbuild mode to get checks and debug features in LLVM.\n\n##### Isolating the bug\n\nTo inspect the optimized LLVM IR, run:\n</code></pre>   opt sample.ll -O3 -S <pre><code>To print the IR before and after each pass:\n</code></pre>  opt sample.ll -S -print-after-all -print-before-all -O3 <pre><code>##### Instcombine\n\nInstcombine is an LLVM optimization pass which is a common source of bugs in\ncode generated from XLS. To run instcombine alone:\n</code></pre>  opt /tmp/bad.ll -S -passes=instcombine <pre><code>Instcombine is a large monolithic pass and it can be difficult to isolate the\nexact transformation which caused the problem. Fortunately, this pass includes a\n\"compiler fuel\" option which can be used to limit the number of transformations\nperformed by the pass. Example usage (fastbuild of LLVM is required):\n</code></pre> opt -S --instcombine sample.ll --debug-counter=instcombine-visit-skip=0,instcombine-visit-count=42 <pre><code>##### Evaluating LLVM IR\n\nThe LLVM tool `lli` evaluates LLVM IR. The tool expects the IR to include a\nentry function `main`. See the uploaded file in this\n[LLVM bug](https://bugs.llvm.org/show_bug.cgi?id=45762) for an example LLVM IR\nfile which includes a main function that calls a (slightly modified)\nXLS-generated function.\n\nThe LLVM tool `opt` optimizes the LLVM IR and can be piped to `lli` like so:\n</code></pre>   opt sample.ll --O2 | lli <pre><code>##### Building LLVM at head\n\nAlthough the internal Google mirror of LLVM is updated frequently, prior to\nfiling an LLVM bug it's a good idea to verify the failure against LLVM head.\nSteps to build:\n</code></pre> git clone https://github.com/llvm/llvm-project.git cd llvm mkdir build cd build cmake -G Ninja ../llvm/ cmake --build . -- opt <pre><code>### Result miscomparison: simulated Verilog\n\nThis can be a bug in codegen, XLS's Verilog testbench code, or the Verilog\nsimulator itself. Running the generated Verilog with different simulators can\nhelp isolate the problem:\n</code></pre>   simulate_module_main --signature_file=module_sig.textproto \\     --args_file=args.txt \\     --verilog_simulator=iverilog \\     sample.v</p> <p>simulate_module_main --signature_file=module_sig.textproto \\     --args_file=args.txt \\     --verilog_simulator=${SIM_2} \\     sample.v ```</p> <p>The tool outputs the results of the evaluation to stdout so diffing their outputs is required.</p>"},{"location":"ideas_and_projects/","title":"Ideas and Projects","text":"<p>This document lists a few sample ideas, projects, and research ideas, to help get started on contributing to XLS.</p>"},{"location":"ideas_and_projects/#programming-languages","title":"Programming Languages","text":""},{"location":"ideas_and_projects/#xls-new-frontends","title":"XLS New Frontends","text":"<p>One of XLS' primary core focus areas was defining a compiler intermediate representation that is powerful enough to express all required concepts, but minimal enough to make it easy to target from other, new, or modified programming languages. We are focusing on a functional domain-specific language, but others are possible. There is work to target the IR from C++. There are many other research systems out there with their own respective DSLs and other input mechanisms. It would be interesting to connect those to allow comparisons. An embedded DSL in Python could be developed, which is straightforward as the IR's builder interfaces are already exported to Python.</p>"},{"location":"ideas_and_projects/#core-xls","title":"Core XLS","text":""},{"location":"ideas_and_projects/#ml-for-delay-estimation","title":"ML for Delay Estimation","text":"<p>We currently estimate the delay of ops and op combos via benchmarks and the theory of logical efforts. In principle we are trying to guess what the commercial toolchains will do. This is a problem that seems to be just made for ML, especially for new technology nodes or FPGA devices.</p>"},{"location":"ideas_and_projects/#delay-estimation-for-a-variety-of-devices","title":"Delay Estimation for a variety of Devices","text":"<p>We are focusing on only a small number of FPGAs and very specific ASIC Flows. For the lager community out there we should add many more models, improve automation of deriving a delay model, and/or try ML based approaches.</p>"},{"location":"ideas_and_projects/#delay-estimation-for-implicit-broadcasts","title":"Delay Estimation for Implicit Broadcasts","text":"<p>HLS often creates implicit broadcasts (wire load / fan out / wiring congestion) in unrolled loops, deep pipelines, large memory blocks, etc. that lead to frequency bottlenecks. Modeling these broadcasts in the delay model can help mitigate or even completely solve such problems.</p>"},{"location":"ideas_and_projects/#z3","title":"Z3","text":"<p>We use Z3 for our logical equivalence checking, eg., to check that the optimized and unoptimized IR have the same semantics. With a solver like this in place, there are many more opportunities to apply it or make it more practical, for example.</p> <ul> <li>(Automatic) Partitioning of the input IR to reduce per-phase problem space</li> <li>Add / compare with other formal verification tools.</li> <li>There are other alternatives, e.g. Boolector</li> <li>Use cases we haven't thought of yet.</li> </ul>"},{"location":"ideas_and_projects/#design-verification-flows","title":"Design Verification Flows","text":"<p>Provide mechanisms for \"constrained random\" approaches to hardware verification -- either libraries to emulate capabilities of constraint-based vector generation similar to UVM, or more automated approaches provided by QuickCheck/Hypothesis.</p>"},{"location":"ideas_and_projects/#implement-new-blocks-and-functions-in-xls","title":"Implement new blocks and functions in XLS","text":""},{"location":"ideas_and_projects/#extend-xls-standard-library","title":"Extend XLS standard library","text":"<p>XLS has a small standard library which includes some basic utility functions and some limited floating point support. Extending this library and developing more complex functionality would improve the usability of XLS. Ideas:</p> <ul> <li>FP Libraries Implement libraries for important FP operations, modes, widths,     with all the relevant parameters. BFloat libraries</li> <li>Fixed point libraries, similar to above</li> <li>Exploit FPGA hard macros and BRAMs</li> </ul> <p>XLS implementations of common hardware libraries - arbiters - counters - encoders - fifos</p>"},{"location":"ideas_and_projects/#three-stage-risc-v","title":"Three-stage RISC-V","text":"<p>Piccolo is a 3-stage RISC-V core. Implementation appears of reasonable size.</p> <ul> <li>IF: ISA / Instruction Fetch / Decode Unit</li> <li>DM: Data Memory stage</li> <li>WB: Write Back stage</li> <li>ALU</li> <li>add/sub unit, mul unit, shifter unit</li> <li>PLIC / Platform Level Interrupts architecture</li> <li>Cache Hierarchy with various sizes, associativity, and replacement policies</li> <li>MMU and L1-Cache</li> <li>CSRs</li> <li>Register File</li> </ul>"},{"location":"ideas_and_projects/#support-for-systolic-arrays-as-a-parallel-pattern","title":"Support for Systolic Arrays as a \"Parallel Pattern\"","text":"<p>It is clear, especially in the domain of machine learning and signal processing, that HLS will benefit from full support of 2D elements, such as systolic arrays or specialized convolution engines. The idea here is to abstract these properly. For example, one could add constructs to the IR, or we can extend the analysis capabilities and add passes to construct them as needed. We also have to make sure that the mechanisms are fully supported by all optimization and code generation passes. This is a fascinating and wide-open research area and intersects with the current work on concurrent blocks.</p>"},{"location":"ideas_and_projects/#interoperability-with-other-languages-ffi","title":"Interoperability with other languages, FFI","text":"<p>Users may want to reuse building blocks written in other languages that are pre-optimized. Support proper FFI. Instantiate external blocks by specifying their properties in a way the scheduler can understand. Import type definitions from system verilog descriptions e.g. as encoded in protobufs</p>"},{"location":"ideas_and_projects/#xls-tools","title":"XLS Tools","text":""},{"location":"ideas_and_projects/#visualization","title":"Visualization","text":"<p>XLS includes some minimal visualization and exploration tools. There is large potential for tool builders to improve and add information, insights, suggestions, etc.</p>"},{"location":"ideas_and_projects/#source-correlation","title":"Source Correlation","text":"<p>It is always important to maintain a high level of productivity and utility for a toolset like XLS provides. Source correlation, annotations, and many other techniques are always improvable the enhance the debugging, visualization, and also design verification experiences.</p>"},{"location":"ideas_and_projects/#source-analysis","title":"Source Analysis","text":"<p>A linter/style checker for the DSL would be very helpful for users to write high-quality HLS code.</p>"},{"location":"ideas_and_projects/#xls-integration-with-other-tools","title":"XLS Integration with other tools","text":""},{"location":"ideas_and_projects/#add-verilator-support-to-xls","title":"Add Verilator support to XLS","text":"<p>Verilator is a strong open-source (System)Verilog simulator. Currently XLS only supports Icarus Verilog, a Verilog-only simulator. Verilator support in XLS will provide much higher simulation performance and SystemVerilog support to open source users. Unlike other simulators which can run testbench code, Verilator only operates on synthesizable Verilog and emits C++ code for compilation and execution. This unique flow needs to be integrating into XLS's simulation framework.</p>"},{"location":"interpreters/","title":"Interpreters","text":"<p>XLS provides a several interpreters to assist in design validation across our functional stack, from input DSLX down to the netlist level.</p> <ul> <li>Interpreters<ul> <li>DSLX<ul> <li>Execution comparison</li> </ul> </li> <li>IR</li> <li>Netlists</li> </ul> </li> </ul>"},{"location":"interpreters/#dslx","title":"DSLX","text":"<p>The DSLX interpreter (<code>//xls/dslx:interpreter_main</code>) operates on DSLX <code>.x</code> files that contain both the design and unit tests to execute (present as <code>#[test]</code> annotated functions).</p> <p>The adler32 example demonstrates this: the design is encapsulated in the <code>main</code>, <code>adler32_seq</code>, and <code>mod</code> functions, and the samples are present in the test <code>adler32_one_char</code> (note that unit-style tests/interpretations of <code>adler32_seq</code> and <code>mod</code> could also be present).</p> <p>Interpreter targets are automatically generated for <code>dslx_test()</code> targets, so no special declarations are necessary to wrap DSLX code.</p> <p>To invoke these samples, execute the following:</p> <pre><code>bazel build -c opt //xls/examples:adler32_dslx_test\n./bazel-bin/xls/examples/adler32_dslx_test\n</code></pre> <p>To execute directly via the interpreter, you can instead run:</p> <pre><code>$ bazel build -c opt //xls/dslx/interpreter_main\n$ ./bazel-bin/xls/dslx/interpreter_main \\\n    ./xls/examples/adler32.x\n</code></pre> <p>These two methods are equivalent.</p>"},{"location":"interpreters/#execution-comparison","title":"Execution comparison","text":"<p>The DSL interpreter provides a flag, <code>--compare</code>, to implicitly compare its run results to those of the IR-converted DSL functions. This helps \"spot check\" consistency between IR and DSL execution (in addition to other methods used in more generally in XLS, like the fuzzer).</p> <p>The user may compare DSL execution to IR interpreter execution, IR JIT execution, or not perform IR comparison at all.</p> <pre><code>$ ./bazel-bin/xls/dslx/interpreter_main \\\n./xls/examples/adler32.x --compare=jit\n$ ./bazel-bin/xls/dslx/interpreter_main \\\n./xls/examples/adler32.x --compare=interpreter\n$ ./bazel-bin/xls/dslx/interpreter_main \\\n./xls/examples/adler32.x --compare=none\n</code></pre>"},{"location":"interpreters/#ir","title":"IR","text":"<p>XLS provides two means of evaluating IR - interpretation and native host compilation (the JIT). Both are invoked in nearly the same way, via the <code>eval_ir_main</code> tool.</p> <p><code>eval_ir_main</code> supports a wide number of use cases, but the most common end-user case will be to run a sample through a design. To evaluate a sample (1.0 + 2.5) on the floating-point adder, one would run the following:</p> <pre><code>bazel build -c opt //xls/tools:eval_ir_main\n./bazel-bin/xls/tools/eval_ir_main \\\n  --input '(bits[1]: 0x0, bits[8]:0x7F, bits[23]:0x0); (bits[1]: 0x0, bits[8]:0x80, bits[23]:0x200000)' \\\n  ./xls/modules/fp/fp32_add_2.x\n</code></pre> <p>By default, this runs via the JIT. To use the interpreter, add the <code>--use_llvm_jit=false</code> flag to the invocation.</p> <p><code>eval_ir_main</code> supports a broad set of options and modes of execution. Refer to its [very thorough] <code>--help</code> documentation for full details.</p>"},{"location":"interpreters/#netlists","title":"Netlists","text":"<p>Finally, compiled netlists can also be interpreted against input samples via the aptly-named <code>netlist_interpreter_main</code> tool. This tool currently only supports single sample evaluation (as illustrated in the IR section above):</p> <pre><code>bazel build -c opt //xls/tools:netlist_interpreter_main\n./bazel-bin/xls/tools/netlist_interpreter_main \\\n  --netlist &lt;path to netlist&gt;\n  --module  &lt;module to evaluate&gt;\n  --cell_library[_proto] &lt;path to the module's cell library [proto]&gt;\n  --inputs  &lt;input sample, as above&gt;\n</code></pre> <p>As XLS does not currently provide an sample/example netlist (TODO(rspringer)), concrete values can't [yet] be provided here. The <code>--cell_library</code> flag merits extra discussion, though.</p> <p>During netlist compilation, a cell library is provided to indicate the individual logic cells available for the design, and these cells are referenced in the output netlist. The interpreter needs a description of these cells' behaviors/functions, so the cell library must be provided here, as well. Many cell libraries are very large (&gt; 1GB), and can thus incur significant processing overhead at startup, so we also accept pre-processed cell libraries, as <code>CellLibraryProto</code> messages, that contain much-abridged cell descriptions. The <code>function_extractor_main</code> tool can automatically perform this extraction for Liberty-formatted cell library descriptions.</p>"},{"location":"ir_jit/","title":"IR JIT Compiler","text":"<ul> <li>IR JIT Compiler<ul> <li>Usage<ul> <li>Specialized matching</li> <li>Direct usage</li> </ul> </li> <li>Design<ul> <li>Arg passing</li> <li>ArrayIndex</li> </ul> </li> <li>main() generator<ul> <li>Usage</li> <li>Design<ul> <li>Output type determination</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>XLS provides a JIT compiler for evaluating functions written in the [XLS] compiler intermediate representation (IR) at native machine speed.</p>"},{"location":"ir_jit/#usage","title":"Usage","text":"<p>Given a DSLX file and build target, one can build and run it through the JIT by:</p> <ol> <li>Declaring a     <code>cc_xls_ir_jit_wrapper</code>     target matching the DSLX build target.</li> <li>Creating a JIT object and calling its <code>Run()</code> method. Using the 2-way     floating-point adder as an example:<pre><code> # include \"xls/modules/fpadd_2x24_jit_wrapper.h\"\n\nabsl::StatusOr&lt;Value&gt; foo(Value a, Value b) {\n...\n// Only create this once and re-use it; it's created here just as\n// an illustration.\nXLS_ASSIGN_OR_RETURN(Fpadd2x32 adder, Fpadd2x32::Create()); return\nadder.Run(a, b);\n}\n</code></pre> </li> </ol> <p>The advantages of JIT compilation (or any compilation, for that matter) only come into play when repeatedly using the compiled object, so programs should be structured to create a JIT wrapper once and to reuse it many times, e.g., to test a module across many - or even exhaustively, across all possible - inputs.</p>"},{"location":"ir_jit/#specialized-matching","title":"Specialized matching","text":"<p>In many cases, the types used by DSLX designs map to native types, such as the C/C++ <code>float</code>. In that case, a simplified wrapper call is available:</p> <pre><code>#include \"xls/modules/fpadd_2x24_jit_wrapper.h\"\n\nabsl::StatusOr&lt;float&gt; foo(float a, float b) {\n  ...\n  // Only create this once and re-use it; it's created here just as\n  // an illustration.\n  XLS_ASSIGN_OR_RETURN(Fpadd2x32 adder, Fpadd2x32::Create());\n  return adder.Run(a, b);\n}\n</code></pre> <p>When available, these simplified wrappers should be used for higher performance (~30% in our measured cases). Currently, floats and integral types &gt;= 64 bits in this way. For non-native integral types, the generated wrapper will accept the next larger native type e.g., <code>uint64_t</code> for <code>bits[47]</code>. Proper operation with next-larger types depends on the input value being present in the least-significant bits of the containing type.</p> <p>These are higher performance because they avoid unnecessary marshaling of these types into Views (e.g., a <code>float</code> outside the JIT -&gt; View -&gt; <code>float</code> inside the JIT).</p>"},{"location":"ir_jit/#direct-usage","title":"Direct usage","text":"<p>The JIT is also available as a library with a straightforward interface:</p> <pre><code>absl::StatusOr&lt;Value&gt; RunOnJit(\n    Function* function, absl::Span&lt;const Value&gt; args) {\n  XLS_ASSIGN_OR_RETURN(auto jit, FunctionJit::Create(function));\n  return jit-&gt;Run(args);\n}\n</code></pre> <p>The IR JIT is the default backend for the eval_ir_main tool, which loads IR from disk and runs with args present on either the command line or in a specified file.</p>"},{"location":"ir_jit/#design","title":"Design","text":"<p>Internally, the JIT converts XLS IR to LLVM IR and uses LLVM's ORC infrastructure to convert that into native machine code. The details of compiling an LLVM IR program with ORC are mostly generic and are available online - here are discussed details specific to our usage in XLS.</p> <p>XLS IR is converted to LLVM IR by recursively visiting every node in a function using the DfsVisitor functions. Most nodes have relatively straightforward implementations, e.g., in Concat, we create an empty value with the combined width of the operands, and each is shifted and blitted into that value to produce the result. Some operations, though, merit more discussion.</p>"},{"location":"ir_jit/#arg-passing","title":"Arg passing","text":"<p>When LLVM JIT-compiles a program, the resulting value is simply a function pointer to the requested entry point (that can be called like any function pointer). Calling such a function pointer with concrete-typed arguments, though, is difficult: one must either make heavy [ab]use of C++ templates or \"hide\" the argument types behind an opaque pointer. The latter approach is taken here.</p> <p>When a compiled function is invoked (via <code>FunctionJit::Run()</code>), the typed input args are \"packed\" into an opaque byte buffer which is passed into the new function. Inside there, any references to an argument (via <code>DfsVisitor::HandleParam()</code>) calculate the offset of that param in the opaque buffer and load from there appropriately (this should happen at most once per arg; LLVM and/or XLS should optimize away redundant loads).</p> <p>A special case is for function invocations (inside the JITted function): for these, the arguments already exist inside \"LLVM-space\", so there's no need for unpacking args, so <code>LlvmFunction::getArg()</code> can be used as usual.</p> <p>Results must be handled in a similar way - they could be of any type and will need to be packed inside XLS types before returning, so there's a corresponding argument unpacking phase at function exit.</p> <p>For both packing and unpacking, LLVM's DataLayout must be used to determining where input and output values will be placed, as LLVM will use those conventions when, e.g., loading values from a struct.</p>"},{"location":"ir_jit/#arrayindex","title":"ArrayIndex","text":"<p>IRBuilder provides three means of extracting values from an aggregate type:</p> <ol> <li><code>CreateGEP</code>: these use the getelementptr instruction, which requires a     pointer-typed value (not the same thing as an array!). This requires holding     a value in a specially-created allocation (via <code>CreateAlloca()</code> or in an     input buffer).</li> <li><code>CreateExtractElement</code>: returns the value at a given index in a     vector-typed value.</li> <li><code>CreateExtractValue</code>: returns the value at a given constant index in an     aggregate value.</li> </ol> <p>Unfortunately, #2 doesn't apply, as arrays aren't LLVM vectors, and #3 doesn't apply, as an array index isn't necessarily a constant value. Uniformly managing arrays as allocas doesn't scale well (consider the case of arrays of arrays of tuples...), so for <code>ArrayIndex</code> nodes, we lazily create allocas for only the array of interest and load the requested index from there.</p>"},{"location":"ir_jit/#main-generator","title":"<code>main()</code> generator","text":"<p>The IR JIT finds more than its share of LLVM bugs, in large part due to XLS' use of fuzzing, which often generates bit widths not often found in software, e.g. a 231-bit wide integer, which won't be emitted by Clang (as it's not a native C type). To ensure that any mismatches between the JIT and the IR interpreter are correctly triaged, it's important to compare results between the JIT and LLVM-provided tools, e.g., lli or llc, the LLVM IR interpreter and compiler, respectively.</p> <p>Both lli and llc execute self-contained LLVM IR programs, i.e., those with an <code>int main(int argc, char** argv)</code> entry point - the JIT does not produce these (as they're not part of a hardware description). To avoid the need to manually edit the JIT-produced IR (which experience has shown to be very error prone), we can generate a <code>main</code> driver function for our samples.</p>"},{"location":"ir_jit/#usage_1","title":"Usage","text":"<p>To generate and execute a <code>main</code> for LLVM IR produced by the JIT, run the following:</p> <pre><code>$ bazel build //xls/tools:llvm_main_generator \\\n              //xls/tools:run_llvm_main\n$ ./bazel-bin/xls/tools/llvm_main_generator \\\n  -entry_function &lt;Mangled IR function name&gt; \\\n  -input &lt;Path to file containing JIT-generated LLVM IR&gt; \\\n  -output &lt;Path to write output&gt;\n$ ./bazel-bin/xls/tools/run_llvm_main \\\n  &lt;Output path from above&gt; \\\n  &lt;Input values as string-formatted XLS Values&gt;\n</code></pre> <p>For a concrete example:</p> <pre><code>$ bazel-bin/xls/tools/llvm_main_generator \\\n  -entry_function \"sample::__sample__main\" \\\n  -input ~/fuzz/mismatch/sample.opt.ll \\\n  -output ./foo.ll\n$ bazel-bin/xls/tools/run_llvm_main \\\n  ./foo.ll \\\n  bits[56]:0x800_0000_0000 \\\n  bits[66]:0x4000_0000 \\\n  bits[7]:0x1 \\\n  bits[2]:0x3 \\\n  bits[12]:0x0 \\\n  bits[74]:0x3c5_482a_0984_e061_1a90\nbits[74]:0x3ff_ffc5_482a_0984_e061\n</code></pre> <p>The final line is the result of running the sample.</p> <p>If the value mismatch occurs both in the IR JIT evaluation as well as lli evaluation, then there's likely a bug in LLVM. A main-annotated IR sample is suitable for attaching to an LLVM bug report (on http://bugs.llvm.org) as a reproducer, along with the input to generate the mismatch.</p>"},{"location":"ir_jit/#design_1","title":"Design","text":"<p>The main generator, at a high level, uses the LLVM tools (namely IRBuilder) to create a <code>main()</code> function to:</p> <ol> <li>Examine its command-line parameters to determine their overall size and to     them into the input buffer (as in Arg Passing above).</li> <li>Invoke the entry function (which remains unchanged from the source emitted     by the JIT).</li> <li>Unpack the output buffer after the entry function completes and print its     contents.</li> </ol> <p>For arg packing/unpacking, the functions provided by JitRuntime are used, but in a stateless context wrapped in an <code>extern \"C\"</code> space, to simplify invocation from within LLVM IR.</p>"},{"location":"ir_jit/#output-type-determination","title":"Output type determination","text":"<p>Inferring the computation's output type merits special discussion. While it's trivial for the main generator to detect the output type, it's very difficult to do so inside the executing <code>main()</code> - in the former, the type is real data, wherein the latter, it's metadata.</p> <p>To make this possible (without doing down an RTTI rabbit hole, or even simply requiring the user to specify it on the command line), we do the following:</p> <ol> <li>Determine the <code>llvm::Type</code> of the output.</li> <li>Convert that into an <code>xls::Type</code>, and capture that type as a String.</li> <li>Hardcode that string as a constant in the emitted <code>main()</code> function.</li> <li>At runtime, pass that type string into <code>UnpackAndPrintBuffer()</code> (one of the     <code>extern \"C\"</code> function wrappers).</li> <li>Inside <code>UnpackAndPrintBuffer()</code>, parse that string (via     <code>xls::Parser::ParseType()</code>), and use the resulting <code>xls::Type</code> to determine     the contents of the computation's output buffer.</li> </ol>"},{"location":"ir_lowering/","title":"XLS: IR Lowering","text":"<ul> <li>XLS: IR Lowering<ul> <li>Flattening<ul> <li>Arrays</li> <li>Tuples</li> <li>Structs</li> </ul> </li> <li>Unrepresented Ops</li> </ul> </li> </ul> <p>As part of codegen, IR constructs are lowered to Verilog/SystemVerilog constructs. In some cases, this lowering is simple and direct, but some IR constructs don't map directly to Verilog constructs.</p>"},{"location":"ir_lowering/#flattening","title":"Flattening","text":"<p>Some XLS types are flattened into simpler types when IR gets lowered to RTL. This flattening is performed here (also see the more-commented header file). The following summarizes how types are flattened.</p>"},{"location":"ir_lowering/#arrays","title":"Arrays","text":"<p>Arrays are flattened such that the last element occupies the most significant bits. Elements are concatenated via the SystemVerilog concatenation operation. This matches the flattening of SystemVerilog packed arrays (e.g. <code>logic [N:0] foo</code>) to unpacked arrays declared like <code>logic bar[N:0]</code>. For example, a 4-element array of 4-bit UInts would be flattened as</p> <pre><code>[0x3, 0x4, 0x5, 0x6] =&gt; 0x6543\n</code></pre>"},{"location":"ir_lowering/#tuples","title":"Tuples","text":"<p>Tuples are flattened by concatenating each leaf element of the tuple. If an element of a tuple is an array, this is equivalent to first flattening the array and treating the flattened array as a leaf element. Concatenation is performed via the SystemVerilog concatenation operation. The zero-th tuple element will end up occupying the most significant bits in the flattened output. For example, a 4-tuple of 4-bit UInts would be flattened as</p> <pre><code>(0x3, 0x4, 0x5, 0x6) =&gt; 0x3456\n</code></pre> <p>and a 2-tuple of length 2 arrays of 4-bit UInts would be flattened as</p> <pre><code>([0x3, 0x4], [0x5, 0x6]) =&gt; 0x4365\n</code></pre>"},{"location":"ir_lowering/#structs","title":"Structs","text":"<p>DSLX structs are lowered to tuples in the IR, so there's no separate handling of structs.</p>"},{"location":"ir_lowering/#unrepresented-ops","title":"Unrepresented Ops","text":"<p>Tokens are not represented in RTL.</p> <p>Entities with zero width are unrepresented in RTL. Where a zero-width value is used, a zero-valued literal can be substituted.</p> <p>Asserts and covers are only represented when producing SystemVerilog, and are unrepresented when producing Verilog.</p>"},{"location":"ir_overview/","title":"XLS: IR Overview","text":"<ul> <li>XLS: IR Overview</li> </ul> <p>Before providing a detailed specification of the IR, in this section we briefly outline the ideas and philosophy behind the IR design and explain how to build, modify, and navigate the IR.</p> <p>The XLS IR is a dataflow-oriented IR that has the static-single-assignment (SSA) property, but is specialized for generating circuitry. It started out as a purely functional IR but over time more and more side-effecting operations had to be introduced. Specifically:</p> <ul> <li>XLS has a single IR representation which is used from the front-end down to     the RTL-level. A single representation throughout the compiler enables     maximal resuse of analysis and transformation components. Often compilers     have different specialized IRs (or \"dialects\") for different levels of     abstraction which can add complexity and inhibit reusability. However, in     XLS this tradeoff between specialization and reusability is unnecessary     because we start with a dataflow representation in the front end and can     smoothly lower the IR down to the RTL-level which is itself dataflow.</li> </ul> <ul> <li>XLS IR is not control-flow graph (CFG) based, as many other compiler     infrastructures. The insight is that the CFG abstraction was developed to     model serial execution on a CPU. In hardware, however, everything happens at     all times and in parallel. A sea-of-nodes (SoN) representation much more     closely resembles this reality, which is why we have chosen it.<p>It further turns out that many optimization passes are rather trivial to   implement in the SoN representation, in particular as it requires no   explicit SSA updates. The SSA property is automatically maintained by the IR   being functional.</p> </li> </ul> <p>TODO: High-level structure, package -&gt; func,proc,block -&gt; sea of nodes</p> <p>TODO: How to navigate</p> <p>TODO: Talk about basic types</p>"},{"location":"ir_semantics/","title":"XLS: IR semantics","text":"<ul> <li>XLS: IR semantics<ul> <li>Data types<ul> <li>Bits</li> <li>Array</li> <li>Tuple</li> <li>Token</li> </ul> </li> <li>Functions, procs, and blocks<ul> <li>Function</li> <li>Proc</li> <li>Block<ul> <li>Port</li> <li>Register</li> <li>Instantiation</li> </ul> </li> </ul> </li> <li>Operations<ul> <li>Unary bitwise operations</li> <li>Variadic bitwise operations</li> <li>Arithmetic unary operations</li> <li>Arithmetic binary operations</li> <li>Comparison operations</li> <li>Shift operations</li> <li>Extension operations<ul> <li>zero_ext</li> <li>sign_ext</li> </ul> </li> <li>Channel operations<ul> <li>receive</li> <li>send</li> </ul> </li> <li>Array operations<ul> <li>array</li> <li>array_index</li> <li>array_update</li> </ul> </li> <li>Tuple operations<ul> <li>tuple</li> <li>tuple_index</li> </ul> </li> <li>Bit-vector operations<ul> <li>bit_slice</li> <li>bit_slice_update</li> <li>dynamic_bit_slice</li> <li>concat</li> <li>reverse</li> <li>decode</li> <li>encode</li> <li>one_hot</li> </ul> </li> <li>Control-oriented operations<ul> <li>param</li> <li>sel</li> <li>one_hot_sel</li> <li>priority_sel</li> <li>invoke</li> <li>map</li> <li>dynamic_counted_for</li> <li>counted_for</li> </ul> </li> <li>Sequencing operations<ul> <li>after_all</li> </ul> </li> <li>Other side-effecting operations<ul> <li>assert</li> <li>cover</li> <li>gate</li> </ul> </li> <li>RTL-level operations<ul> <li>input_port</li> <li>output_port</li> <li>register_read</li> <li>register_write</li> <li>instantiation_input</li> <li>instantiation_output</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>The XLS IR is a pure dataflow-oriented IR that has the static-single-assignment property, but is specialized for generating circuitry. The aim is to create effective circuit designs through a \"lifted\" understanding of the high-level operations and their semantics, instead of trying to reverse all relevant properties via dependence analysis, which often cannot take advantage of high level knowledge that the designer holds in their mind at design time.</p> <p>This document describes the semantics of the XLS intermediate representation (IR) including data types, operations, and textual representation.</p>"},{"location":"ir_semantics/#data-types","title":"Data types","text":""},{"location":"ir_semantics/#bits","title":"Bits","text":"<p>A vector of bits with a fixed width.</p> <p>Type syntax:</p> <p><code>bits[N]</code> where <code>N</code> is the number of bits.</p> <p>Value syntax:</p> <ul> <li>A literal decimal number. Example: <code>42</code>.</li> <li>A binary number prefixed with <code>0b</code>. Example: <code>0b10101</code></li> <li>A hexadecimal number: <code>0x</code>. Example: <code>0xdeadbeef</code></li> </ul> <p>The representation may optionally include the bit width in which case the type is prefixed before the literal: <code>bits[N]:$literal</code>. Example: <code>bits[8]:0xab</code>.</p>"},{"location":"ir_semantics/#array","title":"Array","text":"<p>A one-dimensional array of elements of the same type with a fixed number of elements. An array can contain bits, arrays, or tuples as elements. Empty (zero-element) arrays are not supported.</p> <p>Type syntax:</p> <p><code>$type[N]</code>: an array containing <code>N</code> elements of type <code>$type</code>. Examples:</p> <ul> <li>Two-element array of 8-bit bits type: <code>bits[8][2]</code></li> <li>Three-element array of tuple type: <code>(bits[32], bits[2])[3]</code></li> </ul> <p>Value syntax:</p> <p><code>[$value_1, ... , $value_N]</code> where <code>$value_n</code> is the value of the <code>n</code>-th element. Examples:</p> <ul> <li>Array of bits elements with explicit bit count: <code>[bits[8]:10, bits[8]:30]</code></li> <li>Three-element array consisting of two-element arrays of bits elements: <code>[[1,     2], [3, 4], [5, 6]]]</code></li> </ul>"},{"location":"ir_semantics/#tuple","title":"Tuple","text":"<p>An ordered set of fixed size containing elements with potentially different types. tuples can contain bits, arrays, or tuples as elements. May be empty.</p> <p>Type syntax:</p> <p><code>($type_{0}, ..., $type_{N-1})</code> where <code>N</code> is the number of elements and where <code>$type_n</code> is the type of the <code>n</code>-th element.</p> <p>Value syntax:</p> <p><code>($value_{0}, ..., $value_{N-1})</code> where <code>$value_n</code> is the value of the <code>n</code>-th element. Examples:</p> <ul> <li>Tuple containing two bits elements: <code>(0b100, 0b101)</code></li> <li>A nested tuple containing various element types: <code>((1, 2), 42, [5, 6])</code></li> </ul>"},{"location":"ir_semantics/#token","title":"Token","text":"<p>A type used to enforce ordering between channel operations. The token type has no value and all tokens are identical. A token is purely symbolic / semantic and has no correlate in hardware.</p> <p>Type syntax:</p> <p><code>token</code></p>"},{"location":"ir_semantics/#functions-procs-and-blocks","title":"Functions, procs, and blocks","text":"<p>The XLS IR has three function-level abstractions each which hold a data-flow graph of XLS IR operations: functions, procs, and blocks. Names of function, procs and blocks must be unique among their respective abstractions (functions, procs, and blocks). For example, a block cannot share a name with another block but can share a name with a function.</p>"},{"location":"ir_semantics/#function","title":"Function","text":"<p>A function is a stateless abstraction with a single-output which is computed from zero or more input parameters. May invoke other functions.</p>"},{"location":"ir_semantics/#proc","title":"Proc","text":"<p>A Proc is a stateful abstraction with an arbitrarily-typed recurrent state. Procs can communicate with other procs via channels which (abstractly) are infinite-depth FIFOs with flow control. Channel communication is handled via send and receive IR operations. Procs may invoke functions.</p> <p>TODO(meheff): 2021/11/04 Expand to include more details.</p>"},{"location":"ir_semantics/#block","title":"Block","text":"<p>A Block is an RTL-level abstraction used for code generation. It corresponds to a single Verilog module. Procs and functions are converted to blocks as part of the code generation process. Blocks may \u201cinvoke\u201d other blocks via instantiation. A block includes explicit representations of RTL constructs: ports, registers, and instantiations. The constructs are scoped within the block.</p>"},{"location":"ir_semantics/#port","title":"Port","text":"<p>A port is a representation of an input or output to the block. These correspond to ports on Verilog modules. Ports can be arbitrarily-typed. In the block, each port is represented with a <code>input_port</code> or <code>output_port</code> operation.</p>"},{"location":"ir_semantics/#register","title":"Register","text":"<p>A register is a representation of a hardware register (flop). Registers can be arbitrarily-typed. Each register must have a single <code>register_write</code> and a single <code>register_read</code> operation for writing and reading the register respectively.</p>"},{"location":"ir_semantics/#instantiation","title":"Instantiation","text":"<p>An instantiation is a block-scoped construct that represents a module instantiation at the Verilog level. The instantiated object can be another block, a FIFO (not yet supported), or a externally defined Verilog module (not yet supported). The instantiation is integrated into the instantiating block with <code>instantiation_input</code> and <code>instantiation_output</code> operations. There is a one-to-one mapping between the instantiation input/output and the ports of the instantiated objects.</p>"},{"location":"ir_semantics/#operations","title":"Operations","text":"<p>Operations share a common syntax and have both positional and keyword arguments \u00e0 la Python. Positional arguments are ordered and must appear first in the argument list. Positional arguments are exclusively the identifiers of the operands. Keyword arguments are unordered and must appear after the positional arguments. Keyword arguments can include arbitrary value types.</p> <pre><code>result = operation(pos_arg_0, ..., pos_arg_N, keyword_0=value0, ..., keyword_M=valueM, ...)\n</code></pre> <p>Common keyword arguments</p> Keyword Type Required Default Description <code>pos</code> <code>SourceLocation</code> no The source location associated with this operation. The syntax is a triplet of comma-separated integer values: <code>Fileno,Lineno,Colno</code>"},{"location":"ir_semantics/#unary-bitwise-operations","title":"Unary bitwise operations","text":"<p>Performs a bit-wise operation on a single bits-typed operand.</p> <p>Syntax</p> <pre><code>result = identity(operand)\nresult = not(operand)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>result</code> <code>bits[N]</code> <p>Operations</p> Operation Opcode Semantics <code>identity</code> <code>Op::kIdentity</code> <code>result = operand</code> <code>not</code> <code>Op::kNot</code> <code>result = ~operand</code>"},{"location":"ir_semantics/#variadic-bitwise-operations","title":"Variadic bitwise operations","text":"<p>Performs a bit-wise operation on one-or-more identically-typed bits operands. If only a single argument is provided the operation is a no-op.</p> <p>Syntax</p> <pre><code>result = and(operand_{0}, ..., operand_{N-1})\nresult = or(operand_{0}, ..., operand_{N-1})\nresult = xor(operand_{0}, ..., operand_{N-1})\n</code></pre> <p>Types</p> Value Type <code>operand_{i}</code> <code>bits[N]</code> <code>result</code> <code>bits[N]</code> <p>Operations</p> Operation Opcode Semantics <code>and</code> <code>Op::kAnd</code> <code>result = lhs &amp; rhs &amp; ...</code> <code>or</code> <code>Op::kOr</code> <code>result = lhs \\| rhs \\| ...</code> <code>xor</code> <code>Op::kXor</code> <code>result = lhs ^ rhs ^ ...</code>"},{"location":"ir_semantics/#arithmetic-unary-operations","title":"Arithmetic unary operations","text":"<p>Performs an arithmetic operation on a single bits-typed operand.</p> <p>Syntax</p> <pre><code>result = neg(operand)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>result</code> <code>bits[N]</code> <p>Operations</p> Operation Opcode Semantics <code>neg</code> <code>Op::kNeg</code> <code>result = -operand</code>"},{"location":"ir_semantics/#arithmetic-binary-operations","title":"Arithmetic binary operations","text":"<p>Performs an arithmetic operation on a pair of bits operands. Unsigned operations are prefixed with a 'u', and signed operations are prefixed with a 's'.</p> <p>Syntax</p> <pre><code>result = add(lhs, rhs)\nresult = smul(lhs, rhs)\nresult = umul(lhs, rhs)\nresult = sdiv(lhs, rhs)\nresult = smod(lhs, rhs)\nresult = sub(lhs, rhs)\nresult = udiv(lhs, rhs)\nresult = umod(lhs, rhs)\nresult = smulp(lhs, rhs)\nresult = umulp(lhs, rhs)\n</code></pre> <p>Types</p> <p>Currently signed and unsigned multiply, as wells as their partial product variants, support arbitrary width operands and result. For all other arithmetic operations the operands and the result are the same width. The expectation is that all arithmetic operations will eventually support arbitrary widths.</p> <p>Operations</p> Operation Opcode Semantics <code>add</code> <code>Op::kAdd</code> <code>result = lhs + rhs</code> <code>sdiv</code> <code>Op::kSDiv</code> <code>result = $signed(lhs) / $signed(rhs)</code> * ** <code>smod</code> <code>Op::kSMod</code> <code>result = $signed(lhs) % $signed(rhs)</code> * *** <code>smul</code> <code>Op::kSMul</code> <code>result = $signed(lhs) * $signed(rhs)</code> <code>smulp</code> <code>Op::kSMulp</code> <code>result[0] + result[1] = $signed(lhs) * $signed(rhs)</code> **** <code>sub</code> <code>Op::kSub</code> <code>result = lhs - rhs</code> <code>udiv</code> <code>Op::kUDiv</code> <code>result = lhs / rhs</code> * ** <code>umod</code> <code>Op::kUMod</code> <code>result = lhs % rhs</code> * <code>umul</code> <code>Op::kUMul</code> <code>result = lhs * rhs</code> <code>umulp</code> <code>Op::kUMulp</code> <code>result[0] + result[1] = lhs * rhs</code> **** <p>* Synthesizing division or modulus can lead to failing synthesis and/or problems with timing closure. It is usually best not to rely on this Verilog operator in practice, but instead explicitly instantiate a divider of choice.</p> <p>** Division rounds toward zero. For unsigned division this is the same as truncation. If the divisor is zero, unsigned division produces a maximal positive value. For signed division, if the divisor is zero the result is the maximal positive value if the dividend is non-negative or the maximal negative value if the dividend is negative.</p> <p>*** The sign of the result of modulus matches the sign of the left operand. If the right operand is zero the result is zero.</p> <p>**** The partial product multiply variants return a two-element tuple with both elements having the same type. The outputs are not fully constrained; the operations are free to return any values that sum to the product <code>lhs * rhs</code>.</p>"},{"location":"ir_semantics/#comparison-operations","title":"Comparison operations","text":"<p>Performs a comparison on a pair of identically-typed bits operands. Unsigned operations are prefixed with a 'u', and signed operations are prefixed with a 's'. Produces a result of bits[1] type.</p> <p>Syntax</p> <pre><code>result = eq(lhs, rhs)\nresult = ne(lhs, rhs)\nresult = sge(lhs, rhs)\nresult = sgt(lhs, rhs)\nresult = sle(lhs, rhs)\nresult = slt(lhs, rhs)\nresult = uge(lhs, rhs)\nresult = ugt(lhs, rhs)\nresult = ule(lhs, rhs)\nresult = ult(lhs, rhs)\n</code></pre> <p>Types</p> Value Type <code>lhs</code> <code>bits[N]</code> <code>rhs</code> <code>bits[N]</code> <code>result</code> <code>bits[1]</code> <p>Operations</p> Operation Opcode Semantics <code>eq</code> <code>Op::kEq</code> <code>result = lhs == rhs</code> <code>ne</code> <code>Op::kNe</code> <code>result = lhs != rhs</code> <code>sge</code> <code>Op::kSGe</code> <code>result = lhs &gt;= rhs</code> <code>sgt</code> <code>Op::kSGt</code> <code>result = lhs &gt; rhs</code> <code>sle</code> <code>Op::kSLe</code> <code>result = lhs &lt;= rhs</code> <code>slt</code> <code>Op::kSLt</code> <code>result = lhs &lt; rhs</code> <code>uge</code> <code>Op::kUGe</code> <code>result = lhs &gt;= rhs</code> <code>ugt</code> <code>Op::kUGt</code> <code>result = lhs &gt; rhs</code> <code>ule</code> <code>Op::kULe</code> <code>result = lhs &lt;= rhs</code> <code>ult</code> <code>Op::kULt</code> <code>result = lhs &lt; rhs</code>"},{"location":"ir_semantics/#shift-operations","title":"Shift operations","text":"<p>Performs an shift operation on an input operand where the shift amount is specified by a second operand.</p> <p>Syntax</p> <pre><code>result = shll(operand, amount)\nresult = shra(operand, amount)\nresult = shrl(operand, amount)\n</code></pre> <p>Types</p> <p>The shifted operand and the result of the shift are the same width. Widths of the shift amount may be arbitrary.</p> <p>Operations</p> Operation Opcode Semantics <code>shll</code> <code>Op::kShll</code> <code>result = lhs &lt;&lt; rhs</code> * <code>shra</code> <code>Op::kShra</code> <code>result = lhs &gt;&gt;&gt; rhs</code> (arithmetic shift right) ** <code>shrl</code> <code>Op::kShrl</code> <code>result = lhs &gt;&gt; rhs</code> * <p>* Logically shifting greater than or equal to the number of bits in the <code>lhs</code> produces a result of zero.</p> <p>** Arithmetic right shifting greater than or equal to the number of bits in the <code>lhs</code> produces a result equal to all of the bits set to the sign of the <code>lhs</code>.</p>"},{"location":"ir_semantics/#extension-operations","title":"Extension operations","text":"<p>Extends a bit value to a new (larger) target bit-length.</p> <p>Syntax</p> <pre><code>result = zero_ext(x, new_bit_count=42)\nresult = sign_ext(x, new_bit_count=42)\n</code></pre> <p>Types</p> Value Type <code>arg</code> <code>bits[N]</code> <code>new_bit_count</code> <code>int64_t</code> <code>result</code> <code>bits[new_bit_count]</code> <p>Note: <code>new_bit_count</code> should be <code>&gt;= N</code> or an error may be raised.</p>"},{"location":"ir_semantics/#zero_ext","title":"<code>zero_ext</code>","text":"<p>Zero-extends a value: turns its bit-length into the new target bit-length by filling zeroes in the most significant bits.</p>"},{"location":"ir_semantics/#sign_ext","title":"<code>sign_ext</code>","text":"<p>Sign-extends a value: turns its bit-length into the new target bit-length by filling in the most significant bits (MSbs) with the following policy:</p> <ul> <li>ones in the MSbs if the MSb of the original value was set, or</li> <li>zeros in the MSbs if the MSb of the original value was unset.</li> </ul>"},{"location":"ir_semantics/#channel-operations","title":"Channel operations","text":"<p>These operations send or receive data over channels. Channels are monomorphic, and each channel supports a fixed set of data types which are sent or received in a single transaction.</p>"},{"location":"ir_semantics/#receive","title":"<code>receive</code>","text":"<p>Receives a data value from a specified channel. The type of the data value is determined by the channel. An optional predicate value conditionally enables the receive operation. An optional <code>blocking</code> attribute determines whether the receive operation is blocking. A blocking receive waits (or blocks) until valid data is present at the channel. Compared to a blocking receive, a non-blocking receive has an additional entry in its return tuple of type <code>bits[1]</code> denoting whether the data read is valid.</p> <pre><code>result = receive(tkn, predicate=&lt;pred&gt;, blocking=&lt;bool&gt;, channel_id=&lt;ch&gt;)\n</code></pre> <p>Types</p> Value Type <code>tkn</code> <code>token</code> <code>pred</code> <code>bits[1]</code> <code>result</code> <code>(token, T)</code> if <code>blocking</code> == <code>true</code> else <code>(token, T, bits[1])</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>predicate</code> <code>bits[1]</code> no A value is received iff <code>predicate</code> is true <code>blocking</code> <code>bool</code> no <code>true</code> Whether the receive is blocking <code>channel_id</code> <code>int64_t</code> yes The ID of the channel to receive data from <p>If the predicate is false the data values in the result are zero-filled.</p>"},{"location":"ir_semantics/#send","title":"<code>send</code>","text":"<p>Sends data to a specified channel. The type of the data values is determined by the channel. An optional predicate value conditionally enables the send operation.</p> <pre><code>result = send(tkn, data, predicate=&lt;pred&gt;, channel_id=&lt;ch&gt;)\n</code></pre> <p>Types</p> Value Type <code>tkn</code> <code>token</code> <code>data</code> <code>T</code> <code>pred</code> <code>bits[1]</code> <code>result</code> <code>token</code> <p>The type of <code>data</code> must match the type supported by the channel.</p> <p>Keyword arguments</p> Keyword Type Required Default Description <code>predicate</code> <code>bits[1]</code> no A value is sent iff <code>predicate</code> is true <code>channel_id</code> <code>int64_t</code> yes The ID of the channel to send data to."},{"location":"ir_semantics/#array-operations","title":"Array operations","text":""},{"location":"ir_semantics/#array_1","title":"<code>array</code>","text":"<p>Constructs an array of its operands.</p> <pre><code>result = array(operand_{0}, ..., operand_{N-1})\n</code></pre> <p>Types</p> Value Type <code>operand_{i}</code> <code>T</code> <code>result</code> <code>T[N]</code> <p>Array can take an arbitrary number of operands including zero (which produces an empty array). The n-th operand becomes the n-th element of the array.</p>"},{"location":"ir_semantics/#array_index","title":"<code>array_index</code>","text":"<p>Returns a single element from an array.</p> <p>Syntax</p> <pre><code>result = array_index(array, indices=[idx_{0}, ... , idx_{N-1}])\n</code></pre> <p>Types</p> Value Type <code>array</code> Array of at least <code>N</code> dimensions <code>idx_{i}</code> Arbitrary bits type <code>result</code> <code>T</code> <p>Returns the element of <code>array</code> indexed by the indices <code>idx_{0} ... idx_{N-1}</code>. The array must have at least as many dimensions as number of index elements <code>N</code>. Each element <code>idx_{i}</code> indexes a dimension of <code>array</code>. The first element <code>idx_{0}</code> indexes the outer most dimension, the second element <code>idx_{1}</code> indexes the second outer most dimension, etc. The result type <code>T</code> is the type of <code>array</code> with the <code>N</code> outer most dimensions removed.</p> <p>Any out-of-bounds indices <code>idx_{i}</code> are clamped to the maximum in bounds index for the respective dimension.</p> <p>The table below shows examples of the result type <code>T</code> and the result expression assuming input array operand <code>A</code>.</p> Indices Array type result type <code>T</code> Result expression <code>{1, 2}</code> <code>bits[3][4][5]</code> <code>bits[3]</code> <code>A[1][2]</code> <code>{10, 2}</code> <code>bits[3][4][5]</code> <code>bits[3]</code> <code>A[4][2]</code> (first index is out-of-bounds and clamped at the maximum index) <code>{1}</code> <code>bits[3][4][5]</code> <code>bits[3][4]</code> <code>A[1]</code> <code>{}</code> <code>bits[3][4][5]</code> <code>bits[3][4][5]</code> <code>A</code> <code>{}</code> <code>bits[32]</code> <code>bits[32]</code> <code>A</code>"},{"location":"ir_semantics/#array_update","title":"<code>array_update</code>","text":"<p>Returns a modified copy of an array.</p> <p>Syntax</p> <pre><code>result = array_update(array, value, indices=[idx_{0}, ... , idx_{N-1}])\n</code></pre> <p>Types</p> Value Type <code>array</code> Array of at least <code>N</code> dimensions <code>value</code> <code>T</code> <code>idx_{i}</code> Arbitrary bits type <code>result</code> Same type as <code>array</code> <p>Returns a copy of the input array with the element at the given indices replaced with the given value. If any index is out of bounds, the result is identical to the input <code>array</code>. The indexing semantics is identical to <code>array_index</code> with the exception of out-of-bounds behavior.</p>"},{"location":"ir_semantics/#tuple-operations","title":"Tuple operations","text":""},{"location":"ir_semantics/#tuple_1","title":"<code>tuple</code>","text":"<p>Constructs a tuple of its operands.</p> <pre><code>result = tuple(operand_{0}, ..., operand_{N-1})\n</code></pre> <p>Types</p> Value Type <code>operand_{i}</code> <code>T_{i}</code> <code>result</code> <code>(T_{0}, ... , T_{N-1})</code> <p>Tuple can take and arbitrary number of operands including zero (which produces an empty tuple).</p>"},{"location":"ir_semantics/#tuple_index","title":"<code>tuple_index</code>","text":"<p>Returns a single element from a tuple-typed operand.</p> <p>Syntax</p> <pre><code>result = tuple_index(operand, index=&lt;index&gt;)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>(T_{0}, ... , T_{N-1})</code> <code>result</code> <code>T_{&lt;index&gt;}</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>index</code> <code>int64_t</code> yes Index of tuple element to produce"},{"location":"ir_semantics/#bit-vector-operations","title":"Bit-vector operations","text":""},{"location":"ir_semantics/#bit_slice","title":"<code>bit_slice</code>","text":"<p>Slices a contiguous range of bits from a bits-typed operand.</p> <p>Syntax</p> <pre><code>result = bit_slice(operand, start=&lt;start&gt;, width=&lt;width&gt;)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>result</code> <code>bits[&lt;width&gt;]</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>start</code> <code>int64_t</code> yes The starting bit of the slice. <code>start</code> is is zero-indexed where zero is the least-significant bit of the operand. <code>width</code> <code>int64_t</code> yes The width of the slice. <p>The bit-width of <code>operand</code> must be greater than or equal to <code>&lt;start&gt;</code> plus <code>&lt;width&gt;</code>.</p>"},{"location":"ir_semantics/#bit_slice_update","title":"<code>bit_slice_update</code>","text":"<p>Replaces a contiguous range of bits in a bits-typed operand at a variable start index with a given value.</p> <p>Syntax</p> <pre><code>result = bit_slice_update(operand, start, update_value)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>start</code> <code>bits[I]</code> <code>update_value</code> <code>bits[M]</code> <code>result</code> <code>bits[N]</code> <p>Evaluates to <code>operand</code> with the contiguous <code>M</code> bits starting at index <code>start</code> replaced with <code>update_value</code>. Out-of-bound bits (which occur if <code>start + M &gt; N</code>) are ignored. Examples:</p> <code>operand</code> <code>start</code> <code>update_value</code> <code>result</code> <code>bits[16]:0xabcd</code> <code>0</code> <code>bits[8]:0xff</code> <code>bits[16]:0xabff</code> <code>bits[16]:0xabcd</code> <code>4</code> <code>bits[8]:0xff</code> <code>bits[16]:0xaffd</code> <code>bits[16]:0xabcd</code> <code>12</code> <code>bits[8]:0xff</code> <code>bits[16]:0xfbcd</code> <code>bits[16]:0xabcd</code> <code>16</code> <code>bits[8]:0xff</code> <code>bits[16]:0xabcd</code>"},{"location":"ir_semantics/#dynamic_bit_slice","title":"<code>dynamic_bit_slice</code>","text":"<p>Slices a contiguous range of bits from a bits-typed operand, with variable starting index but fixed width. Out-of-bounds slicing is supported by treating all out-of-bounds bits as having value 0.</p> <p>Syntax</p> <pre><code>result = dynamic_bit_slice(operand, start, width=&lt;width&gt;)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>start</code> <code>bits[M]</code> <code>result</code> <code>bits[&lt;width&gt;]</code> <p><code>start</code> can be of arbitrary bit width. It will be interpreted as an unsigned integer.</p> <p>Keyword arguments</p> Keyword Type Required Default Description <code>width</code> <code>int64_t</code> yes The width of the slice."},{"location":"ir_semantics/#concat","title":"<code>concat</code>","text":"<p>Concatenates and arbitrary number of bits-typed operands.</p> <pre><code>result = concat(operand{0}, ..., operand{n-1})\n</code></pre> <p>Types</p> Value Type <code>operand_{i}</code> <code>bits[N_{i}]</code> <code>result</code> <code>bits[Sum(N_{i})]</code> <p>This is equivalent to the verilog concat operator: <code>result = {arg0, ..., argN}</code></p>"},{"location":"ir_semantics/#reverse","title":"<code>reverse</code>","text":"<p>Reverses the order of bits of its operand.</p> <pre><code>result = reverse(operand)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>result</code> <code>bits[N]</code>"},{"location":"ir_semantics/#decode","title":"<code>decode</code>","text":"<p>Implements a binary decoder.</p> <pre><code>result = decode(operand, width=&lt;width&gt;)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>result</code> <code>bits[M]</code> <p>The result width <code>M</code> must be less than or equal to 2**<code>N</code> where <code>N</code> is the operand width.</p> <p>Keyword arguments</p> Keyword Type Required Default Description <code>width</code> <code>int64_t</code> yes Width of the result <p><code>decode</code> converts the binary-encoded operand value into a one-hot result. For an operand value of <code>n</code> interpreted as an unsigned number the <code>n</code>-th result bit and only the <code>n</code>-th result bit is set. The width of the <code>decode</code> operation may be less than the maximum value expressible by the input (2**<code>N</code> - 1). If the encoded operand value is larger than the number of bits of the result the result is zero.</p>"},{"location":"ir_semantics/#encode","title":"<code>encode</code>","text":"<p>Implements a binary encoder.</p> <pre><code>result = encode(operand, width=&lt;width&gt;)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>bits[N]</code> <code>result</code> <code>bits[M]</code> <p>The result width <code>M</code> must be equal to \\(\\(\\lceil \\log_{2} N \\rceil\\)\\).</p> <p><code>encode</code> converts the one-hot operand value into a binary-encoded value of the \"hot\" bit of the input. If the <code>n</code>-th bit and only the <code>n</code>-th bit of the operand is set the result is equal the value <code>n</code> as an unsigned number.</p> <p>If multiple bits of the input are set the result is equal to the logical or of the results produced by the input bits individually. For example, if bit 3 and bit 5 of an <code>encode</code> input are set the result is equal to 3 | 5 = 7.</p> <p>If no bits of the input are set the result is zero.</p>"},{"location":"ir_semantics/#one_hot","title":"<code>one_hot</code>","text":"<p>Produces a bits value with exactly one bit set. The index of the set bit depends upon the input value.</p> <p>Syntax</p> <pre><code>result = one_hot(input, lsb_prio=true)\nresult = one_hot(input, lsb_prio=false)\n</code></pre> <p>Types</p> Value Type <code>input</code> <code>bits[N]</code> <code>result</code> <code>bits[N+1]</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>lsb_prio</code> <code>bool</code> yes Whether the least significant bit (LSb) has priority. <p>For <code>lsb_prio=true</code>: result bit <code>i</code> for <code>0 &lt;= i &lt; N</code> is set in <code>result</code> iff bit <code>i</code> is set in the input and all lower bits <code>j</code> for <code>j &lt; i</code> are not set in the input.</p> <p>For <code>lsb_prio=false</code>: result bit <code>i</code> for <code>N-1 &gt;= i &gt;= 0</code> is set in <code>result</code> iff bit <code>i</code> is set in the input and all higher (more significant) bits <code>j</code> for <code>j &gt; i</code> are not set in the input.</p> <p>For both <code>lsb_prio=true</code> and <code>lsb_prio=false</code>, result bit <code>N</code> (the most significant bit in the output) is only set if no bits in the input are set.</p> <p>Examples:</p> <ul> <li><code>one_hot(0b0011, lsb_prio=true)</code> =&gt; <code>0b00001</code> -- note that an extra MSb has   been appended to the output to potentially represent the \"all zeros\" case.</li> <li><code>one_hot(0b0111, lsb_prio=false)</code> =&gt; <code>0b00100</code>.</li> <li><code>one_hot(0b00, lsb_prio=false)</code> =&gt; <code>0b100</code>.</li> <li><code>one_hot(0b00, lsb_prio=true)</code> =&gt; <code>0b100</code> -- note the output for <code>one_hot</code> is   the same for the all-zeros case regardless of whether <code>lsb_prio</code> is true or   false.</li> </ul> <p>This operation is useful for constructing match or switch operation semantics where a condition is matched against an ordered set of cases and the first match is chosen. It is also useful for one-hot canonicalizing, e.g. as a prelude to counting leading/trailing zeros.</p>"},{"location":"ir_semantics/#control-oriented-operations","title":"Control-oriented operations","text":"<p>For context note that, in XLS, operations are evaluated eagerly in a very general sense: all \"branches\" of computation may be evaluated in full before the result is selected via an operation such as <code>one_hot_sel</code> or <code>sel</code>. This model is amenable to pipeline-like hardware execution, where operations tend to be fixed in some spatial area and operations execute a single function, while interconnect is used for reconfiguration purposes.</p> <p>Towards this eager-evaluation-capable model, operations used within a function are generally not Turing-complete: operations such as <code>counted_for</code> require a finite bound so that they could be implemented using a finite amount of pipeline area. Operations such as <code>dynamic_counted_for</code> are an exception, where that operation will only be possible to use in a time-multiplexed code generation mode, such as the XLS sequential emitter, where arbitrary iteration to some dynamic bound is likely to be possible.</p>"},{"location":"ir_semantics/#param","title":"<code>param</code>","text":"<p>A parameter to the current IR function, which can be used as an operand for operations within the function.</p> <p>Syntax</p> <p>Parameters have a special syntactic form distinct from other nodes, where they are listed directly in the function signature with their type.</p> <pre><code>fn f(x: bits[32]) -&gt; bits[32] {\n  ret identity.2 = identity(x, id=2)\n}\n</code></pre> <p>Types</p> Value Type <code>name</code> <code>str</code> <code>type</code> <code>type</code>"},{"location":"ir_semantics/#sel","title":"<code>sel</code>","text":"<p>Selects between operands based on a selector value.</p> <p>Syntax</p> <pre><code>result = sel(selector, cases=[case_{0}, ... , case_{N-1}], default=&lt;default&gt;)\n</code></pre> <p>Types</p> Value Type <code>selector</code> <code>bits[M]</code> <code>case_{i}</code> <code>T</code> <code>default</code> <code>T</code> <code>result</code> <code>T</code>"},{"location":"ir_semantics/#one_hot_sel","title":"<code>one_hot_sel</code>","text":"<p>Selects between operands based on a one-hot selector, <code>OR</code>-ing all selected cases if more than one case is selected.</p> <p>See <code>one_hot</code> for an example of the one-hot selector invariant. Note that when the selector is not one-hot, this operation is still well defined.</p> <p>Note that when <code>one_hot</code> operations are used to precondition the <code>selector</code> operand to <code>one_hot_sel</code>, the XLS optimizer will try to determine when they are unnecessary and subsequently eliminate them.</p> <p>Syntax</p> <pre><code>result = one_hot_sel(selector, cases=[case_{0}, ... , case_{N-1}])\n</code></pre> <p>Types</p> Value Type <code>selector</code> <code>bits[N]</code> <code>case_{i}</code> <code>T</code> <code>result</code> <code>T</code> <p>The result is the logical OR of all cases <code>case_{i}</code> for which the corresponding bit <code>i</code> is set in the selector. When selector is one-hot this performs a select operation.</p>"},{"location":"ir_semantics/#priority_sel","title":"<code>priority_sel</code>","text":"<p>Selects between operands based on a selector, choosing the highest-priority case if more than one case is selected. Each bit in the selector corresponds to a case, with the least significant bit corresponding to the first case and having the highest priority. If there are no bits in the selector set, no case is selected and the default value of 0 is chosen.</p> <p>See <code>one_hot</code> for an example of the one-hot selector invariant. Note that when the selector is not one-hot, this operation is still well defined.</p> <p>Note that when <code>one_hot</code> operations are used to precondition the <code>selector</code> operand to <code>priority_sel</code>, the XLS optimizer will try to determine when they are unnecessary and subsequently eliminate them.</p> <p>Syntax</p> <pre><code>result = priority_sel(selector, cases=[case_{0}, ... , case_{N-1}])\n</code></pre> <p>Types</p> Value Type <code>selector</code> <code>bits[N]</code> <code>case_{i}</code> <code>T</code> <code>result</code> <code>T</code> <p>The result is the first case <code>case_{i}</code> for which the corresponding bit <code>i</code> is set in the selector. If the selector is known to be one-hot, then the <code>priority_sel()</code> operation is equivalent to a <code>one_hot_sel()</code>.</p>"},{"location":"ir_semantics/#invoke","title":"<code>invoke</code>","text":"<p>Invokes a function. The return value for the invoked function is the result value.</p> <p>Syntax</p> <pre><code>result = invoke(operand_{0}, ... , operand_{N-1}, to_apply=&lt;to_apply&gt;)\n</code></pre> <p>Types</p> Value Type <code>init</code> <code>T</code> <code>result</code> <code>T</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>to_apply</code> <code>string</code> yes Name of the function to use as the loop body"},{"location":"ir_semantics/#map","title":"<code>map</code>","text":"<p>Applies a function to the elements of an array and returns the result as an array.</p> <p>Syntax</p> <pre><code>result = map(operand, to_apply=&lt;to_apply&gt;)\n</code></pre> <p>Types</p> Value Type <code>operand</code> <code>array[T]</code> <code>result</code> <code>array[U]</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>to_apply</code> <code>string</code> yes Name of the function to apply to each element of the operand"},{"location":"ir_semantics/#dynamic_counted_for","title":"<code>dynamic_counted_for</code>","text":"<p>Invokes a dynamic-trip count loop.</p> <p>Syntax</p> <pre><code>result = counted_for(init, trip_count, stride, body=&lt;body&gt;, invariant_args=&lt;inv_args&gt;)\n</code></pre> <p>Types</p> Value Type <code>init</code> <code>T</code> <code>trip_count</code> <code>bits[N], treated as unsigned</code> <code>stride</code> <code>bits[M], treated as signed</code>, <code>result</code> <code>T</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>invariant_args</code> array of yes Names of the invariant operands as the loop body <code>body</code> <code>string</code> yes Name of the function to use as the loop body <p><code>dynamic_counted_for</code> invokes the function <code>body</code> <code>trip_count</code> times, passing loop-carried data that starts with value <code>init</code>. The induction variable is incremented by <code>stride</code> after each iteration.</p> <ul> <li>The first argument passed to <code>body</code> is the induction variable -- presently,     the induction variable always starts at zero and increments by <code>stride</code>     after every trip.</li> <li>The second argument passed to <code>body</code> is the loop-carry data. The return type     of <code>body</code> must be the same as the type of the <code>init</code> loop carry data. The     value returned from the last trip is the result of the <code>counted_for</code>     expression.</li> <li>All subsequent arguments passed to <code>body</code> are passed from <code>invariant_args</code>;     e.g. if there are two members in <code>invariant_args</code> those values are passed as     the third and fourth arguments.</li> </ul> <p>Therefore <code>body</code> should have a signature that matches the following:</p> <pre><code>body(i, loop_carry_data, [invariant_arg0, invariant_arg1, ...])\n</code></pre> <p>Note that we currently inspect the <code>body</code> function to see what type of induction variable (<code>i</code> above) it accepts in order to pass an <code>i</code> value of that type. <code>trip_count</code> must have fewer bits than <code>i</code> and <code>stride</code> should have fewer than or equal number of bits to <code>i</code>.</p> <p>Code generation support for <code>dynamic_counted_for</code> is limited because the pipeline generator cannot handle an unknown trip count.</p>"},{"location":"ir_semantics/#counted_for","title":"<code>counted_for</code>","text":"<p>Invokes a fixed-trip count loop.</p> <p>Syntax</p> <pre><code>result = counted_for(init, trip_count=&lt;trip_count&gt;, stride=&lt;stride&gt;, body=&lt;body&gt;, invariant_args=&lt;inv_args&gt;)\n</code></pre> <p>Types</p> Value Type <code>init</code> <code>T</code> <code>result</code> <code>T</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>trip_count</code> <code>int64_t</code> yes Trip count of the loop (number of times that the loop body will be executed) <code>stride</code> <code>int64_t</code> no 1 Stride of the induction variable <code>invariant_args</code> array of yes Names of the invariant operands as the loop body <code>body</code> <code>string</code> yes Name of the function to use as the loop body <p><code>counted_for</code> invokes the function <code>body</code> <code>trip_count</code> times, passing loop-carried data that starts with value <code>init</code>.</p> <ul> <li>The first argument passed to <code>body</code> is the induction variable -- presently,     the induction variable always starts at zero and increments by <code>stride</code>     after every trip.</li> <li>The second argument passed to <code>body</code> is the loop-carry data. The return type     of <code>body</code> must be the same as the type of the <code>init</code> loop carry data. The     value returned from the last trip is the result of the <code>counted_for</code>     expression.</li> <li>All subsequent arguments passed to <code>body</code> are passed from <code>invariant_args</code>;     e.g. if there are two members in <code>invariant_args</code> those values are passed as     the third and fourth arguments.</li> </ul> <p>Therefore <code>body</code> should have a signature that matches the following:</p> <pre><code>body(i, loop_carry_data[, invariant_arg0, invariant_arg1, ...])\n</code></pre> <p>Note that we currently inspect the <code>body</code> function to see what type of induction variable (<code>i</code> above) it accepts in order to pass an <code>i</code> value of that type.</p>"},{"location":"ir_semantics/#sequencing-operations","title":"Sequencing operations","text":"<p>Some operations in XLS IR are sensitive to sequence order, similar to channel operations, but are not themselves channel-related. Tokens are used to determine the possible sequencing of these effects, and <code>after_all</code> can be used to join together tokens as a sequencing merge point for concurrent threads of execution described by different tokens.</p>"},{"location":"ir_semantics/#after_all","title":"<code>after_all</code>","text":"<p>Used to construct partial orderings among channel operations.</p> <pre><code>result = after_all(operand_{0}, ..., operand_{N-1})\n</code></pre> <p>Types</p> Value Type <code>operand_{i}</code> <code>token</code> <code>result</code> <code>token</code> <p><code>after_all</code> can consume an arbitrary number of token operands including zero.</p>"},{"location":"ir_semantics/#other-side-effecting-operations","title":"Other side-effecting operations","text":"<p>Aside from channels operations such as <code>send</code> and <code>receive</code> several other operations have side-effects. Care must be taken when adding, removing, or transforming these operations, e.g., in the optimizer.</p>"},{"location":"ir_semantics/#assert","title":"<code>assert</code>","text":"<p>Raises an error at software run-time (DSLX/IR interpretation, JIT execution, RTL simulation) if the given condition evaluates to false. The operation takes a literal string attribute which is included in the error message. This is a software-only operation and has no representation in the generated hardware. Tokens are used to connect the operation to the graph and order with respect to other side-effecting operations.</p> <pre><code>result = assert(tkn, condition, message=&lt;string&gt;)\nresult = assert(tkn, condition, message=&lt;string&gt;, label=&lt;string&gt;)\n</code></pre> <p>Types</p> Value Type <code>tkn</code> <code>token</code> <code>condition</code> <code>bits[1]</code> <code>result</code> <code>token</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>message</code> <code>string</code> yes Message to include in raised error <code>label</code> <code>optional string</code> yes Label to associate with the assert statement in the generated (System)Verilog"},{"location":"ir_semantics/#cover","title":"<code>cover</code>","text":"<p>Records the number of times the given condition evaluates to true. Just like <code>assert</code>, this is a software-only construct and is not emitted in a final hardware design. Tokens are used to sequence this operation in the graph.</p> <pre><code>result = cover(tkn, condition, label=&lt;string&gt;)\n</code></pre> <p>Types</p> Value Type <code>tkn</code> <code>token</code> <code>condition</code> <code>bits[1]</code> <code>result</code> <code>token</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>label</code> <code>string</code> yes Name associated with the counter."},{"location":"ir_semantics/#gate","title":"<code>gate</code>","text":"<p>Gates an arbitrarily-typed value based on a condition.</p> <p>The result of the operation is the data operand if the condition is true, otherwise the result is a zero value of the type of the data operand (i.e., the value is gated off). A helpful mnemonic is to think of this as analogous to an <code>AND</code> gate: if the condition is <code>true</code>, the value passes through, otherwise it's zeroed.</p> <p>This operation can reduce switching and may be used in power optimizations. This is intended for use in operand gating for power reduction, and the compiler may ultimately use it to perform register-level load-enable gating.</p> <p>The operation is considered side-effecting to prevent removal of the operation when the gated result (condition is false) is not observable. In this case the gate operation is still desirable because of the operations' effects on power consumption.</p> <pre><code>result = gate(condition, data)\n</code></pre> <p>Types</p> Value Type <code>condition</code> <code>bits[1]</code> <code>data</code> <code>T</code> <code>result</code> <code>T</code>"},{"location":"ir_semantics/#rtl-level-operations","title":"RTL-level operations","text":"<p>These IR operations correspond to RTL-level constructs in the emitted Verilog. These operations are added and used in the code generation process and may only appear in blocks (not procs or functions).</p>"},{"location":"ir_semantics/#input_port","title":"<code>input_port</code>","text":"<p>Corresponds to an input port on a Verilog module.</p> <p>Syntax</p> <pre><code>result = input_port()\n</code></pre> <p>Types</p> Value Type <code>result</code> <code>T</code> <p>An input_port operation can be an arbitrary type.</p>"},{"location":"ir_semantics/#output_port","title":"<code>output_port</code>","text":"<p>Corresponds to an output port on a Verilog module. The value sent to the output port is the data operand.</p> <p>Syntax</p> <pre><code>result = output_port(data)\n</code></pre> <p>Types</p> Value Type <code>data</code> <code>T</code> <code>result</code> <code>T</code>"},{"location":"ir_semantics/#register_read","title":"<code>register_read</code>","text":"<p>Reads a value from a register.</p> <p>The register is defined on the block.</p> <p>Syntax</p> <pre><code>result = register_read(register=&lt;register_name&gt;)\n</code></pre> <p>Types</p> Value Type <code>result</code> <code>T</code> <p>The type <code>T</code> of the result of the operation is the type of the register.</p> <p>Keyword arguments</p> Keyword Type Required Default Description <code>register</code> <code>string</code> yes Name of the register to read"},{"location":"ir_semantics/#register_write","title":"<code>register_write</code>","text":"<p>Writes a value to a register.</p> <p>The write to the register may be conditioned upon an optional load-enable and/or reset signal. The register is defined on the block.</p> <p>Syntax</p> <pre><code>result = register_write(data, load_enable=&lt;load_enable&gt;, reset=&lt;reset&gt;, register=&lt;register_name&gt;)\n</code></pre> <p>Types</p> Value Type <code>data</code> <code>T</code> <code>load_enable</code> <code>bits[1]</code> (optional) <code>reset</code> <code>bits[1]</code> (optional) <code>result</code> <code>()</code> (empty tuple) <p>Keyword arguments</p> Keyword Type Required Default Description <code>register</code> <code>string</code> yes Name of the register to write <p>The type <code>T</code> of the data operand must be the same as the the type of the register.</p>"},{"location":"ir_semantics/#instantiation_input","title":"<code>instantiation_input</code>","text":"<p>Corresponds to a single input port of an instantiation.</p> <p>An instantiation is a block-scoped construct that represents a module instantiation at the Verilog level. Each <code>instantation_input</code> operation corresponds to a particular port of the instantiated object, so generally a single instantiation can have multiple associated <code>instantiation_input</code> operations (one for each input port).</p> <p>Syntax</p> <pre><code>result = instantiation_input(data, instantiation=&lt;instantiation&gt;, port_name=&lt;port_name&gt;)\n</code></pre> <p>Types</p> Value Type <code>data</code> <code>T</code> <code>result</code> <code>()</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>instantiation</code> <code>string</code> yes Name of the instantiation. <code>port_name</code> <code>string</code> yes Name of the associated port of the instantiation. <p>The type <code>T</code> of the data operand must be the same as the the type of the associated input port of the instantiated object.</p>"},{"location":"ir_semantics/#instantiation_output","title":"<code>instantiation_output</code>","text":"<p>Corresponds to a single output port of an instantiation.</p> <p>An instantiation is a block-scoped construct that represents a module instantiation at the Verilog level. Each <code>instantation_output</code> operation corresponds to a output particular port of the instantiated object, so generally a single instantiation can have multiple associated <code>instantiation_output</code> operations (one for each output port).</p> <p>Syntax</p> <pre><code>result = instantiation_output(instantiation=&lt;instantiation&gt;, port_name=&lt;port_name&gt;)\n</code></pre> <p>Types</p> Value Type <code>result</code> <code>T</code> <p>Keyword arguments</p> Keyword Type Required Default Description <code>instantiation</code> <code>string</code> yes Name of the instantiation. <code>port_name</code> <code>string</code> yes Name of the associated port of the instantiation. <p>The type <code>T</code> of the result is type of the associated output port of the instantiated object.</p>"},{"location":"ir_visualization/","title":"IR Visualization","text":"<p>The XLS IR visualization web app presents the IR in text and graphical form side-by-side and enables interactive exploration of the IR.</p>"},{"location":"ir_visualization/#running-the-web-app","title":"Running the web app","text":"<p>To build and launch the IR visualization web app run:</p> <pre><code>bazel run -c opt //xls/visualization/ir_viz:app -- --delay_model=unit\n</code></pre> <p>Then visit http://localhost:5000 in a browser.</p>"},{"location":"ir_visualization/#screenshot","title":"Screenshot","text":"<p>The screenshot below shows a zoomed-in portion of the IR graph for the <code>fp_adder</code> benchmark. The highlighted path in blue is the timing critical path the through the graph.</p> <p></p>"},{"location":"ir_visualization/#usage","title":"Usage","text":""},{"location":"ir_visualization/#text-ir","title":"Text IR","text":"<p>The left hand side of the UI shows the IR in text form in an editable text box. The IR may be entered or loaded in several ways:</p> <ul> <li>Upload from a file on the local file system via the Upload button.</li> </ul> <ul> <li>Enter directly by typing in the text box or cut and pasting.</li> </ul> <ul> <li>Load a pre-compiled benchmark via the Benchmarks button. The IR is from     the benchmark after optimizations.</li> </ul> <p>The text IR is parsed as you type. The result of the parse (OK or an error) appears in an alert at the bottom of the text box. On successful parsing all identifiers in the IR will be shown in bold.</p>"},{"location":"ir_visualization/#ir-graph","title":"IR graph","text":"<p>The right-hand side of the UI shows the IR in graphical form. Clicking on the View Graph button renders the text IR on the left hand side as a graph. The View Graph button is enabled only if the IR is parsed successfully. The graph view may be manipulated as follows:</p> <ul> <li>Zoom The mouse scroll wheel zooms the view of the IR graph.</li> </ul> <ul> <li>Pan Clicking and holding the left mouse button down in the graph panel     (while not on a graph element) and moving the mouse pans the graph.</li> </ul> <ul> <li>Moving nodes Nodes in the graph are moved by clicking and holding on     the node and moving the mouse.</li> </ul> <ul> <li>Focusing on nodes Clicking on a node in the graph while holding down     the control key scrolls the respective definition of the node in the text IR     into view in the text box. Similarly, control clicking on an identifier in     the text IR zooms and centers the graph view on the respective node.</li> </ul>"},{"location":"ir_visualization/#node-colors","title":"Node colors","text":"<p>Every node in the graph is assigned a color on a spectrum from white (<code>#FFFFFF</code>) to red (<code>#FF0000</code>) depending on the modeled latency of the operation. The nodes with the longest latency in the graph are assigned red. Nodes with zero latency are assigned white.</p>"},{"location":"ir_visualization/#hovering-on-ir-elements","title":"Hovering on IR elements","text":"<p>Hovering on nodes and edges in the graph highlights the corresponding element in the text IR and vice versa. In the text IR, the definition and all uses of the IR value are highlighted when a node is highlighted. When a graph edge is highlighted, the definition and corresponding use are highlighted in the text IR.</p> <p>Information about a highlighted node (identifier in text IR) is displayed in a box above the IR graph. This information includes:</p> <ul> <li>The definition of the IR value in text form.</li> </ul> <ul> <li>Estimate of the delay in picoseconds of the corresponding operation. The     delay estimation methodology is described here.</li> </ul> <ul> <li>Any known bits of the value as determined by the query engine     (https://github.com/google/xls/tree/main/xls/passes/query_engine.h).</li> </ul>"},{"location":"ir_visualization/#selecting-nodes","title":"Selecting nodes","text":"<p>Nodes in the graph may be in a selected or deselected state. Clicking on a node in the graph or identifier in the text IR toggles the selection state. A selected node (identifier in IR text) is shown with a blue border. Nodes and edges which are neighbors of selected nodes (the selection frontier) are shown in orange.  Clicking on an empty area of the graph deselects all nodes.</p>"},{"location":"ir_visualization/#showing-only-selected-nodes","title":"Showing only selected nodes","text":"<p>The toggle Show only selected nodes controls whether to show the entire graph or only the selected node and those elements in the selection frontier. Showing only selected nodes can be used to display only a subgraph of interest. For large graphs which are slow to render in their entirety, this mechanism can be used to interactively explore parts of the graph.</p> <p>When showing only selected nodes, the graph maybe be expanded by selecting additional nodes to add to the graph. The graph is re-rendered to include the newly selected node. Similarly, nodes may be removed from the graph by deselecting nodes.</p>"},{"location":"ir_visualization/#selecting-the-critical-path","title":"Selecting the critical path","text":"<p>The button Critical Path selects exactly those nodes which are on the critical path as determined by XLS's timing model. This may be used with the Show only selected nodes toggle to show a graph containing only critical path elements and neighbors. In the screenshot above, the selected critical path is shown in blue.</p>"},{"location":"optimizations/","title":"XLS Optimizations","text":"<ul> <li>XLS Optimizations<ul> <li>Traditional compiler optimizations<ul> <li>Dead Code Elimination (DCE)</li> <li>Common Subexpression Elimination (CSE)</li> <li>Constant Folding</li> <li>Assert Cleanup</li> <li>IO Simplifications</li> <li>Reassociation</li> </ul> </li> <li>Narrowing Optimizations<ul> <li>Select operations</li> <li>Arithmetic and shift operations</li> <li>Comparison operations</li> <li>Known-literals and ArrayIndex</li> </ul> </li> <li>Strength Reductions<ul> <li>Arithmetic Comparison Strength Reductions</li> </ul> </li> <li>\"Simple\" Boolean Simplification</li> <li>Bit-slice optimizations<ul> <li>Slicing sign-extended values</li> </ul> </li> <li>Concat optimizations<ul> <li>Hoisting a reverse above a concat</li> <li>Hoisting a bitwise operation above a concat</li> <li>Merging consecutive bit-slices</li> </ul> </li> <li>Select optimizations<ul> <li>Converting chains of Selects to into a single OneHotSelect</li> <li>Specializing select arms</li> <li>Consecutive selects with identical selectors</li> <li>Sparsifying selects with range analysis</li> </ul> </li> <li>Binary Decision Diagram based optimizations<ul> <li>BDD common subexpression elimination</li> <li>OneHot MSB elimination</li> </ul> </li> </ul> </li> </ul>"},{"location":"optimizations/#traditional-compiler-optimizations","title":"Traditional compiler optimizations","text":"<p>Many optimizations from traditional compilers targeting CPUs also apply to the optimization of hardware. Common objectives of traditional compiler optimizations include exposing parallelism, reducing latency, and eliminating instructions. Often these translate directly into the primary objectives of hardware optimization of reducing delay and area.</p>"},{"location":"optimizations/#dead-code-elimination-dce","title":"Dead Code Elimination (DCE)","text":"<p>Dead Code Elimination (DCE for short) is usually one of the easiest and most straightforward optimization passes in compilers. The same is true for XLS (the implementation is in <code>xls/passes/dce_pass.*</code>). Understanding the pass is also a good way to familiarize yourself with basics of the compiler IR, how to implement a pass, how to iterate over the nodes in the IR, how to query for node properties and so on.</p> <p>In general, DCE removes nodes from the IR that cannot be reached. Nodes can become unreachable by construction, for example, when a developer writes side-effect-free computations in DSLX that are disconnected from the function return ops. Certain optimization passes may also result in dead nodes.</p> <p>Let's look at the structure of the pass. The header file is straightforward, The <code>DeadCodeEliminationPass</code> is a function-level pass and hence derived from <code>FunctionBasePass</code>. Every function-level pass must implement the function <code>RunOnFunctionBaseInternal</code> and return a status indicating whether or not the pass made a change to the IR:</p> <pre><code>class DeadCodeEliminationPass : public FunctionBasePass {\npublic:\nDeadCodeEliminationPass()\n: FunctionBasePass(\"dce\", \"Dead Code Elimination\") {}\n~DeadCodeEliminationPass() override {}\n\nprotected:\n// Iterate all nodes, mark and eliminate the unvisited nodes.\nabsl::StatusOr&lt;bool&gt; RunOnFunctionBaseInternal(\nFunctionBase* f, const PassOptions&amp; options,\nPassResults* results) const override;\n};\n</code></pre> <p>Now let's look at the implementation (in file <code>xls/passes/dce_pass.cc</code>). After the function declaration:</p> <pre><code>absl::StatusOr&lt;bool&gt; DeadCodeEliminationPass::RunOnFunctionBaseInternal(\nFunctionBase* f, const PassOptions&amp; options, PassResults* results) const {\n</code></pre> <p>There is a little lambda function testing whether a node is deletable or not:</p> <pre><code>  auto is_deletable = [](Node* n) {\nreturn !n-&gt;function_base()-&gt;HasImplicitUse(n) &amp;&amp;\n!OpIsSideEffecting(n-&gt;op());\n};\n</code></pre> <p>This function tests for two special classes of nodes.</p> <ul> <li>A node with implicit uses (defined in <code>xls/ir/function.h</code>) is a function's     return value. In case of procs, the return is not reached and may appear as     dead. It must not be removed as XLS expects each function to have a return     value.</li> </ul> <ul> <li>There are a number of side-effecting nodes, such as send/receive operations,     asserts, covers, input / output ports, register read / writes, or parameters     (and a few more). Because of their side effects, they must not be eliminated     by DCE.</li> </ul> <p>Next the pass iterates over all nodes in the function and adds deletable nodes with no users to a worklist. Those are leaf nodes, they are the initial candidates for deletion:</p> <pre><code>  std::deque&lt;Node*&gt; worklist;\nfor (Node* n : f-&gt;nodes()) {\nif (n-&gt;users().empty() &amp;&amp; is_deletable(n)) {\nworklist.push_back(n);\n}\n}\n</code></pre> <p>Now on to the heart of the DCE algorithm. The algorithm iterates over nodes in the worklist until it is empty, popping elements from the front of the list and potentially adding new elements to the list. For example, assume there was a leaf node A with no further users. Further assume that its operand(s) only have node A as user, then the operand will be added to the worklist and visited in the next iteration over the worklist. There is a minor subtlety here - the code has to ensure that operands are only visited once, hence the use of a <code>flat_hash_set&lt;Node*&gt;</code> to check whether an operand has been visited already.</p> <p>After all operands have been visited and potentially added to the worklist, the original leaf node A is being removed and a corresponding logging statement (level 3) is generated.</p> <pre><code>  int64_t removed_count = 0;\nabsl::flat_hash_set&lt;Node*&gt; unique_operands;\nwhile (!worklist.empty()) {\nNode* node = worklist.front();\nworklist.pop_front();\n\n// A node may appear more than once as an operand of 'node'. Keep track of\n// which operands have been handled in a set.\nunique_operands.clear();\nfor (Node* operand : node-&gt;operands()) {\nif (unique_operands.insert(operand).second) {\nif (operand-&gt;users().size() == 1 &amp;&amp; is_deletable(operand)) {\nworklist.push_back(operand);\n}\n}\n}\nXLS_VLOG(3) &lt;&lt; \"DCE removing \" &lt;&lt; node-&gt;ToString();\nXLS_RETURN_IF_ERROR(f-&gt;RemoveNode(node));\nremoved_count++;\n}\n</code></pre> <p>Finally, a pass has to indicate whether or not it made any changes to the IR. For this pass, this amounts to returning whether or not a single IR node has been DCE'ed:</p> <pre><code>  XLS_VLOG(2) &lt;&lt; \"Removed \" &lt;&lt; removed_count &lt;&lt; \" dead nodes\";\nreturn removed_count &gt; 0;\n}\n</code></pre>"},{"location":"optimizations/#common-subexpression-elimination-cse","title":"Common Subexpression Elimination (CSE)","text":"<p>Common subexpression elimination is another example of a classic compiler optimization that equally applies to high-level synthesis. The heuristics on which specific expressions to commonize may differ, given that commonizing expressions can increase fan-out and connectivity of the IR, complicating place and route. Currently, XLS is greedy and does not apply heuristics. It commonizes any and all common expressions it can find. The CSE implementation can be found in files <code>xls/passes/cse_pass.*</code>.</p> <p>What does CSE actually do? The principles are quite simple and similar in classic control-flow based compilers. Yet, as mentioned, the heuristics may be moderately different. In CFG-based IRs, CSE would look for common expressions and substitute in temporary variables. For example, for code like this with the common expression <code>a+b</code>:</p> <pre><code>   x = a + b + c;\nif (cond) {\n...\n} else {\ny = b + a;\n}\n</code></pre> <p>The compiler would first determine that addition is commutative and that hence the expressions <code>a+b</code> and <code>b+a</code> can be canonicalized, eg., by ordering the operands alphabetically. Then the compiler would introduce a temporary variable for the expression and forward-substitute it into all occurances. For the example, the resulting code would be something like this:</p> <pre><code>   t1 = a + b\nx = t1 + c;\nif (cond) {\n...\n} else {\ny = t1;\n}\n</code></pre> <p>In effect, an arithmetic operation has been traded against a register (or cache) access. Even in classic compilers, the CSE heuristics may consider factors such as the length and number of live ranges (and corresponding register pressure) to determine whether or not it may be better to just recompute the expression.</p> <p>In XLS's \"sea of nodes\" IR, this transformation is quite simple. Given a graph that contains multiple common subexpressions, for example:</p> <pre><code>   A   B\n    \\ /\n     C1      A   B\n      \\       \\ /\n       ...     C2\n               /\n             op(C2)\n</code></pre> <p>XLS would find that <code>C1</code> and <code>C2</code> compute identical expressions and would simply replace the use of <code>C2</code> with <code>C1</code>, as in this graph (which will result in <code>C2</code> being dead-code eliminated):</p> <pre><code>   A   B\n    \\ /\n     C1      A   B\n      \\       \\ /\n       ...     C2\n         \\\n        op(C1)\n</code></pre> <p>Now let's see how this is implemented in XLS. CSE is a function-level transformation and accordingly the pass is derived from <code>FunctionBasePass</code>. In the header file:</p> <pre><code>class CsePass : public FunctionBasePass {\npublic:\nCsePass() : FunctionBasePass(\"cse\", \"Common subexpression elimination\") {}\n~CsePass() override {}\n\nprotected:\nabsl::StatusOr&lt;bool&gt; RunOnFunctionBaseInternal(\nFunctionBase* f, const PassOptions&amp; options,\nPassResults* results) const override;\n};\n</code></pre> <p>Several other optimizations passes expose new CSE opportunities. To make it easy to call CSE from these other passes, we declare a standalone function to call it. It accepts as input the function and returns a map containing the potential replacements of one node with another:</p> <pre><code>absl::StatusOr&lt;bool&gt; RunCse(FunctionBase* f,\nabsl::flat_hash_map&lt;Node*, Node*&gt;* replacements);\n</code></pre> <p>CSE conceptually has to check for each op and its operands whether or not a similar op exists somewhere else in the IR. To make this more efficient, XLS first computes a 64-bit hash for each node. It combines the nodes' opcode with all operands' IDs into a vector and computes the hash function over this vector.</p> <pre><code>  auto hasher = absl::Hash&lt;std::vector&lt;int64_t&gt;&gt;();\nauto node_hash = [&amp;](Node* n) {\nstd::vector&lt;int64_t&gt; values_to_hash = {static_cast&lt;int64_t&gt;(n-&gt;op())};\nstd::vector&lt;Node*&gt; span_backing_store;\nfor (Node* operand : GetOperandsForCse(n, &amp;span_backing_store)) {\nvalues_to_hash.push_back(operand-&gt;id());\n}\n// If this is slow because of many literals, the Literal values could be\n// combined into the hash. As is, all literals get the same hash value.\nreturn hasher(values_to_hash);\n};\n</code></pre> <p>Note that this procedure uses the function <code>GetOperandsForCse</code> to collect the operands. What does this function do? For nodes to be considered as equivalent, the operands must be in the same order. Commutative operands are agnostic to operand order. So in order to expand the opportunities for CSE, XLS sorts commutative operands by their ID. As an optimization, to avoid having to construct and return a full vector for each node and operands, the function gets a parameter to a vector of nodes to use as storage and returns a <code>absl::Span&lt;Node * const&gt;</code> over this backing store. This may look a bit confusing in the code but is really just a performance optimization:</p> <pre><code>absl::Span&lt;Node* const&gt; GetOperandsForCse(\nNode* node, std::vector&lt;Node*&gt;* span_backing_store) {\nXLS_CHECK(span_backing_store-&gt;empty());\nif (!OpIsCommutative(node-&gt;op())) {\nreturn node-&gt;operands();\n}\nspan_backing_store-&gt;insert(span_backing_store-&gt;begin(),\nnode-&gt;operands().begin(), node-&gt;operands().end());\nSortByNodeId(span_backing_store);\nreturn *span_backing_store;\n}\n</code></pre> <p>Now on to the meat of the optimization pass. As always, we have to maintain whether or not the pass modified the IR:</p> <pre><code>bool changed = false;\n</code></pre> <p>We store each first occurance of an expression in a map which is indexed by the expression's hash value. Since potentially there is no redundancy in the IR, we can pre-allocate this map to the size of function's IR. Note that non-common expressions may result in the same hash value. Because of that, <code>node_buckets</code> is a map from the hash value to a vector of nodes with the same hash value:</p> <pre><code>absl::flat_hash_map&lt;int64_t, std::vector&lt;Node*&gt;&gt; node_buckets;\nnode_buckets.reserve(f-&gt;node_count());\n</code></pre> <p>Now we iterate over the nodes in the IR, ignoring nodes that have side effects:</p> <pre><code>  for (Node* node : TopoSort(f)) {\nif (OpIsSideEffecting(node-&gt;op())) {\ncontinue;\n}\n</code></pre> <p>First thing to check is whether or not the op represents an expression that we have potentially already seen. If this is the first occurrance of the expression, which is efficient to check via the hash value, we store the op in <code>node_buckets</code> and continue with the next node.</p> <pre><code>    int64_t hash = node_hash(node);\nif (!node_buckets.contains(hash)) {\nnode_buckets[hash].push_back(node);\ncontinue;\n}\n</code></pre> <p>Now it is getting more interesting. We may have found a node that is common with a previously seen node. We collect the nodes operands (again, this looks a bit complicated because of the performance optimization):</p> <pre><code>    std::vector&lt;Node*&gt; node_span_backing_store;\nabsl::Span&lt;Node* const&gt; node_operands_for_cse =\nGetOperandsForCse(node, &amp;node_span_backing_store);\n</code></pre> <p>Then we iterate over all previously seen nodes with the same hash value which are stored in <code>node_buckets</code>. Again, the may be multiple expressions with the same hash value, hence we have to iterate over all candidates with that hash value.</p> <p>For each candidate, we collect the operands and then check whether the node is definitely identical to a previously seen node. In this case the node's uses can be replaced:</p> <pre><code>    for (Node* candidate : node_buckets.at(hash)) {\nstd::vector&lt;Node*&gt; candidate_span_backing_store;\nif (node_operands_for_cse ==\nGetOperandsForCse(candidate, &amp;candidate_span_backing_store) &amp;&amp;\nnode-&gt;IsDefinitelyEqualTo(candidate)) {\n[...]\n</code></pre> <p>If it was a match we replace the nodes, fill in the resulting replacement map, and mark the IR as modified. We also note whether a true match was found (via <code>replaced</code>):</p> <pre><code>        XLS_VLOG(3) &lt;&lt; absl::StreamFormat(\n\"Replacing %s with equivalent node %s\", node-&gt;GetName(),\ncandidate-&gt;GetName());\nXLS_RETURN_IF_ERROR(node-&gt;ReplaceUsesWith(candidate));\nif (replacements != nullptr) {\n(*replacements)[node] = candidate;\n}\nchanged = true;\nreplaced = true;\nbreak;\n}\n}\n</code></pre> <p>If, however, it turns out that while the hash value was identical but the ops were not identical, we have to update <code>node_buckets</code> and insert the new candidate.</p> <pre><code>    if (!replaced) {\nnode_buckets[hash].push_back(node);\n}\n</code></pre> <p>As a final step, we return whether or not the IR was modified:</p> <pre><code>  return changed;\n</code></pre>"},{"location":"optimizations/#constant-folding","title":"Constant Folding","text":"<p>Constant folding is another classic compiler optimization that equally applies to high-level synthesis. What does it do? Given an arithmetic expression that as inputs only as constant values, the compiler computes this expression at compile time and replaces it with the result. There are two complexities:</p> <ol> <li> <p>The IR has to be updated after the transformation.</p> </li> <li> <p>More importantly, the evaluation of the expression must match the semantics     of the target architecture!</p> </li> </ol> <p>Both problems are solved elegantly in XLS. The IR update itself is trivial to do with the sea-of-nodes IR. For expression evaluation, XLS simply re-uses the interpreter, which implements the correct semantics. Let's look again at the implementation, which is in file <code>xls/passes/constant_folding_pass.*</code>.</p> <p>We define the pass as usual and maintain whether or not the pass modified the IR in a boolean variable <code>changed</code>:</p> <pre><code>absl::StatusOr&lt;bool&gt; ConstantFoldingPass::RunOnFunctionBaseInternal(\nFunctionBase* f, const PassOptions&amp; options, PassResults* results) const {\nbool changed = false;\n</code></pre> <p>We now iterate over all nodes in the IR and check whether the node only has literals as operands as well as whether it is safe to replace the node.</p> <pre><code>  for (Node* node : TopoSort(f)) {\n[...]\nif (!node-&gt;Is&lt;Literal&gt;() &amp;&amp; !TypeHasToken(node-&gt;GetType()) &amp;&amp;\n!OpIsSideEffecting(node-&gt;op()) &amp;&amp;\nstd::all_of(node-&gt;operands().begin(), node-&gt;operands().end(),\n[](Node* o) { return o-&gt;Is&lt;Literal&gt;(); })) {\nXLS_VLOG(2) &lt;&lt; \"Folding: \" &lt;&lt; *node;\n</code></pre> <p>Here now comes the fun part. If the condition is true, XLS simply collects the operands in a vector and calls the interpreter to compute the result. Again, the interpreter has to implement the proper semantics, which leads to this exceedingly simple implementation.</p> <pre><code>      std::vector&lt;Value&gt; operand_values;\nfor (Node* operand : node-&gt;operands()) {\noperand_values.push_back(operand-&gt;As&lt;Literal&gt;()-&gt;value());\n}\nXLS_ASSIGN_OR_RETURN(Value result, InterpretNode(node, operand_values));\nXLS_RETURN_IF_ERROR(node-&gt;ReplaceUsesWithNew&lt;Literal&gt;(result).status());\nchanged = true;\n</code></pre>"},{"location":"optimizations/#assert-cleanup","title":"Assert Cleanup","text":"<p>Asserts whose condition is known to be true (represented by a 1-bit value of 1) are removed as they will never trigger. This pass is implemented in file <code>xls/passes/useless_assert_removel_pass.*</code> and is rather trivial. Again, it shows in a simple way how to navigate the IR:</p> <p>https://github.com/google/xls/blob/main/xls/passes/useless_assert_removal_pass.cc#L27-L43</p>"},{"location":"optimizations/#io-simplifications","title":"IO Simplifications","text":"<p>Conditional sends and receives that have a condition known to be false are replaced with their input token (in the case of sends) or a tuple containing their input token and a literal representing the zero value of the appropriate channel (in the case of receives). Conditional sends and receives that have a condition known to be true are replaced with unconditional sends and receives. These two transforms are implemented in file <code>xls/passes/useless_io_removal_pass.*</code>.</p>"},{"location":"optimizations/#reassociation","title":"Reassociation","text":"<p>Reassociation in XLS uses the associative and commutative property of arithmetic operations (such as adds and multiplies) to rearrange expressions of identical operations to minimize delay and area. Delay is reduced by transforming chains of operations into balanced trees which reduces the critical-path delay. For example, given the following expression:</p> <p></p> <p>This can be reassociated into the following balanced tree:</p> <p></p> <p>The transformation has reduced the critical path through the expression from three adds down to two adds.</p> <p>Reassociation can also create opportunities for constant folding. If an expression contains multiple literal values (constants) the expressions can be reassociated to gather literals into the same subexpression which can then be folded. Generally this requires the operation to be commutative as well as associative. For example, given the following expression:</p> <p></p> <p>This can be reassociated into:</p> <p></p> <p>The right-most add of the two literals can be folded reducing the number of adds in the expression to two.</p>"},{"location":"optimizations/#narrowing-optimizations","title":"Narrowing Optimizations","text":"<p>The XLS compiler performs bitwise flow analysis, and so can deduce that certain bits in the output of operations are always-zero or always-one. As a result, after running this bit-level tracking flow analysis, some of the bits on the output of an operation may be \"known\". With known bits in the output of an operation, we can often narrow the operation to only produce the unknown bits (those bits that are not known static constants), which reduces the \"cost\" of the operation (amount of delay through the operation) by reducing its bitwidth.</p>"},{"location":"optimizations/#select-operations","title":"Select operations","text":"<p>An example of this is select narrowing, as shown in the following -- beforehand we have three operands, but from our bitwise analysis we know that there are two constant bits in the MSb as well as two constant bits in the LSb being propagated from all of our input operands.</p> <p></p> <p>Recognizing that property, we squeeze the one hot select operation -- in the \"after\" diagram below observe we've narrowed the operation by slicing the known-constant bits out of the one hot select operation, making it cheaper in terms of delay, and propagated the slices up to the input operands -- these slices being presented at the output of the operands may in turn let them narrow their operation and become cheaper, and this can continue transitively):</p> <p></p>"},{"location":"optimizations/#arithmetic-and-shift-operations","title":"Arithmetic and shift operations","text":"<p>Most arithmetic ops support mixed bit widths where the operand widths may not be the same width as each other or the result. This provides opportunities for narrowing. Specifically (for multiplies, adds and subtracts):</p> <ol> <li> <p>If the operands are wider than the result, the operand can be truncated to     the result width.</p> </li> <li> <p>If the operation result is wider than the full-precision width of the     operation, the operation result can be narrowed to the full-precision width     then sign- or zero-extended (depending upon the sign of the operation) to     the original width to produce the desired result. The full-precision width     of an add or subtract is one more than the width of the widest operand, and     the full-precision width of a multiply is the sum of the operand widths.</p> </li> <li> <p>If the most-significant bit of an operand are zeros (for unsigned     operations) or the same as the sign-bit value (for signed operations), the     operand can be narrowed to remove these known bits.</p> </li> </ol> <p>As a special case, adds can be narrowed if the least-significant bits of an is all zeros. The add operation is narrowed to exclude this range of least-significant bits. The least-significant bits of the result are simply the least-significant bits of the non-zero operand:</p> <p></p> <p>Similarly, if the most-significant bits of the shift-amount of a shift operation are zero the shift amount can be narrowed.</p>"},{"location":"optimizations/#comparison-operations","title":"Comparison operations","text":"<p>Leading and trailing bits can be stripped from the operands of comparison operations if these bits do not affect the result of the comparison. For unsigned comparisons, leading and trailing bits which are identical between the two operands can be stripped which narrows the comparison and reduces the cost of the operation.</p> <p>Signed comparison are more complicated to handle because the sign bit (most-significant bit) affects the interpretation of the value of the remaining bits. Stripping leading bits must preserve the sign bit of the operand.</p>"},{"location":"optimizations/#known-literals-and-arrayindex","title":"Known-literals and <code>ArrayIndex</code>","text":"<p>The narrowing pass also converts any node that is determined by range analysis to have a range containing only one value into a literal. As a further extension of this idea, it also converts <code>ArrayIndex</code> nodes that are determined to have a small number of possible indices into select chains.</p> <p>This latter optimization is sometimes harmful, so we currently hide it behind the <code>--convert_array_index_to_select=&lt;n&gt;</code> flag in <code>opt_main</code> and <code>benchmark_main</code>, where <code>&lt;n&gt;</code> controls the number of possible array indices above which the optimization does not fire. The right number to put there is highly contextual, since this optimization relies heavily on later passes to clean up its output.</p>"},{"location":"optimizations/#strength-reductions","title":"Strength Reductions","text":""},{"location":"optimizations/#arithmetic-comparison-strength-reductions","title":"Arithmetic Comparison Strength Reductions","text":"<p>When arithmetic comparisons occur with respect to constant values, comparisons which are be arithmetic in the general case may be strength reduced to more boolean-analyzeable patterns; for example, comparison with mask constants:</p> <pre><code>u4:0bwxyz &gt; u4:0b0011\n</code></pre> <p>Can be strength reduced -- for the left hand side to be greater one of the <code>wx</code> bits must be set, so we can simply replace this with an or-reduction of <code>wx</code>. Similarly, a trailing-bit and-reduce is possible for less-than comparisons.</p> <p>NOTE These examples highlight a set of optimizations that are not applicable (profitable) on traditional CPUs: the ability to use bit slice values below what we'd traditionally think of as a fundamental comparison \"instruction\", which would nominally take a single cycle.</p>"},{"location":"optimizations/#simple-boolean-simplification","title":"\"Simple\" Boolean Simplification","text":"<p>NOTE This optimization is a prelude to a more general optimization we expect to come in the near future that is based on Binary Decision Diagrams. It is documented largely as a historical note of an early / simple optimization approach.</p> <p>With the addition of the <code>one_hot_select</code> and its corresponding optimizations, a larger amount of boolean logic appears in XLS's optimized graphs (e.g. or-ing together bits in the selector to eliminate duplicate <code>one_hot_select</code> operands). Un-simplified boolean operations compound their delay on the critical path; with the process independent constant \\(\\tau\\) a single bit <code>or</code> might be \\(6\\tau\\), which is just to say that having lots of dependent <code>or</code> operations can meaningfully add up in the delay estimation for the critical path. If we can simplify several layers of boolean operations into one operation (say, perhaps with inputs optionally inverted) we could save a meaningful number of tau versus a series of dependent boolean operations.</p> <p>For a simple approach to boolean simplification:</p> <ul> <li>The number of parameters to the boolean function is limited to three inputs</li> <li>The truth table is computed for the aggregate boolean function by flowing     input bit vectors through all the boolean operation nodes.</li> <li>The result bit vectors on the output frontier are matched the resulting     truth table from the flow against one of our standard operations (perhaps     with the input operands inverted).</li> </ul> <p>The algorithm starts by giving <code>x</code> and <code>y</code> their vectors (columns) from the truth table, enumerating all possible bit combinations for those operands. For example, consider two operands and a (bitwise) boolean function, the following is the truth table:</p> <pre><code>X Y | X+~Y\n----+------\n0 0 |  1\n0 1 |  0\n1 0 |  1\n1 1 |  1\n</code></pre> <p>Each column in this table is a representation of the possibilities for a node in the graph to take on, as a vector. After giving the vector <code>[0, 0, 1, 1]</code> to the first input node (which is arbitrarily called X) and the vector <code>[0, 1, 0, 1]</code> to the second input node (which is arbitrarily called Y), and flowing those bit vectors through a network of boolean operations, if you wind up with a vector <code>[1, 0, 1, 1]</code> at the end, it is sound to replace that whole network with the expression <code>X+~Y</code>. Similarly, if the algorithm arrived at the vector <code>[1, 1, 1, 1]</code> at the end of the network, you could replace the result with a literal <code>1</code>, because it has been proven for all input operand possibilities the result is always <code>1</code> in every bit. Effectively, this method works by brute force enumerating all the possibilities for input bits and operating on all of those possibilities at the same time. In the end, the algorithm arrives at a composite boolean function that can be pattern matched against XLS's set of \"simple boolean functions\".</p> <p>In the following example there are two nodes on the \"input frontier\" for the boolean operations (<code>sub</code> and <code>add</code>, which we \"rename\" to <code>x</code> and <code>y</code> for the purposes of analysis).</p> <p></p> <p>As shown in the picture, the algorithm starts flowing the bit vector, which represents all possible input values for <code>x</code> and <code>y</code>. You can see that the <code>not</code> which produces \\(\\bar{x}\\) (marked with a red star) simply inverts all the entries in the vector and corresponds to the \\(\\bar{x}\\) column in the truth table. Similarly the <code>and</code> operation joins the two vector with the binary <code>&amp;</code> operation, and finally we end up with the blue-starred bit vector on the \"output frontier\", feeding the dependent <code>one_hot_select</code> (marked as <code>ohs</code> in the diagram).</p> <p>When we resolve that final result bit vector with the blue star against our table of known function substitutions, we see that the final result can be replaced with a node that is simply <code>or(x, y)</code>, saving two unnecessary levels of logic, and reducing the critical path delay in this example from something like \\(13\\tau\\) to something like \\(6\\tau\\).</p> <p>This basic procedure is then extended to permit three variables on the input frontier to the boolean expression nodes, and the \"known function\" table is extended to include all of our supported logical operators (i.e. <code>nand</code>, <code>nor</code>, <code>xor</code>, <code>and</code>, <code>or</code>) with bit vectors for all combinations of inputs being present, and when present, either asserted, or their inversions (e.g. we can find \\(nand(\\bar{X}, Y)\\) even though X is inverted).</p>"},{"location":"optimizations/#bit-slice-optimizations","title":"Bit-slice optimizations","text":"<p>Bit-slice operations narrow values by selecting a contiguous subset of bits from their operand. Bit-slices are zero-cost operations as no computation is performed. However, optimization of bit-slices can be beneficial as bit-slices can interfere with optimizations and hoisting bit-slices can narrow other operations reducing their computation cost.</p>"},{"location":"optimizations/#slicing-sign-extended-values","title":"Slicing sign-extended values","text":"<p>A bit-slice of a sign-extended value is a widening operation followed by a narrowing operation and can be optimized. The details of the transformation depends upon relative position of the slice and the sign bit of the original value. Let <code>sssssssXXXXXXXX</code> be the sign-extended value where <code>s</code> is the sign bit and <code>X</code> represents the bits of the original value. There are three possible cases:</p> <ol> <li> <p>Slice is entirely within the sign-extend operand.</p> <p></p> <p>Transformation: replace the bit-slice of the sign-extended value with a   bit-slice of the original value.</p> </li> <li> <p>Slice spans the sign bit of the sign-extend operand.</p> <p></p> <p>Transformation: slice the most significant bits from the original value   and sign-extend the result.</p> </li> <li> <p>Slice is entirely within the sign-extended bits.</p> <p></p> <p>Transformation: slice the sign bit from the original value and   sign-extend it.</p> </li> </ol> <p>To avoid introducing additional sign-extension operations cases (2) and (3) should only be performed if the bit-slice is the only user of the sign-extension.</p>"},{"location":"optimizations/#concat-optimizations","title":"Concat optimizations","text":"<p><code>Concat</code> (short for concatenation) operations join their operands into a single word. Like <code>BitSlice</code>s, <code>Concat</code> operations have no cost since since they simply create a new label to refer to a set of bits, performing no actual computation. However, <code>Concat</code> optimizations can still provide benefit by reducing the number of IR nodes (increases human readability) or by refactoring the IR in a way that allows other optimizations to be applied. Several <code>Concat</code> optimizations involve hoisting an operation on one or more <code>Concat</code>s to above the <code>Concat</code> such that the operation is applied on the <code>Concat</code> operands directly. This may provide opportunities for optimization by bringing operations which actually perform logic closer to other operations performing logic.</p>"},{"location":"optimizations/#hoisting-a-reverse-above-a-concat","title":"Hoisting a reverse above a concat","text":"<p>A <code>Reverse</code> operation reverses the order of the bits of the input operand. If a <code>Concat</code> is reversed and the <code>Concat</code> has no other consumers except for reduction operations (which are not sensitive to bit order), we hoist the <code>Reverse</code> above the <code>Concat</code>. In the modified IR, the <code>Concat</code> input operands are <code>Reverse</code>'d and then concatenated in reverse order, e.g. :</p> <pre><code>Reverse(Concat(a, b, c))\n=&gt; Concat(Reverse(c), Reverse(b), Reverse(a))\n</code></pre>"},{"location":"optimizations/#hoisting-a-bitwise-operation-above-a-concat","title":"Hoisting a bitwise operation above a concat","text":"<p>If the output of multiple <code>Concat</code> operations are combined with a bitwise operation, the bitwise operation is hoisted above the <code>Concat</code>s. In the modified IR, we have a single <code>Concat</code> whose operands are bitwise'd <code>BitSlice</code>s of the original <code>Concat</code>s, e.g. :</p> <pre><code>Or(Concat(A, B), Concat(C, D)), where A,B,C, and D are 1-bit values\n=&gt; Concat(Or(Concat(A, B)[1], Concat(C, D)[1]), Or(Concat(A, B)[0], Concat(C, D)[0]))\n</code></pre> <p>In the case that an added <code>BitSlice</code> exactly aligns with an original <code>Concat</code> operand, other optimizations (bit slice simplification, constant folding, dead code elimination) will replace the <code>BitSlice</code> with the operand, e.g. for the above example:</p> <pre><code>=&gt; Concat(Or(A, C), Or(B, D))\n</code></pre>"},{"location":"optimizations/#merging-consecutive-bit-slices","title":"Merging consecutive bit-slices","text":"<p>If consecutive <code>Concat</code> operands are consecutive <code>BitSlice</code>s, we create a new, merged <code>BitSlice</code> spanning the range of the consecutive <code>BitSlice</code>s. Then, we create a new <code>Concat</code> that includes this <code>BitSlice</code> as an operand, e.g.</p> <pre><code>Concat(A[3:2], A[1:0], B)\n=&gt; Concat(A[3:0], B)\n</code></pre> <p>This optimization is sometimes helpful and sometimes harmful, e.g. in the case that there are other consumers of the original <code>BitSlice</code>s, we may only end up adding more IR nodes since the original <code>BitSlice</code>s will not be removed by DCE once they are replaced in the <code>Concat</code>. Some adjustments might be able to help with this issue. An initial attempt at this limited the application of this optimization to cases where the given<code>Concat</code> is the only consumer of the consecutive <code>BitSlice</code>s. This limited the more harmful applications of this optimization, but also reduced instances in which the optimization was beneficially applied (e.g. the same consecutive <code>BitSlice</code>s could be merged in multiple <code>Concat</code>s).</p>"},{"location":"optimizations/#select-optimizations","title":"Select optimizations","text":"<p>XLS supports two types of select operations:</p> <ol> <li> <p><code>Select</code> (opcode <code>Op::kSel</code>) is a traditional multiplexer. An <code>n</code>-bit     binary-encoded selector chooses among 2**<code>n</code> inputs.</p> </li> <li> <p><code>OneHotSelect</code> (opcode <code>Op::kOneHotSel</code>) has one bit in the selector for     each input. The output of the operation is equal to the logical-or reduction     of the inputs corresponding to the set bits of the selector. Generally, a     <code>OneHotSelect</code> is lower latency and area than a <code>Select</code> as a <code>Select</code> is     effectively a decode operation followed by a <code>OneHotSelect</code>.</p> </li> </ol>"},{"location":"optimizations/#converting-chains-of-selects-to-into-a-single-onehotselect","title":"Converting chains of <code>Select</code>s to into a single <code>OneHotSelect</code>","text":"<p>A linear chain of binary <code>Select</code> operations may be produced by the front end to select amongst a number of different values. This is equivalent to nested ternary operators in C++.</p> <p></p> <p>A chain of <code>Select</code>s has high latency, but latency may be reduced by converting the <code>Select</code> chain into a single <code>OneHotSelect</code>. This may only be performed if the single-bit selectors of the <code>Select</code> instructions are one-hot (at most one selector is set at one time). In this case, the single-bit <code>Select</code> selectors are concatenated together to produce the selector for the one hot.</p> <p></p> <p>This effectively turns a serial operation into a lower latency parallel one. If the selectors of the original <code>Select</code> instructions can be all zero (but still at most one selector is asserted) the transformation is slightly modified. An additional selector which is the logical NOR of all of the original <code>Select</code> selector bits is appended to the <code>OneHotSelect</code> selector and the respective case is the value selected when all selector bits are zero (<code>case_0</code> in the diagram).</p>"},{"location":"optimizations/#specializing-select-arms","title":"Specializing select arms","text":"<p>Within any given arm of a <code>Select</code> multiplexer, we can assume that the selector has the specific value required to select that arm. This assumption is safe because in the event that the selector has a different value, the arm is dead.</p> <p></p> <p>This makes it possible to try specialize the arms based on the selector value. In the above example, a LHS of <code>Selector + x</code> could be simplified to <code>0 + x</code>.</p> <p>The current optimization simply substitutes any usages of the selector in a <code>Select</code> arm with its known value in that arm. Future improvements could use range based analysis or other techniques to narrow down the possible values of any variables within the selector, and use that information to optimize the select arms.</p>"},{"location":"optimizations/#consecutive-selects-with-identical-selectors","title":"Consecutive selects with identical selectors","text":"<p>Two consecutive two-way selects which use the same selector can be compacted into a single select statement. The selector only has two states so only two of the three different cases may be selected. The third is dead. Visually, the transformation looks like:</p> <p></p> <p>The specific cases which remain in the new select instruction depends on whether the upper select feeds the true or false input of the lower select.</p>"},{"location":"optimizations/#sparsifying-selects-with-range-analysis","title":"Sparsifying selects with range analysis","text":"<p>If range analysis determines that the selector of a select has fewer possible values than the number of cases, we can do a form of dead code elimination to remove the impossible cases.</p> <p>Currently, we do this in the following way:</p> <pre><code>// Suppose bar has interval set {[1, 4], [6, 7], [10, 13]}\nfoo = sel(bar, cases=[a1, ..., a16])\n// Sparsification will lead to the following code:\nfoo = sel((bar &gt;= 1) &amp;&amp; (bar &lt;= 4), cases=[\n  sel((bar &gt;= 6) &amp;&amp; (bar &lt;= 7), cases=[\n    sel(bar - 10, cases=[a11, ..., a14], default=0),\n    sel(bar - 6, cases=[a7, a8], default=0)\n  ]),\n  sel(bar - 1, cases=[a2, ..., a5], default=0)\n])\n</code></pre> <p>This adds a little bit of code for the comparisons and subtractions but is generally worth it since eliminating a case branch can be a big win.</p>"},{"location":"optimizations/#binary-decision-diagram-based-optimizations","title":"Binary Decision Diagram based optimizations","text":"<p>A binary decision diagram (BDD) is a data structure that can represent arbitrary boolean expressions. Properties of the BDD enable easy determination of relationships between different expressions (equality, implication, etc.) which makes them useful for optimization and analysis</p>"},{"location":"optimizations/#bdd-common-subexpression-elimination","title":"BDD common subexpression elimination","text":"<p>Determining whether two expression are equivalent is trivial using BDDs. This can be used to identify operations in the graph which produce identical results. BDD CSE is an optimization pass which commons these equivalent operations.</p>"},{"location":"optimizations/#onehot-msb-elimination","title":"OneHot MSB elimination","text":"<p>A <code>OneHot</code> instruction returns a bitmask with exactly one bit equal to 1. If the input is not all-0 bits, this is the first 1 bit encountered in the input going from least to most significant bit or vice-versa depending on the priority specified. If the input is all-0 bits, the most significant bit of the <code>OneHot</code> output is set to 1. The semantics of <code>OneHot</code> are described in detail here. If the MSB of a <code>OneHot</code> does not affect the functionality of a program, we replace the MSB with a 0-bit, e.g.</p> <pre><code>OneHot(A) such that the MSB has no effect\n\u21d2 Concat(0, OneHot(A)[all bits except MSB]))\n</code></pre> <p>This can open up opportunities for further optimization. To determine if a <code>OneHot</code>\u2019s MSB has any effect on a function, we iterate over the <code>OneHot</code>\u2019s post-dominators. We use the BDD to test if setting the <code>OneHot</code>\u2019s MSB to 0 or to 1 (other bits are 0 in both cases) implies the same value for the post-dominator node. If so, we know the value of the MSB cannot possibly affect the function output, so the MSB can safely be replaced with a 0 bit. Note: This approach assumes that IR nodes do not have any side effects. When IR nodes with side effects are introduced (i.e. channels) the analysis for this optimization will have to be adjusted slightly to account for this.</p>"},{"location":"scheduling/","title":"XLS Pipeline scheduling","text":"<ul> <li>XLS Pipeline scheduling<ul> <li>Scheduling process<ul> <li>Step 1: determine the effective clock period</li> <li>Step 2: schedule to minimize pipeline registers</li> <li>Options for common scheduling objectives</li> </ul> </li> <li>Minimizing pipeline registers via min-cut</li> <li>Rematerialization</li> </ul> </li> </ul> <p>Pipeline scheduling divides the IR nodes of an XLS function or proc into a sequence of stages constituting a feed-forward pipeline. Sequential stages are separated by registers enabling pipeline parallelism. The schedule must satisfy dependency constraints between XLS nodes as well as timing constraints imposed by the target clock frequency. Pipeline scheduling has multiple competing optimization objectives: minimize number of stages (minimize pipeline latency), minimize maximum delay of any stage (maximize clock frequency), and minimize the number of pipeline registers.</p>"},{"location":"scheduling/#scheduling-process","title":"Scheduling process","text":"<p>Pipeline scheduling occurs in two phases:</p> <ol> <li> <p>Determine the effective clock period. This clock period defines the maximum     delay, based on XLS's internal delay model, through     any pipeline stage and limits how many IR operations might be placed in each     stage.</p> </li> <li> <p>Given the constraints of the effective clock period and, optionally, a     user-defined number of pipeline stages, find the schedule which minimizes     the number of pipeline registers. Pipeline registers are required for any IR     operation whose value which is used in a later stage.</p> </li> </ol> <p>The schedule process is controlled via several options defined here. These options are typically passed in as flags to the <code>codegen_main</code> binary but maybe set programmatically. Each is optional though at least one of clock period or pipeline stages must be specified. Different combinations of options result in different strategies as described below.</p> <p>Clock period :   The target clock period.</p> <p>Pipeline stages :   The number of stages in the pipeline.</p> <p>Clock margin percent :   The percentage to reduce the target clock period before scheduling. May only     be specified with clock period. This option is equivalent to specifying     a reduced value for clock period.</p> <p>Clock period relaxation percent: :   This is the percentage that the computed minimum clock period, as determined     by the number of pipeline stages, is increased (relaxed) prior to     scheduling. May not be specified with clock period.</p>"},{"location":"scheduling/#step-1-determine-the-effective-clock-period","title":"Step 1: determine the effective clock period","text":"<p>The effective clock period determines the maximum delay through any pipeline stage for the purpose of scheduling. The value is determined in one of two ways depending upon whether the clock period option is specified.</p> <ol> <li> <p>clock period specified</p> <p>The effective clock period is set the clock period value. If clock   margin percent is also specified, then the effective clock period is also   reduced by the given percentage. Example: if clock period is 800ps and   clock margin percent is 20% then the effective clock period is 640ps.</p> </li> <li> <p>clock period not specified</p> <p>In this case, pipeline stages must be specified. The effective clock   period is computed as the minimum clock period in which a schedule may be   found that meets timing with the specified number of pipeline stages. This   is done via a binary search through clock period values. If clock period   relaxation percent is specified then the computed effective clock period   is increased by the given percentage. The motivation is that this   relaxation may result in fewer pipeline registers because of increased   scheduling flexibility. Example: if the minimum clock period found by XLS   was 1000ps and clock period relaxation percent is 10% the effective   clock period is 1100ps.</p> </li> </ol>"},{"location":"scheduling/#step-2-schedule-to-minimize-pipeline-registers","title":"Step 2: schedule to minimize pipeline registers","text":"<p>Once an effective clock period is determined, XLS computes a schedule which minimizes the number of registers (see below for details) while satisfying the critical path delay constraints imposed by the effective clock period. The number of stages in the pipeline may be specified by the user via the pipeline stages option. If the number of pipeline stages specified is too small an error such that no feasible schedule can be found then an error is returned. If pipeline stages is not given then the minimum number of stages which meets the delay constraint imposed by the effective clock period is used.</p>"},{"location":"scheduling/#common-options","title":"Options for common scheduling objectives","text":"<p>Different scheduling options result in different optimization strategies for the scheduler. Below are several common scheduling objectives and options which should be set to enable them.</p> <ol> <li> <p>Minimize the number of pipeline registers for a given clock period and given     number of pipeline stages.</p> <p>Specify both clock period and pipeline stages. The scheduler will   attempt to minimize the number of pipeline registers given those   constraints. The option clock margin percent can be swept to search the   local design space (or equivalently, sweep clock period)</p> </li> <li> <p>Minimize the clock period for a given number of pipeline stages</p> <p>Specify only pipeline stages. XLS will find a schedule with minimum   clock period with a secondary objective of minimizing the number of pipeline   registers. Sweeping clock period relaxation percent explores relaxing   the timing constraint which may result in fewer pipeline registers.</p> </li> <li> <p>Minimize the number of pipeline stages for a given clock period</p> <p>Specify only clock period. XLS will find a schedule of the minimum   number of stages with a secondary objective of minimizing the number of   pipeline registers. The option clock margin percent can be swept to   search the local design space (or equivalently, sweep clock period)</p> </li> <li> <p>Minimize the number of pipeline registers for a given clock period</p> <p>Specify only clock period and sweep pipeline stages. Pick the   schedule which produces the minimum number of pipeline registers.</p> </li> <li> <p>Sweep the entire scheduling space</p> <p>The various options directly or indirectly control the two degrees of   freedom within the scheduler: pipeline stages and clock period. Sweeping   these two degrees of freedom is most easily done by sweeping pipeline   stages and clock period relaxation percent. The advantage of sweeping   clock period relaxation percent instead of clock period directly is   that the percent relaxation can be a fixed range (e.g., 0 to 50%) for all   designs and each value will produce a feasible schedule. If clock period   is swept some combinations of pipeline stages* and clock period** values   will result in an error returned because the design point is infeasible.</p> </li> </ol>"},{"location":"scheduling/#min-cut","title":"Minimizing pipeline registers via min-cut","text":"<p>Scheduling to minimize pipeline registers can be formulated as a graph min-cut problem where the graph cut divides the nodes of the graph into separate pipeline stages and the cost of the cut is the number of bits in the pipeline register between the stages. This formulation of the pipeline scheduling problem is attractive because the graph min-cut problem can be solved in polynomial time.</p> <p>In general, the XLS IR graph cannot be used directly by the min-cut algorithm because of additional constraints imposed by pipeline scheduling and features of the IR graph. As a motivating example, consider the following graph of an XLS function to be scheduled into a two-stage pipeline:</p> <p></p> <p>Node x is a parameter to the function, and node F is the return value. The width of the edges correlates with the (labeled) bit width of the respective operation. The bit width of the edges are edge weights in the min-cut algorithm.</p> <p>The drawing above shows the initial and final pipeline registers which flops the input output on the interface boundary. In this example, a two-stage pipeline is desired so one additional pipeline register is required. The scheduling problem is to partition the nodes A through F into the two pipeline stages while minimizing register count, or alternatively formulated, identify a cut through the graph of minimum cost. Below is one possible cut resulting in a pipeline schedule where nodes A and B are in stage one and nodes C through F are in stage two.</p> <p></p> <p>In the pipeline generated from the example cut above pipeline registers are required for nodes A and B of bit widths 2 and 32 respectively for a total of 34 flops. However this value is inconsistent with the cost of the cut in the IR graph which is equal to the sum of weights of the cut edges: 2 + 32 + 32 = 66. To reconcile the cost function, transformations are applied to the graph about nodes with fan-out. Specifically, an artificial node N' is added for each node N with fan-out and an edge is added from each immediate successor of N to N'. The weight of each edge fanning out from N and fanning into N' is set to the original weight of the edges of N divided by the fan-out factor. In the example, the edge weight is set to 32 / 2 = 16. Below is the transformed graph. As shown, the cost of the cut (sum of edge weights) now equals the number of flops in the pipeline register (34).</p> <p></p> <p>For scheduling the example graph, assume the target clock period be three time units and all nodes have unit delay. In this case, not all cuts will produce a schedule which satisfies the timing constraint. Specifically, if B is scheduled in the second stage, or F is scheduled in the first stage the pipeline cannot meet the timing constraint. To ensure the min-cut results in a schedule which satisfies timing an artificial source and sink node is added to the graph. Edges with infinite weight are added from the source to nodes which must be scheduled in the first stage (or earlier in the case of parameter nodes) to satisfy timing constraints. Similar edges are added from nodes which must be scheduled in the second stage to the sink node as shown below:</p> <p></p> <p>One additional transformation (not shown) is required to ensure a correct pipeline. Generally, a partitioning created by a min-cut allows edges going in both directions between the partitions. However, pipeline stages do not allow circular dependencies. To enforce directionality to the edges of the cut, an edge of infinite weight is added parallel to and in the opposite direction of every edge in the graph.</p> <p>After transforming the graph, a min-cut is found by applying a max flow algorithm (Ford-Fulkerson) from the artificial source node to the artificial sink node. In the running example, the min cut is edges C -&gt; F and E -&gt; F of cost 12. All nodes except F are placed in the first stage of the pipeline.</p> <p>Generally, a pipeline can have more than two stages so a single cut is insufficient to determine a schedule. In this case a sequence of cuts is performed, one for each boundary between pipeline stages. Each min-cut partitions the nodes into two parts: the set of nodes scheduled before the respective stage boundary, and the set of node scheduled after. This imposes additional constraints on later min-cut computations. These constraints are imposed by extending infinite weight edges between these nodes and the source or sink node in the graph.</p> <p>The order in which the sequence of cuts is performed (e.g., cut the boundary between stage 0 and stage 1, then between 1 and 2, then between 2 and 3, and so on) can affect the total number of pipeline flops so, in general, multiple orders are attempted and the result with the fewest pipeline flops is kept.</p>"},{"location":"scheduling/#rematerialization","title":"Rematerialization","text":"<p>TODO(meheff): Finish.</p>"},{"location":"solvers/","title":"XLS Solvers","text":"<p>Programs that are represented as optimized XLS IR are converted into circuits based on boolean logic, and so it is also possible to feed those as logical operations to a theorem prover.</p> <p>We have implemented that conversion with the Z3 theorem prover using its \"bit vector\" type support. As a result, you can conceptually ask Z3 to prove any predicate that can be expressed as XLS, over all possible parameter inputs.</p> <p>See the tools documentation for usage information on related command line tools.</p>"},{"location":"solvers/#applications","title":"Applications","text":"<p>This facility is expected to be useful to augment random testing. While profiling the values in an XLS IR function that is given random stimulus, we may observe bits that result from nodes that appear to be constant (but are not created via a \"literal\" or a \"concat\" of a literal).</p> <p>Example: Say the value resulting from <code>and.1234</code> in the graph appears to be constant zero with all the stimulus provided via a fuzzer thus far -- the solver provides a facility whereby we can ask \"is there a counterexample to <code>and.1234</code> always being zero?\" and the solver will either say \"no, it is always zero\", or it will yield a counterexample, or will not terminate within the allocated deadline.</p> <p>Assuming we can prove useful properties in a reasonable amount of time, we can use this proof capability to help find interesting example inputs that provide unique stimulus.</p>"},{"location":"solvers/#correctness-wrt-reference-32-bit-floating-point-adder","title":"Correctness WRT reference: 32-bit Floating-Point Adder","text":"<p>The full input space for a 32-bit adder is a whopping 64 bits - far more than is possible to exhaustively test for correctness. Proving correctness via Z3, however, is relatively straightforward: at a high level, one simply compares the output from the DSLX (translated into Z3) to the same operation performed solely in Z3.</p> <p>In detail, the steps are:</p> <ol> <li>Translate the DSLX implementation into Z3 via     <code>Z3Translator::CreateAndTranslate()</code>.</li> <li>Create a Z3 implementation of the same addition. This is nearly trivial, as     Z3 helpfully has built-in support for floating-point values and theories.</li> <li>Take the result nodes from each \"branch\" above and create a new node     subtracting the two. This is the absolute error. Note: Usually, one is     interested in relative error when working with FP values, but here, our     target is absolute equivalence, so absolute error sufficies (and is     simpler).</li> <li>Create a Z3 node comparing that error to the maximum bound (here 0.0f).</li> <li>Feed that error node into a Z3 solver, asking it to prove that the error     could be greater than that bound.</li> </ol> <p>If the solver can not satisfy that criterion, then that means the error is never greater than that bound, i.e., that the implementations are equivalent (with our 0.0f bound).</p>"},{"location":"solvers/#ir-transform-validity","title":"IR Transform validity","text":"<p>It's usually not possible (or is merely extremely difficult) to write tests to prove that an optimization/transform is safe across all input IR. By comparing the optimized vs. unoptimized IR in a similar manner as the correctness proof above, we can symbolically prove safety.</p> <p>The only difference between this and the correctness proof is that both the optimized and unoptimized IR need to be fed into the same Z3Translator (the second via <code>Z3Translator::AddFunction()</code>) and the result nodes each are used in the error comparison.</p>"},{"location":"solvers/#ir-to-netlist-logical-equivalence-checking-lec","title":"IR to netlist Logical Equivalence Checking (LEC)","text":"<p>After a user design has been lowered to IR, it is optimized (see the previous section), then Verilog is generated for that optimized IR. That Verilog is then compiled by an external tool, which, if successful, will output a \"netlist\" - a set of standard cells (think AND, OR, NOT, flops, etc.) and wires connecting them that realizes the design.</p> <p>Between the IR level and that netlist, many, many transformations are applied to the design. Before processing the netlist further - and certainly before sending the final design to fabrication - it's a very good idea to ensure that the netlist describes the correct logic!</p> <p>Demonstrating initial design correctness is up to the user, via unit tests or integration tests at the DSLX level. At all stages below that, though, ensuring logical equivalence between forms is XLS' responsibility. To prove equivalence between the IR and netlist forms of a design, XLS uses formal verification via solvers - currently only Z3, above.</p> <p>Performing IR-to-netlist LEC is very similar to the checking above - the source IR is one half of the comparison. Here, the second half is the netlist translated into IR, which only requires a small amount of extra work. Consider the snippet below:</p> <pre><code>FOO p1_and_1 ( .A(p0_i0), .B(p0_i1), .Z(p1_and_1_comb) );\nBAR p1_and_2 ( .A(p0_i2), .B(p0_i3), .Z(p1_and_2_comb) );\n</code></pre> <p>These lines describe, in order:</p> <ul> <li>One cell, called <code>FOO</code>, that takes two inputs, .A and .B, provided by the     wires <code>p0_i0</code> and <code>p0_i1</code>, respectively, and one output, .Z, which will be     assigned to the wire `p1_and_1_comb.</li> <li>One cell, called <code>BAR</code>, that takes two inputs, .A and .B, provided by the     wires <code>p0_i2</code> and <code>p0_i2</code>, respectively, and one output, .Z, which will be     assigned to the wire `p1_and_2_comb.</li> </ul> <p>Note that the values computed by the cells wasn't mentioned - that's because <code>FOO</code> and <code>BAR</code> are defined in the \"cell library\", the list of standard cells used to generate the netlist. Thus, to be able to model these gates in a solver, we need to take that cell library as input to the LEC tool. The netlist describes how cells are laid out, and the cell library indicates what cells actually do. With both of these in hand, preparing the netlist half of a LEC is a [relatively] straightforward matter of parsing a netlist and cell library and converting those together into a description of logic. See z3_netlist_translator.cc for full details.</p>"},{"location":"solvers/#utilities","title":"Utilities","text":"<ul> <li>tools/lec_main.cc:     Driver function for performing IR-to-netlist LEC.</li> <li>solvers/python/z3_lec.cc:     Wrapper to perform IR-to-netlist LEC from Python.</li> </ul>"},{"location":"solvers/#current-limitations","title":"Current Limitations","text":""},{"location":"solvers/#time-to-result","title":"Time-to-result","text":"<p>Under the hood, Z3 (and many other tools in this space) is an SMT solver. At a high level, think of an SMT solver as a SAT solver that has special handling for certain classes of data (bit vectors, floating-point numbers). Many sufficiently complicated problems will reduce to raw SAT solving (especially those involving netlists, which have to implement complex logic at the gate level. Consider what that means for a multiply, for example!). Since SAT scales exponentially with the size of its inputs, execution time can quickly grow past a point of utility for complex operations, notably multiplication. Fortunately, for most designs (without such complex ops), proving equivalence of a single pipeline stage can complete in a small amount of time (O(minutes)).</p>"},{"location":"solvers/#predicate-coverage","title":"Predicate coverage","text":"<p>Hypothetically, any XLS function that computes a predicate (bool) can be fed to Z3 for satisfiability testing. Currently a more limited set of predicates are exposed that can be easily expressed on the command line; however, it should be possible to provide:</p> <ul> <li>an XLS IR file</li> <li>a set of nodes in the entry function</li> <li>a DSLX function that computes a predicate on those nodes</li> </ul> <p>Which would allow the user to compute arbitrary properties of nodes in the function with the concise DSL syntax.</p>"},{"location":"solvers/#subroutines","title":"Subroutines","text":"<p>Z3 doesn't intrinsically have support for subroutines, or as they're called in Z3, \"macros\", instead requiring that all function calls be inlined.</p> <p>There is an extension that adds support for recursive function decls and defs, but in our experience, it doesn't behave the way we'd expect.</p> <p>Consider the following example:</p> <pre><code>package p\n\nfn mapper(value: bits[32]) -&gt; bits[32] {\n  ret value\n}\n\nfn main() -&gt; bits[1] {\n  literal_0: bits[32] = literal(value=0)\n  literal_1: bits[1] = literal(value=1)\n  elem_0: bits[32] = invoke(literal_0, to_apply=mapper)\n  eq_12: bits[1] = eq(literal_0, elem_0)\n  ret and_13: bits[1] = and(eq_12, literal_1)\n}\n</code></pre> <p>Here, it's trivial for a human reader to see that the results are the same; the output should be equal to 1. Z3, however, reports that this is not necessarily the case, suggesting that <code>literal_0</code> and <code>elem_0</code> would not be equal in the case where the input to <code>mapper</code> was 1...which is clearly never the case here.</p> <p>To address this, we require that all subroutines (including those used in maps and counted fors) be inlined before consumption by Z3.</p>"},{"location":"tools/","title":"XLS Tools","text":"<p>An index of XLS developer tools.</p>"},{"location":"tools/#bdd_stats","title":"<code>bdd_stats</code>","text":"<p>Constructs a binary decision diagram (BDD) using a given XLS function and prints various statistics about the BDD. BDD construction can be very slow in pathological cases and this utility is useful for identifying the underlying causes. Accepts arbitrary IR as input or a benchmark specified by name.</p>"},{"location":"tools/#benchmark_main","title":"<code>benchmark_main</code>","text":"<p>Prints numerous metrics and other information about an XLS IR file including: total delay, critical path, codegen information, optimization time, etc. This tool may be run against arbitrary IR not just the fixed set of XLS benchmarks. The output of this tool is scraped by <code>run_benchmarks</code> to construct a table comparing metrics against a mint CL across the benchmark suite.</p>"},{"location":"tools/#booleanify_main","title":"<code>booleanify_main</code>","text":"<p>Rewrites an XLS IR function in terms of its ops' fundamental AND/OR/NOT constituents, i.e., makes all operations boolean, thus it's \"booleanifying\" the function.</p>"},{"location":"tools/#codegen_main","title":"<code>codegen_main</code>","text":"<p>Lowers an XLS IR file into Verilog. Options include emitting a feedforward pipeline or a purely combinational block. Emits both a Verilog file and a module signature which includes metadata about the block. The tool does not run any XLS passes so unoptimized IR may fail if the IR contains constructs not expected by the backend.</p> <p>For a detailed list of codegen options including I/O configurations, please visit the codegen options page.</p>"},{"location":"tools/#delay_info_main","title":"<code>delay_info_main</code>","text":"<p>Dumps delay information about an XLS function including per-node delay information and critical-path.</p>"},{"location":"tools/#eval_ir_main","title":"<code>eval_ir_main</code>","text":"<p>Evaluates an XLS IR file with user-specified or random inputs. Includes features for evaluating the IR before and after optimizations which makes this tool very useful for identifying optimization bugs.</p> <p>This tool accepts two [mutually exclusive] optional args, <code>--input_validator_expr</code> and <code>--input_validator_path</code>, which allow the user to specify an expression to \"filter\" potential input values to discard invalid ones. For both, the filter must be a function, named <code>validator</code>, and must take params of the same layout as the function under test. This function should return true if the inputs are valid for the function and false otherwise. <code>--input_validator_expr</code> lists the function as an inline command-line argument, whereas <code>--input_validator_path</code> holds the path to a .x file containing the validation function.</p>"},{"location":"tools/#ir_minimizer_main","title":"<code>ir_minimizer_main</code>","text":"<p>Tool for reducing IR to a minimal test case based on an external test.</p>"},{"location":"tools/#ir_stats_main","title":"<code>ir_stats_main</code>","text":"<p>Prints summary information/stats on an IR [Package] file. An example:</p> <pre><code>$ bazel-bin/xls/tools/ir_stats_main bazel-genfiles/xls/modules/fp32_add_2.ir\nPackage \"fp32_add_2\"\n  Function: \"__float32__is_inf\"\n    Signature: ((bits[1], bits[8], bits[23])) -&gt; bits[1]\n    Nodes: 8\n\n  Function: \"__float32__is_nan\"\n    Signature: ((bits[1], bits[8], bits[23])) -&gt; bits[1]\n    Nodes: 8\n\n  Function: \"__fp32_add_2__fp32_add_2\"\n    Signature: ((bits[1], bits[8], bits[23]), (bits[1], bits[8], bits[23])) -&gt; (bits[1], bits[8], bits[23])\n    Nodes: 252\n</code></pre>"},{"location":"tools/#check_ir_equivalence","title":"<code>check_ir_equivalence</code>","text":"<p>Verifies that two IR files (for example, optimized and unoptimized IR from the same source) are logically equivalent.</p>"},{"location":"tools/#opt_main","title":"<code>opt_main</code>","text":"<p>Runs XLS IR through the optimization pipeline.</p>"},{"location":"tools/#proto_to_dslx_main","title":"<code>proto_to_dslx_main</code>","text":"<p>Takes in a proto schema and a textproto instance thereof and outputs a DSLX module containing a DSLX type and constant matching both inputs, respectively.</p> <p>Not all protocol buffer types map to DSLX types, so there are some restrictions or other behaviors requiring explanation:</p> <ol> <li>Only scalar and repeated fields are supported (i.e., no maps or oneofs,     etc.).</li> <li>Only recursively-integral messages are supported, that is to say, a message     may contain submessages, as long as all non-Message fields are integral.</li> <li>Since DSLX doesn't support variable arrays and Protocol Buffers don't     support fixed-length repeated fields. To unify this, all instances of     repeated-field-containing Messages must have the same size of their repeated     members (declared as arrays in DSLX). This size will be calculated as the     maximum size of any instance of that repeated field across all instances in     the input textproto. For example, if a message <code>Foo</code> has a repeated field     <code>bar</code>, and this message is present multiple times in the input textproto,     say as:<pre><code>  foo: {\n    bar: 1\n  }\n  foo: {\n    bar: 1\n    bar: 2\n  }\n  foo: {\n    bar: 1\n    bar: 2\n    bar: 3\n  }\n</code></pre> <p>the DSLX version of <code>Foo</code> will declare <code>bar</code> has a 3-element array. An   accessory field, <code>bar_count</code>, will also be created, which will contain the   number of valid entries in an actual instance of <code>Foo::bar</code>.</p> <p>The \"Fields\" example in   <code>./xls/tools/testdata/proto_to_dslx_main.*</code> demonstrates this   behavior.</p> </li> </ol>"},{"location":"tools/#repl","title":"<code>repl</code>","text":"<p>Allows you to interactively run various parts of the compiler, including parsing/type checking (<code>:reload</code>), lowering/optimization (<code>:ir</code>), Verilog codegen (<code>:verilog [identifier]</code>), and LLVM codegen (<code>:llvm</code>, not yet implemented). You can also inspect the IR types of identifiers with <code>:type</code>, and even imported identifiers can be accessed with <code>:type foo::bar</code>.</p> <p></p>"},{"location":"tools/#simulate_module_main","title":"<code>simulate_module_main</code>","text":"<p>Runs an Verilog block emitted by XLS through a Verilog simulator. Requires both the Verilog text and the module signature which includes metadata about the block.</p>"},{"location":"tools/#smtlib_emitter_main","title":"<code>smtlib_emitter_main</code>","text":"<p>Simple driver for Z3IrTranslator - converts a given IR function into its Z3 representation and outputs that translation as SMTLIB2.</p> <p>First obtain an XLS IR file:</p> <pre><code>$ bazel build -c opt //xls/examples:tiny_adder.opt.ir\n</code></pre> <p>And then feed that XLS IR file into this binary:</p> <pre><code>$ bazel run -c opt //xls/tools:smtlib_emitter_main -- --ir_path \\\n    $PWD/bazel-bin/xls/examples/tiny_adder.opt.ir\n(bvadd (concat #b0 x) (concat #b0 y))\n</code></pre> <p>To turn it into \"gate level\" SMTLib, we can do a pre-pass through the <code>booleanify_main</code> tool:</p> <pre><code>$ bazel run -c opt //xls/tools:booleanify_main -- --ir_path \\\n   $PWD/bazel-bin/xls/examples/tiny_adder.opt.ir \\\n   &gt; /tmp/tiny_adder.boolified.ir\n$ bazel run -c opt //xls/tools:smtlib_emitter_main -- \\\n    --ir_path /tmp/tiny_adder.boolified.ir\n(let ((a!1 (bvand (bvor ((_ extract 0 0) x) ((_ extract 0 0) y))\n                  (bvnot (bvand ((_ extract 0 0) x) ((_ extract 0 0) y))))))\n(let ((a!2 (bvor (bvand (bvor #b0 #b0) (bvnot (bvand #b0 #b0)))\n                 (bvor (bvand ((_ extract 0 0) x) ((_ extract 0 0) y))\n                       (bvand a!1 #b0))))\n      (a!3 (bvand (bvand (bvor #b0 #b0) (bvnot (bvand #b0 #b0)))\n                  (bvor (bvand ((_ extract 0 0) x) ((_ extract 0 0) y))\n                        (bvand a!1 #b0)))))\n  (concat (bvand a!2 (bvnot a!3))\n          (bvand (bvor a!1 #b0) (bvnot (bvand a!1 #b0))))))\n</code></pre>"},{"location":"tools/#solver","title":"<code>solver</code>","text":"<p>Uses a SMT solver (i.e. Z3) to prove properties of an XLS IR program from the command line. Currently the set of \"predicates\" that the solver supports from the command line are limited, but in theory it is capable of solving for arbitrary IR-function-specified predicates.</p> <p>This can be used to uncover opportunities for optimization that were missed, or to prove equivalence of transformed representations with their original version.</p>"},{"location":"tools/#cell_library_extract_formula","title":"<code>cell_library_extract_formula</code>","text":"<p>Parses a cell library \".lib\" file and extracts boolean formulas from it that determine the functionality of cells. This is useful for LEC of the XLS IR against the post-synthesis netlist.</p>"},{"location":"tools/#dslxhighlight_main","title":"<code>dslx/highlight_main</code>","text":"<p>Performs terminal-based color code highlighting of a DSL file.</p>"},{"location":"tools/#dslxtypecheck_main","title":"<code>dslx/typecheck_main</code>","text":"<p>Dumps type information that has been deduced for a given DSL file.</p>"},{"location":"tools_quick_start/","title":"XLS Tools Quick Start","text":"<p>This document is a quick start guide through the use of the individual XLS tools, from DSL input to RTL generation.</p> <p>Note: This guide assumes you have set up your system so it can build the XLS tools via Bazel. There is currently no binary tools distribution so building from source is required.</p> <p>Create a file <code>/tmp/simple_add.x</code> with the following contents:</p> <pre><code>fn add(x: u32, y: u32) -&gt; u32 {\n  x + y + u32:0  // Something to optimize.\n}\n\n#[test]\nfn test_add() {\n  assert_eq(add(u32:2, u32:3), u32:5)\n}\n</code></pre> <p>This contains a function, and a unit test of that function.</p>"},{"location":"tools_quick_start/#interpreting-the-dsl-file","title":"Interpreting the DSL file","text":"<p>Now, run it through the DSL interpreter -- the DSL interpreter is useful for interactive development and debugging.</p> <pre><code>$ bazel run -c opt //xls/dslx:interpreter_main -- /tmp/simple_add.x\n[ RUN      ] add\n[       OK ] add\n</code></pre> <p>The DSL interpreter is the execution engine running the test shown.</p> <p>In lieu of using bazel run for the subsequent commands, this document will assume <code>bazel build -c opt //xls/...</code> has been completed so the binaries in <code>./bazel-bin</code> can be used directly:</p> <pre><code>$ ./bazel-bin/xls/dslx/interpreter_main /tmp/simple_add.x\n[ RUN      ] add\n[       OK ] add\n</code></pre>"},{"location":"tools_quick_start/#dsl-to-ir-conversion","title":"DSL to IR conversion","text":"<p>To convert the DSL file to IR, run the following command:</p> <pre><code>$ ./bazel-bin/xls/dslx/ir_converter_main --top=add /tmp/simple_add.x &gt; /tmp/simple_add.ir\n</code></pre>"},{"location":"tools_quick_start/#ir-optimization","title":"IR optimization","text":"<p>To optimize the IR, use the <code>opt_main</code> tool:</p> <pre><code>$ ./bazel-bin/xls/tools/opt_main /tmp/simple_add.ir &gt; /tmp/simple_add.opt.ir\n</code></pre> <p>Check the output of <code>diff -U8 /tmp/simple_add*.ir</code> to see that the optimizer eliminated the useless add-with-zero.</p>"},{"location":"tools_quick_start/#verilog-rtl-generation","title":"Verilog RTL generation","text":"<p>To generate RTL from the optimized IR, use the <code>codegen_main</code> tool:</p> <pre><code>$ ./bazel-bin/xls/tools/codegen_main --pipeline_stages=1 --delay_model=unit /tmp/simple_add.opt.ir &gt; /tmp/simple_add.v\n</code></pre>"},{"location":"tools_quick_start/#ir-visualizer","title":"IR visualizer","text":"<p>To get a graphical view of the IR files, use the IR visualization tool:</p> <pre><code>$ ./bazel-bin/xls/visualization/ir_viz/app --delay_model=unit --preload_ir_path=/tmp/simple_add.ir\n</code></pre> <p>This starts a server on localhost port 5000 by default, so you can access it from your machine as <code>http://localhost:5000</code> in a web browser.</p>"},{"location":"vast/","title":"Verilog Abstract Syntax Tree (VAST)","text":"<p>XLS outputs Verilog (or SystemVerilog) for synthesis and simulation. As a lowest common denominator, Verilog output enables XLS generated designs to integrate into existing design flows. To make generation of Verilog easier, XLS includes an abstract representation of Verilog called VAST (Verilog Abstract Syntax Tree). VAST is a C++ library which represents Verilog in a recursive tree data structure which is simple to construct and manipulate programmatically. Verilog source code is emitted directly from the VAST data structure.</p> <p>VAST is intentionally not a complete representation of the Verilog language. VAST is used to emit Verilog for the purposes of code generation within XLS. Given this limited use case, VAST is much smaller and simpler than a complete representation of the entire Verilog language as might be required for a parser, for example.</p>"},{"location":"vast/#vast-overview","title":"VAST Overview","text":"<p>Each supported Verilog construct is represented with a C++ class. These classes form a type hierarchy with the class <code>VastNode</code> at the root. Objects are gathered in tree-shaped structures to represent Verilog constructs. Ownership of all VAST objects is maintained by a <code>VerilogFile</code> object which represents a single file of Verilog source code. References between objects are stored as plain pointers.</p> <p>For example, consider the following Verilog expression:</p> <pre><code>  foo + 8\n</code></pre> <p>In VAST, this is represented with an object of the <code>BinaryInfix</code> class which is derived from the <code>Expression</code> class representing arbitrary Verilog expressions. A <code>BinaryInfix</code> object has three relevant data members:</p> <p><code>std::string op_;</code> :   The string representation of the operation to perform (e.g., <code>+</code>).</p> <p><code>Expression* lhs_;</code> :   The left-hand-side of the expression. In this example, this points to a     <code>LogicRef</code> object (derived from <code>Expression</code> class) referring to a Verilog     <code>reg</code> or <code>wire</code> variable.</p> <p><code>Expression* rhs_;</code> :   The left-hand-side of the expression. In this example, this points to a     <code>Literal</code> object (derived from <code>Expression</code> class) containing the number 8     with unspecified bit width.</p> <p>The <code>BinaryInfix</code> object representing <code>foo + 8</code> might be used within other expressions or statements by referring to the object by pointer. For example, the representation of the statement <code>assign bar = foo + 8</code> would contain an <code>Expression*</code> pointer referring to the <code>foo + 8</code> object for the right-hand-side of the assignment.</p>"},{"location":"vast/#operator-precedence","title":"Operator Precedence","text":"<p>To avoid ambiguity, operators in Verilog follow precedence rules. For example, multiplication is higher precedence than addition so the expression <code>2 + 4 * 10</code> evaluates to <code>42</code> (i.e., <code>2 + (4 * 10)</code>) not <code>60</code> (i.e., <code>(2 + 4) * 10</code>). In VAST, expressions are built as a trees which is evaluated from the leaves to the root. To ensure that the operations are evaluated in the correct order when emitted as Verilog text, VAST automatically adds parentheses where appropriate. For example, the VAST expression consisting of the product (<code>BinaryInfix</code> with operation <code>*</code>) of <code>10</code> and the sum of <code>2</code> and <code>4</code> (<code>BinaryInfix</code> with operation <code>+</code>) will be emitted as <code>10 * (2 + 4)</code>.</p>"},{"location":"vast/#containers","title":"Containers","text":"<p>VAST has a number of classes which hold a sequence of (pointers to) other VAST objects. At the top-level, this includes the <code>VerilogFile</code> class which can hold a sequence of objects such as include statements and modules. Verilog modules themselves are represented with the <code>Module</code> class containing a sequence of statements, declarations, comments, and other constructs. Other containers include always blocks and functions.</p>"},{"location":"vast/#emitting-verilog-text","title":"Emitting Verilog text","text":"<p>VAST classes include an <code>Emit</code> method which returns the represented Verilog construct as a string. Typically, <code>Emit</code> is called on the top-level <code>VerilogFile</code> object to create the text of the entire Verilog source file. Underneath the hood, this method calls the <code>Emit</code> method on all contained VAST objects and assembles the returned strings into the Verilog source code.</p>"},{"location":"vast/#systemverilog-support","title":"SystemVerilog support","text":"<p>XLS can emit either Verilog or SystemVerilog so VAST supports both languages. SystemVerilog constructs are included alongside Verilog constructs in VAST. Examples of SystemVerilog features supported by VAST include:</p> <ul> <li><code>always_ff</code> procedure for modeling sequential logic (VAST <code>AlwaysFlop</code>     class).</li> </ul> <ul> <li>Array assignment pattern (VAST <code>ArrayAssignmentPattern</code> class). Example:     <code>'{foo, bar, baz}</code></li> </ul> <ul> <li>Array declaration using sizes. Example: <code>reg [7:0] foo[42];</code></li> </ul> <p>Within VAST, there is no distinction between the two languages and it is up to the user of VAST to only use the supported features for the target language (Verilog or SystemVerilog).</p>"},{"location":"xls_noc_butterfly_topology/","title":"k-ary n-fly Butterfly Topology Types","text":""},{"location":"xls_noc_butterfly_topology/#overview","title":"Overview","text":"<p>A k-ary n-fly butterfly topology type is a multistage logarithm network. It is implemented using n stages of identical routers, where k is the number of channels of a router that connect to the previous and/or to the next stage. For example, a 2-ary 3-tree butterfly topology has three stages composed of routers with two channels connect to the routers of the previous and/or the next stage (see Figure Butterfly_Topology_Example).</p> <p>Each endpoint node and channel has an n-digit radix-k identifier, {dn\u22121, dn\u22122, ..., d0}. The first n\u22121 digits {dn\u22121, dn\u22122, ..., d1} of the identifier corresponds to the router that it is connected to. Each router node has an n\u22121-digit radix-k identifier. To distinguish nodes and channels from different stages, the stage number is appended to their identifier separated by a period. For example, for a 2-ary 4-fly butterfly network: 2.10102 is channel 1010 from stage 2. Butterfly_Ref_0</p> <p>The connection between the stages is a permutation of the channel identifier. The connection of a channel from stage i-1 to stage i swaps digits dn\u2212i and d0 of the channel identifier, with i &gt;= 1 and i &lt; n. For example, for a 2-ary 4-fly butterfly network: channel 910 of stage 1 [1.10012] is connected to router 4 [1.10012] of stage 1 and router 6 [2.11002] of stage 2. Butterfly_Ref_0</p> <p></p> <p>Figure Butterfly_Topology_Example. The router nodes of a 2-ary 3-tree butterfly topology.</p> <p>Figure Butterfly_Topology_Example shows the router nodes of a 2-ary 3-tree butterfly topology. The routers are labelled with an S.I format where S is the stage identifier and I is the router identifier. For example, router 0.2 is router 2 from stage 0. Channel 0.6 is connected to router 3 [0.1102] of stage 0 and router 1 of stage 1 [1.0112], Channel 1.3 is connected to router 1 [1.0112] of stage 1 and to router 1 [1.0112] of stage 2.</p>"},{"location":"xls_noc_butterfly_topology/#unidirectional-types","title":"Unidirectional Types","text":"<p>For the unidirectional type of the k-ary n-fly, there are endpoints connected to stage 0 and stage n-1. There are two configurations: 1) the endpoints connected to stage 0 send to the network, and the endpoints connected to stage n-1 receive from the network, and 2) the endpoints connected to stage 0 receive from the network, and the endpoints connected to stage n-1 send to the network. A unidirectional k-ary n-fly butterfly topology has at most kn endpoints connected to stage 0 and at most kn endpoints connected to stage n-1. Typically, the endpoints nodes connected to stage 0 and stage n-1 are the same nodes, resulting in an equal number of nodes connected to stage 0 and stage n-1. Moreover, the endpoints nodes are connected to stage 0 in the same order as stage n-1 (mirrored from the vertical cross section).</p> <p></p> <p>Figure Unidirectional_Butterfly_Topology_Example. A 2-ary 3-fly butterfly with the endpoints connected to stage 0 sending to the network, and the endpoints connected to stage 2 receiving from the network example.</p> <p>Figure Unidirectional_Butterfly_Topology_Example shows a 2-ary 3-fly butterfly with the endpoints connected to stage 0 sending to the network, and the endpoints connected to stage 2 receiving from the network example.</p>"},{"location":"xls_noc_butterfly_topology/#bidirectional-types","title":"Bidirectional Types","text":"<p>In the bidirectional type, there are endpoints connected to stage 0 or stage n-1. A bidirectional k-ary n-fly butterfly topology has at most kn endpoints connected to stage 0 or stage n-1. A bidirectional k-ary n-fly butterfly topology with the endpoints connected to stage n-1 is also referred to as the k-ary n-fly fat tree butterfly topology or k-ary n-tree butterfly fat tree topology Fat_Tree_Ref_0.</p> <p>For context, minimal routing between a pair of nodes on a bidirectional k-ary n-tree can be accomplished by sending the message to one of the nearest common ancestors of both source and destination and from there to the destination. That is, each message experiences two phases, an ascending phase to get to a nearest common ancestor, followed by a descending phase. Fat_Tree_Ref_1</p> <p></p> <p>Figure Bidirectional_Butterfly_Topology_Example. A bidirectional 2-ary 3-fly butterfly with the endpoints connected to stage 0 example.</p> <p>Figure Bidirectional_Butterfly_Topology_Example shows a bidirectional 2-ary 3-fly butterfly with the endpoints connected to stage 0 example.</p>"},{"location":"xls_noc_butterfly_topology/#cheat-sheet","title":"Cheat Sheet","text":"<ul> <li>k-ary n-flies are implemented by using n stages of     identical routers, where k is the number of channels of a router that     connect to the previous and/or to the next stage.</li> <li>For unidirectional k-ary n-fly, there are     endpoints connected to stage 0     and stage n-1. The     communication flows from stage 0 to stage n-1     or from stage n-1 to     stage 0.</li> <li>For bidirectional k-ary n-fly, there are     endpoints connected to stage 0     or stage n-1. The     communication flows from stage 0 to stage n-1     and from stage n-1 to     stage 0.</li> </ul>"},{"location":"xls_noc_butterfly_topology/#variants","title":"Variants","text":"<p>This section describes variants to the k-ary n-fly butterfly topology.</p>"},{"location":"xls_noc_butterfly_topology/#flattened-butterfly","title":"Flattened Butterfly","text":"<p>The flattened butterfly is derived by flattening the routers in each row of a conventional butterfly topology while maintaining the same inter-router connections. Butterfly_Ref_1</p> <p></p> <p>Figure Flattened_Butterfly_Topology_Example. An example of a 2-ary 3-fly butterfly and its corresponding flattened butterfly topology.</p> <p>Figure Flattened_Butterfly_Topology_Example shows an example of a 2-ary 3-fly butterfly and its corresponding flattened butterfly topology. For each row, routers from stage 0, 1 and 2 are flattened into individual routers. For example, router 0.0, 1.0 and 2.0 are flattened into router 0.</p>"},{"location":"xls_noc_butterfly_topology/#endpoint-connections","title":"Endpoint Connections","text":"<p>As mentioned, typically, for the unidirectional butterfly topology, the endpoints nodes are connected to stage 0 in the same order as stage n-1 (mirrored from the vertical cross section). However, different topologies are said to emerge by modifying the order of the endpoint nodes connected to the network. Such a change in connectivity may also change the routing algorithm. Ludovici et al present a Reduced Unidirectional Fat Tree derived from a k-ary n-fly topology. Fat_Tree_Ref_0</p>"},{"location":"xls_noc_butterfly_topology/#references","title":"References","text":"<p>[Butterfly_Ref_0] William James Dally and Brian Patrick Towles. 2004. Principles and Practices of Interconnection Networks. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</p> <p>[Fat_Tree_Ref_0] D. Ludovici et al., \"Assessing fat-tree topologies for regular network-on-chip design under nanoscale technology constraints,\" 2009 Design, Automation &amp; Test in Europe Conference &amp; Exhibition, Nice, 2009, pp. 562-565, doi: 10.1109/DATE.2009.5090727.</p> <p>[Fat_Tree_Ref_1] F. Petrini and M. Vanneschi, \"k-ary n-trees: high performance networks for massively parallel architectures,\" Proceedings 11th International Parallel Processing Symposium, Genva, Switzerland, 1997, pp. 87-93, doi: 10.1109/IPPS.1997.580853.</p> <p>[Butterfly_Ref_1] J. Kim, J. Balfour and W. Dally, \"Flattened Butterfly Topology for On-Chip Networks,\" 40th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2007), Chicago, IL, 2007, pp. 172-182, doi: 10.1109/MICRO.2007.29.</p>"},{"location":"xls_noc_dimension_order_topology/","title":"Dimension-Order Topology Types","text":""},{"location":"xls_noc_dimension_order_topology/#overview","title":"Overview","text":"<p>The dimension-order topology is a topology where the arrangement of the routers are described by their location in a dimensional space. The topology has a hierarchical structure where dimension n is composed of structures from dimension n-1. One or more endpoint nodes are connected to a router.</p>"},{"location":"xls_noc_dimension_order_topology/#k-ary-n-cube","title":"k-ary n-cube","text":"<p>A k-ary n-cube topology consists of kn routers arranged in an n-dimensional cube with k routers along each dimension. Each router is assigned an n-digit radix-k address {an\u22121, ..., a0} and is connected to all routers with addresses that differ by \u00b11(mod k) in exactly one address digit. Each dimension is constructed using k k-ary (n-1)-cubes. The channels between the routers can be unidirectional or bidirectional. In practice, the channels are bidirectional.</p>"},{"location":"xls_noc_dimension_order_topology/#ring-topology","title":"Ring Topology","text":"<p>Figure Ring_4ary_1cube_example. A ring topology with four routers, also known as a 4-ary 1-cube topology.</p> <p>The ring topology is a special instance of the k-ary n-cube, where n is equal to one. Figure Ring_4ary_1cube_example shows a ring topology with four routers, also known as a 4-ary 1-cube topology. The dotted lines show the connectivity between routers 0 and k-1 for a dimension.</p>"},{"location":"xls_noc_dimension_order_topology/#symmetric-torus-topology","title":"Symmetric Torus Topology","text":"<p>Figure Symmetric_Torus_4ary_2cube_example. A symmetric torus topology with four routers along each dimension, also known as a 4-ary 2-cube topology.</p> <p>The symmetric torus topology is a special instance of the k-ary n-cube, where n is equal to two. Figure Symmetric_Torus_4ary_2cube_example shows a symmetric torus topology with four routers along each dimension, also known as a 4-ary 2-cube topology. Router (3,0) has address 3 in a dimension and 0 in the other dimension. The dotted lines show the connectivity between routers 0 and k-1 for a dimension.</p> <p></p> <p>Figure 4ary_2cube_construction_example. The construction of a symmetric torus (4-ary 2-cube) topology using 4-ary 1-cubes.</p> <p>Figure 4ary_2cube_construction_example shows the construction of a symmetric torus (4-ary 2-cube) topology using 4-ary 1-cubes (ring topologies).</p>"},{"location":"xls_noc_dimension_order_topology/#multi-radix-n-cube","title":"multi-radix n-cube","text":"<p>A multi-radix n-cube is a generalized form of a k-ary n-cube topology where the radix (number of router nodes) for each dimension is explicitly stated. Each router is assigned an n-digit where the digit at index i has the radix of dimension i. A 2,3-ary 2-cube describes a grid-like topology with a radix of 2 in one dimension and radix of 3 in the other dimension.</p> <p></p> <p>Figure 2,3-ary_2cube_example. A 2,3-ary 2-cube topology example.</p> <p>Figure 2,3-ary_2cube_example shows a 2,3-ary 2-cube topology example. The dotted lines show the connectivity between router 0 and router radixi - 1 for each dimension.</p>"},{"location":"xls_noc_dimension_order_topology/#k-ary-n-mesh","title":"k-ary n-mesh","text":"<p>A k-ary n-mesh is a k-ary n-cube topology with the connection from address ak\u22121 to address a0 omitted in each dimension.</p>"},{"location":"xls_noc_dimension_order_topology/#line","title":"Line","text":"<p>Figure Line_4ary_1mesh_example. A line topology with four routers, also known as a 4-ary 1-mesh topology.</p> <p>The line topology is a special instance of the k-ary n-mesh, where n is equal to one. Figure Line_4ary_1mesh_example shows a line topology with four routers, also known as a 4-ary 1-mesh topology. Compared to the ring topology in Figure Ring_4ary_1cube_example, the connection from router 0 to router 3 is omitted.</p>"},{"location":"xls_noc_dimension_order_topology/#symmetric-mesh","title":"Symmetric Mesh","text":"<p>Figure Symmetric_Mesh_4ary_2mesh_example. A symmetric mesh topology with four routers along each dimension, also known as a 4-ary 2-mesh topology.</p> <p>The symmetric torus mesh is a special instance of the k-ary n-mesh, where n is equal to two. Figure Symmetric_Mesh_4ary_2mesh_example shows a symmetric mesh topology with four routers along each dimension, also known as a 4-ary 2-mesh topology. Router (1,2) has address 1 in a dimension and 2 in the other dimension. Compared to the torus topology in Figure Symmetric_Torus_4ary_2cube_example, the connections between the pair of routers [(0,0), (0,3)], [(1,0), (1,3)], [(2,0), (2,3)], [(3,0), (3,3)], [(0,0), (3,0)], [(0,1), (3,1)], [(0,2), (3,2)], and [(0,3), (3,3)] are omitted.</p>"},{"location":"xls_noc_dimension_order_topology/#multi-radix-n-mesh","title":"multi-radix n-mesh","text":"<p>Similar to the multi-radix n-cube, a multi-radix n-mesh is a generalized form of a k-ary n-mesh topology where the radix (number of router nodes) for each dimension is explicitly stated. Each router is assigned an n-digit where the digit at index i has the radix of dimension i. A 2,3-ary 2-mesh describes a grid-like topology with a radix of 2 in one dimension and radix of 3 in the other dimension.</p> <p></p> <p>Figure 2,3-ary_2mesh_example. A 2,3-ary 2-mesh topology example.</p> <p>Figure 2,3-ary_2mesh_example shows a 2,3-ary 2-mesh topology example. Compared to the multi-radix n-cube topology in Figure 2,3-ary_2cube_example, the connections from the pair of routers [(0,0), (0,2)], [(1,0), (1,2)], [(0,0), (1,0)], [(0,1), (1,1)] and [(0,2), (1,2)] are omitted.</p>"},{"location":"xls_noc_dimension_order_topology/#cheat-sheet","title":"Cheat Sheet","text":"<ul> <li>A k-ary n-cube topology consists of kn     routers arranged in an n-dimensional cube with k router nodes along each     dimension. Each router is assigned an n-digit radix-k address     {an\u22121, ..., a0} and is connected to all routers with     addresses that differ by \u00b11 (mod k) in exactly one address digit. Each     dimension is constructed using k k-ary (n-1)-cubes where there are k     routers in the first dimension.</li> <li>A multi-radix n-cube is a generalized form of a     k-ary n-cube topology where the radix (number of routers) for each     dimension is explicitly stated. Each router is assigned an n-digit where     the digit at index i has the radix of dimension i.</li> <li>A k-ary n-mesh is a k-ary n-cube topology with the     connection from address ak\u22121 to address a0 omitted in     each dimension.</li> <li>Similar to the multi-radix n-cube, a     multi-radix n-mesh is a generalized form of a k-ary     n-mesh topology where the radix (number of routers) for each dimension is     explicitly stated. Each router is assigned an n-digit where the digit at     index i has the radix of dimension i.</li> <li>Channel direction can be unidirectional or bidirectional.</li> <li>Ring: k-ary 1-cube</li> <li>Symmetric Torus: k-ary 2-cube</li> <li>Line: k-ary 1-mesh</li> <li>Symmetric Mesh: k-ary 2-mesh</li> </ul>"},{"location":"xls_noc_dimension_order_topology/#references","title":"References","text":"<p>William James Dally and Brian Patrick Towles. 2004. Principles and Practices of Interconnection Networks. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</p>"},{"location":"xls_noc_fully_connected_topology/","title":"Fully-connected Topology Types","text":"<p>The fully-connected topology is a topology where each router has a bidirectional channel connecting it to each remaining router of the topology. One or more endpoint nodes are connected to a router.</p> <p></p> <p>Figure Fully_Connected_example. A fully-connected topology with six routers.</p> <p>Figure Fully_Connected_example shows a fully-connected topology with six routers.</p>"},{"location":"xls_noc_fully_connected_topology/#cheat-sheet","title":"Cheat Sheet","text":"<ul> <li>The fully-connected topology is a topology where each     router has a bidirectional connecting it to each remaining router of the     topology.</li> </ul>"},{"location":"xls_noc_glossary/","title":"XLS-NoC Glossary","text":""},{"location":"xls_noc_glossary/#adaptive-routing","title":"Adaptive Routing","text":"<p>An adaptive routing algorithm derives a route using any information about the network\u2019s state.</p>"},{"location":"xls_noc_glossary/#channel","title":"Channel","text":"<p>A channel interconnects a pair of nodes and is the medium that transfers data amongst the pair. A node is either a router input, a router output or an endpoint port. A channel may be unidirectional, transferring the data in a single direction, or bidirectional, transferring the data in both directions.</p>"},{"location":"xls_noc_glossary/#endpoint","title":"Endpoint","text":"<p>A node connected to the network that communicates to other endpoints using the network.</p>"},{"location":"xls_noc_glossary/#endpoint-port","title":"Endpoint Port","text":"<p>An endpoint port is a port that connects to an endpoint. There are two types of endpoint ports: a send port and a receive port. A send port enables an endpoint to send data to the network and a receive port enables an endpoint to receive data from the network. The naming convention for a send port and receive port is from the perspective of the endpoints.</p>"},{"location":"xls_noc_glossary/#deadlock","title":"Deadlock","text":"<p>A deadlock occurs when a set of agents holding resources are waiting on another set of resources such that a cycle of waiting agents is formed, implying that agents are unable to make progress.</p> <p></p> <p>Figure Deadlock_Example. A deadlock example with two agents and two resources.</p> <p>Figure Deadlock_Example shows a deadlock example with two agents and two resources. In the example, agent 0 is waiting for resource B that is assigned to agent 1, and agent 1 is waiting for resource A that is assigned to agent 0. The dependency cycle created with agent 0 and 1 demonstrate that the agents are unable to make progress.</p>"},{"location":"xls_noc_glossary/#flit","title":"Flit","text":"<p>A flow control digit, or flit, is the smallest unit of resource allocation in a router. Variable length packets are divided into one or more fixed length flits to simplify the management and allocation of resources. Flits may be divided further into phits when traversing a router.</p>"},{"location":"xls_noc_glossary/#flow-control","title":"Flow Control","text":"<p>Flow control is the scheduling and allocation of a network\u2019s resources. For example, a virtual channel can have a wormhole flow control.</p>"},{"location":"xls_noc_glossary/#hotspot-hot-spot","title":"Hotspot (Hot-spot)","text":"<p>A hotspot resource is one whose demand is significantly greater than other, similar resources. For example, a particular destination terminal becomes a hotspot in a shared memory multicomputer when many processors are simultaneously reading from the same memory location (for example, a shared lock or data structure). Another example is traffic congestion within an area of the network.</p>"},{"location":"xls_noc_glossary/#livelock","title":"Livelock","text":"<p>Livelock occurs when a packet is not able to make progress in the network and is never delivered to its destination. Unlike deadlock, a livelocked packet continues to move through the network.</p> <p></p> <p>Figure Livelock_Example. A example with livelocked packet P1.</p> <p>Figure Livelock_Example shows a livelock example. In the example, there are two packets, P0 and P1. The destination router for the packets is router R2. R1 uses an adaptive routing algorithm. At timestep 1, P0 and P1 are at router R0. Given the routing algorithm at R0, R0 routes packet P0 to R2 and P1 to R1 (timestep 2). At timestep 3, another instance of P0 is routed to R0 and P1 is routed to R2. At timestep 4, P1 is routed to R0. After the arrival of P1 at R0. The state of R0 is identical to timestep1 where these sequence of events will repeat. In the end, P1 does not arrive to its destination although it makes progress, thus livelocked.</p>"},{"location":"xls_noc_glossary/#network-on-chip-noc","title":"Network-On-Chip (NoC)","text":"<p>At a high level, a Network-On-Chip (NoC) is a network designed for one chip. It is composed of routers, channels and endpoint ports. It transports data between endpoints connected to it. Although the design is intended for a single chip, the logical description can be partitioned across multiple chips.</p>"},{"location":"xls_noc_glossary/#oblivious-routing","title":"Oblivious Routing","text":"<p>An oblivious routing algorithm derives a route without using any information about the network\u2019s state, where, fundamentally, the route is computed using solely the source and the destination.</p>"},{"location":"xls_noc_glossary/#packet","title":"Packet","text":"<p>Packets are the unit of routing within an interconnection network. Messages are broken into one or more variable, but bounded, length packets for processing by the network. All data contained within a packet follow the same route through the network and packets are reassembled into messages at the destination node. A packet is divided further into flits.</p>"},{"location":"xls_noc_glossary/#phit","title":"Phit","text":"<p>A physical digit, or phit, is the smallest unit of data processed (e.g. traversing or accessed) by a router. One or more phits are combined to form a flit.</p>"},{"location":"xls_noc_glossary/#port","title":"Port","text":"<p>A port is a physical gateway to a component (input port) or from a component (output port).</p>"},{"location":"xls_noc_glossary/#router","title":"Router","text":"<p>A router receives packets on its inputs, determines the packets' destination based on the routing algorithm, and forwards the packets to the appropriate output.</p>"},{"location":"xls_noc_glossary/#routing-algorithm","title":"Routing Algorithm","text":"<p>The series of steps for choosing a path for a packet through the network. For a packet, the routing algorithm determines the router's output from its input.</p>"},{"location":"xls_noc_glossary/#topology","title":"Topology","text":"<p>The static arrangement of router nodes, channels, and endpoint ports in a network. The topology affects the routing in the network.</p>"},{"location":"xls_noc_glossary/#virtual-channel","title":"Virtual Channel","text":"<p>A virtual channel (VC) is a logical representation of a channel at a router's input or output. It is composed of flit buffers within the router. In a router that handles virtual channels, a packet or flit is assigned to a virtual channel. Hence, the presence of virtual channels at a router's input or output enables the transfer of multiple packets through a single channel.</p>"},{"location":"xls_noc_glossary/#wormhole-flow-control","title":"Wormhole Flow Control","text":"<p>Wormhole flow control defines the allocation of a resource at the flit granularity. Upon a successful allocation, the transfer of the flit is permitted to commence.</p>"},{"location":"xls_noc_glossary/#references","title":"References","text":"<p>William James Dally and Brian Patrick Towles. 2004. Principles and Practices of Interconnection Networks. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</p>"},{"location":"xls_noc_readme/","title":"XLS-NoC Project","text":"<p>The XLS-NoC subproject is a project that leverages XLS's facilities for optimizing parameterized hardware designs in the realm of NoC generation.</p> <p>A declarative specification drives the NoC generation process for optimization (e.g. of performance/area tradeoffs), traffic simulations and software-level functional verification, and the creation of (System)Verilog RTL artifacts such as routers and network-interfacing adapter components.</p>"},{"location":"xls_noc_star_topology/","title":"Star Topology Types","text":""},{"location":"xls_noc_star_topology/#overview","title":"Overview","text":"<p>The star topology is a topology with a central router node.</p>"},{"location":"xls_noc_star_topology/#hierarchical-star-topology","title":"Hierarchical Star Topology","text":"<p>The hierarchical star topology is a hierarchical topology with a central router node that is only connected to router nodes, and the endpoint nodes are only connected to leaf routers. It is identical to a bidirectional tree topology with the exception that there are no endpoints connected to the root router. The channels are unidirectional or bidirectional. In practice, it is common that all channels of the network be bidirectional.</p> <p></p> <p>Figure Hierarchical_Star_example. A hierarchical star topology example with eight endpoint nodes and five router nodes.</p> <p>Figure Hierarchical_Star_example shows a hierarchical star topology example with eight endpoint nodes and five router nodes. Router 8 is the central router that is only connected to router nodes 9, 10, 11 and 12. The endpoints [0, 1], [2, 3], [4, 5] and [6, 7] are connected to leaf routers 9, 10, 11 and 12 respectively. All the channels of the network are bidirectional.</p>"},{"location":"xls_noc_star_topology/#star-topology","title":"Star Topology","text":"<p>The star topology is a topology with a single router: the central router node. All communication flows through the central router (all traffic traverses through the central router). The channels are bidirectional.</p> <p></p> <p>Figure Star_example. A star topology example with four endpoint nodes and the central router.</p> <p>Figure Star_example shows a star topology example with four endpoint nodes and the central router.</p>"},{"location":"xls_noc_star_topology/#single-router-topology","title":"Single Router Topology","text":"<p>The single router topology is the star topology with the channels being unidirectional. The single router topology has a single router: the central router node. All communication flows through the central router (all traffic traverses through the central router).</p> <p></p> <p>Figure Single_Router_example. A single router topology example with four endpoint nodes and the central router.</p> <p>Figure Single_Router_example shows a single router topology example with four endpoint nodes and the central router. Compared to Figure Star_example, the channels are unidirectional.</p>"},{"location":"xls_noc_star_topology/#cheat-sheet","title":"Cheat Sheet","text":"<ul> <li>The hierarchical star topology is a hierarchical     topology with a central router node that is only connected to router nodes,     and the endpoint nodes are only connected to leaf routers.</li> <li>The star topology is a topology with a single router: the central     router node. All traffic traverses through the central router. The channels     are bidirectional.</li> <li>The single router topology is a topology with a single     router: the central router node. All traffic traverses through the central     router. The channels are unidirectional.</li> </ul>"},{"location":"xls_noc_topologies/","title":"XLS-NoC Topologies","text":"<p>The network topology is the static arrangement of router nodes, channels, and endpoints in a network. The document will describe the logical representation of common topology types and define the communication flow within the topology. At the physical level, the arrangement of the topology influences the floorplan, layout and packaging.</p> <p>The supported set of topologies types are:</p> <ul> <li>Dimension Order</li> <li>Tree</li> <li>k-ary n-fly Butterfly</li> <li>Fully Connected</li> <li>Star</li> </ul>"},{"location":"xls_noc_tree_topology/","title":"Tree Topology Types","text":""},{"location":"xls_noc_tree_topology/#overview","title":"Overview","text":"<p>The tree topology is a hierarchical topology with a root node and children nodes. The radix of a node defines the number of children nodes for the given node. The nodes represent the router nodes and endpoint nodes of a network. A tree topology has endpoints connected to the root router and leaf routers. It is called a tree topology because the router nodes form a tree data structure.</p> <p></p> <p>Figure Tree_Topology_Example. A tree topology example.</p> <p>Figure Tree_Topology_Example shows an example of a tree topology. In the figure, there are nine nodes: three router nodes and six endpoint nodes. Router 1 is a root router, and routers 2 and 5 are leaf routers. Router 1 has a radix of four, and routers 2 and 5 have a radix of two. Routers 2 and 5 are child routers of router 1. Endpoints 3 and 4 are child endpoints of router 1. Endpoints 6 and 7, and endpoints 8 and 9 are child endpoints of router 2 and router 5 respectively.</p>"},{"location":"xls_noc_tree_topology/#unidirectional-types","title":"Unidirectional Types","text":"<p>A unidirectional tree is a tree topology where the communication flow is unidirectional, thus all channels in the tree are unidirectional. There are two unidirectional tree types: aggregation tree and distribution tree.</p>"},{"location":"xls_noc_tree_topology/#aggregation-tree","title":"Aggregation Tree","text":"<p>In the aggregation tree, the communication flow is from the leaf routers of the tree to the root router of the tree. The endpoints connected to the root router receive from the network, and the endpoints connected to the leaf routers send to the network.</p> <p></p> <p>Figure Aggregation_Tree_Topology_Example. The aggregation tree topology representation of the tree in Figure Tree_Topology_Example.</p> <p>Figure Aggregation_Tree_Topology_Example shows the aggregation tree topology representation of the tree in Figure Tree_Topology_Example. Endpoints 6, 7, 8 and 9 send to the network, and endpoints 3 and 4 receive from the network.</p>"},{"location":"xls_noc_tree_topology/#distribution-tree","title":"Distribution Tree","text":"<p>In the distribution tree, the communication flow is from the root router of the tree to the leaf routers of the tree. The endpoints connected to the root router send to the network, and the endpoints connected to the leaf routers receive from the network.</p> <p></p> <p>Figure Distribution_Tree_Topology_Example. The distribution tree topology representation of the tree in Figure Tree_Topology_Example.</p> <p>Figure Distribution_Tree_Topology_Example shows the distribution tree topology representation of the tree in Figure Tree_Topology_Example. Endpoints 3 and 4 send to the network, and endpoints 6, 7, 8 and 9 receive from the network.</p>"},{"location":"xls_noc_tree_topology/#bidirectional-type","title":"Bidirectional Type","text":"<p>A bidirectional tree is a tree topology where the communication flow is bidirectional. The communication flows: from the root router of the tree to the leaf routers of the tree and from the leaf routers of the tree to the root router of the tree. By definition, a bidirectional tree requires: 1) at least one endpoint connected to the root router that sends to the network, 2) at least one endpoint connected to the root router that receives from the network, 3) at least one endpoint connected to the leaf routers that sends to the network, and 4) at least one endpoint connected to the leaf routers that receives from the network. In practice, it is common to have all endpoints connected to the root router and leaf routers send to and receive from the network.</p> <p></p> <p>Figure Bidirectional_Tree_Topology_Example. The bidirectional tree topology representation of the tree in Figure Tree_Topology_Example.</p> <p>Figure Bidirectional_Tree_Topology_Example shows the bidirectional tree topology representation of the tree in Figure Tree_Topology_Example. All endpoints in the tree send to and receive from the network.</p>"},{"location":"xls_noc_tree_topology/#cheat-sheet","title":"Cheat Sheet","text":"<ul> <li>A tree topology has endpoints connected to the root router and leaf     routers.</li> <li>Unidirectional Trees<ul> <li>In the aggregation tree, the communication flow is       from the leaf routers of the tree to the root router of the tree.</li> <li>In the distribution tree, the communication flow       is from the root router of the tree to the leaf routers of the tree.</li> </ul> </li> <li>The communication flow of a bidirectional tree is:     from the root router of the tree to the leaf routers of the tree     and from the leaf routers of     the tree to the root router of the tree.</li> </ul>"},{"location":"xls_style/","title":"XLS Style Guide","text":"<p>The Google style guides recommend enforcing local consistency where stylistic choices are not predefined. This file notes some of the choices we make locally in the XLS project, with the relevant Google style guides (C++, Python) as their bases.</p>"},{"location":"xls_style/#c","title":"C++","text":"<ul> <li>Align the pointer or reference modifier token with the type; e.g. <code>Foo&amp;     foo = ...</code> instead of <code>Foo &amp;foo = ...</code>, and <code>Foo* foo = ...</code> instead of <code>Foo     *foo= ...</code>.</li> </ul> <ul> <li>Use <code>/*parameter_name=*/value</code> style comments if you choose to annotate     arguments in a function invocation. <code>clang-tidy</code> recognizes this form, and     provides a Tricorder notification if <code>parameter_name</code> is mismatched against     the parameter name of the callee.</li> </ul> <ul> <li>Prefer <code>int64_t</code> over <code>int</code> to avoid any possibility of overflow.</li> </ul> <ul> <li>Always use <code>Status</code> or <code>StatusOr</code> for any error that a user could encounter.</li> </ul> <ul> <li>Other than user-facing errors, use <code>Status</code> only in exceptional situations.     For example, <code>Status</code> is good to signal that a required file does not exist     but not for signaling that constant folding did not constant fold an     expression.<p>See how heavyweight is StatusOr for more   details on thinking about the costs involved.</p> </li> </ul> <ul> <li>Internal errors for conditions that should never be false can use <code>CHECK</code>,     but may also use <code>Status</code> or <code>StatusOr</code>.</li> </ul> <ul> <li>Prefer using <code>XLS_ASSIGN_OR_RETURN</code> / <code>XLS_RETURN_IF_ERROR</code> when     appropriate, but when binding a <code>StatusOr</code> wrapped value prefer to name it     <code>thing_or</code> so that it can be referenced without the wrapper as <code>thing</code>; e.g.<pre><code>absl::StatusOr&lt;Thing&gt; thing_or = f();\nif (!thing_or.ok()) {\n  // ... handling of the status via thing_or.status() and returning ...\n}\nconst Thing&amp; thing = thing_or.value();\n</code></pre> </li> </ul> <ul> <li>Prefer <code>CHECK</code> to <code>DCHECK</code>, except that <code>DCHECK</code> can be used to verify     conditions that it would be too expensive to verify in production, but that     are fast enough to include outside of production.</li> </ul> <ul> <li>Follow the C++ style guide for capitalization guidelines; however, in the     somewhat ambiguous case of I/O (short for Input/Output, which we use often),     the slash counts as internal spacing and therefore the capitalization we use     is <code>IO</code>, as in <code>WrapIO</code> or <code>StreamingIOReader</code>.</li> </ul> <ul> <li>Prefer to use the <code>XLS_FRIEND_TEST</code> macro vs friending manually-mangled test     names.<p>At times it can be useful to test unit test a private/protected member of a   class, and the <code>XLS_FRIEND_TEST</code> macro makes this possible. Note that the   test case must live outside an unnamed namespace in the test file for the   \"friending\" to work properly.</p> </li> </ul>"},{"location":"xls_style/#functions","title":"Functions","text":"<ul> <li>Short or easily-explained argument lists (as defined by the developer) can     be explained inline with the rest of the function comment. For more complex     argument lists, the following pattern should be used:<pre><code>// &lt;Function description&gt;\n// Args:\n//   arg1: &lt;arg1 description&gt;\n//   arg2: &lt;arg2 description&gt;\n//   ...\n</code></pre> </li> </ul>"},{"location":"xls_style/#ir-nodes","title":"IR nodes","text":"<ul> <li>Unlike most data, IR elements should be passed as non-const pointers, even     when expected to be const (which would usually indicate passing them as     const references). Experience has shown that IR elements often develop     non-const usages over time. Consider the case of IR analysis passes - those     passes themselves rarely need to mutate their input data, but they build up     data structures whose users often need to mutate their contents. In     addition, treating elements as pointers makes equality comparisons more     straightforward (avoid taking an address of a reference) and helps avoid     accidental copies (assigning a reference to local, etc.). Non-const pointer     usage propagates outwards such that the few cases where a const reference     could actually be appropriate become odd outliers, so our guidance is that     IR elements should uniformly be passed as non-const pointers.</li> </ul>"},{"location":"xls_style/#protocol-buffers","title":"Protocol buffers","text":"<ul> <li>Prefer to use     proto3     specifications in all new protocol buffer files.</li> </ul>"},{"location":"xls_style/#faq","title":"FAQ","text":""},{"location":"xls_style/#how-heavyweight-is-statusor","title":"How heavyweight is <code>StatusOr</code>?","text":"<p>What follows is the general guidance on how absl::StatusOr is used -- it is used extensively throughout the XLS code base as an error-style indicator object wrapper, so it is important to understand the mental model used for its cost.</p> <p>Consider cost wise that: a) creating an ok <code>StatusOr</code> is cheap, b) creating a non-ok <code>StatusOr</code> is expensive (that is, imagine the non-ok <code>Status</code> within a <code>StatusOr</code> is the expensive part).</p> <p>The implication being: if there's an API where \"not found\" is a reasonable outcome, prefer <code>absl::optional&lt;&gt;</code> as a return value to indicate that / go with the grain of cost.</p> <p>Something like a filesystem API would be a classic example -- where you shouldn't be rooting around looking for files that aren't there -- so a not-found <code>absl::StatusOr</code> result would be fine to use.</p> <p>A good potential mental model is to imagine the program may run with logging of a traceback for every non-ok status that is created. (This is related to a debugging capability in Google internally called <code>--util_status_save_stack_trace</code> that captures backtraces when error <code>Status</code>es are created.) Ideally, with such a logging flag turned on, the screen wouldn't fill up with \"non error tracebacks\", only tracebacks from events where something really went wrong.</p>"},{"location":"tutorials/","title":"XLS Tutorials","text":"<p>The XLS team has written several tutorials to help explain language features and design techniques. Here they are, grouped by topic:</p>"},{"location":"tutorials/#dslx","title":"DSLX","text":"<ul> <li>Hello, XLS! : A brief introduction to writing and evaluating     your first design in DSLX.</li> <li>Float-to-int conversion : A guide to writing \"real\" logic     in DSLX, demonstrated by creating an IEEE-754 binary32, i.e., C <code>float</code> to     <code>int32_t</code> converter.</li> <li>Intro to parametrics : A demonstration on how     functions and types can be parameterized to allow a single implementation to     apply to many different data layouts.</li> <li><code>for</code> expressions : Explains how to understand and write looping     constructs in DSLX.</li> <li><code>enumerate</code> and <code>match</code> expressions : Explains how to use     <code>enumerate()</code> expressions to control loop iteration and how to use the     <code>match</code> pattern-matching expression for selecting between alternatives.</li> <li>Intro to procs (communicating sequential processes) :     Provides a basic introduction to writing stateful and communicating modules,     i.e., procs.</li> </ul>"},{"location":"tutorials/crc32/","title":"Tutorial: <code>for</code> expressions","text":"<p>In this document we explain in detail the implementation of routine to compute a CRC32 checksum on a single 8-bit input. We don't discuss the algorithm here, only the language features necessary to implement the algorithm.</p> <p>Refer to the full implementation while following this document.</p>"},{"location":"tutorials/crc32/#function-prototype","title":"Function Prototype","text":"<p>The signature and first line of this function should look familiar enough now, but the <code>for</code> construct is new: DSLX provides a means of iterating a fixed number of times within a function.</p> <p>A DSLX <code>for</code> loop has the following structure:</p> <ol> <li>The loop signature: this consists of three elements:     1.  An (index, ) tuple. The index holds the current         iteration number, and the accumulator vars are user-specified data         carried into the current iteration.     2.  The type specification for the index/accumulators tuple. Note that the         index type can be controlled by the user (i.e., doesn't have to be u32,         but it should be able to hold all possible loop index values).     3.  An         iterable,         either the <code>range()</code> or <code>enumerate()</code> expressions, either of which         dictates the number of iterations of the loop to complete. <li>The loop body: this has the same general form as a DSLX function.     Particularly noteworthy is that the loop body ends by stating the \"return\"     value. In a <code>for</code> loop, this \"return\" value is either used as the input to     the next iteration of the loop (for non-terminal iterations) or as the     result of the entire expression (for the terminal iteration).</li> <p>For this specific for loop, the index variable and accumulator are <code>i</code> and <code>crc</code>, both of type <code>u32</code>. The iterable range expression specifies that the loop should execute 8 times.</p> <pre><code>  // 8 rounds of updates.\nfor (i, crc): (u32, u32) in range(u32:8) {\n</code></pre> <p>At the end of the loop, the calculated value is being assigned to the accumulator <code>crc</code> - the last expression in the loop body is assigned to the accumulator:</p> <pre><code>    let mask: u32 = -(crc &amp; u32:1);\n(crc &gt;&gt; u32:1) ^ (polynomial &amp; mask)\n</code></pre> <p>Finally, the accumulator's initial value is being passed to the <code>for</code> expression as a parameter. This can be confusing, especially when compared to other languages, where the init value typically is provided at or near the top of a loop.</p> <pre><code>}(crc)\n</code></pre> <p>Since the <code>for</code> loop is the last expression in the function, it's also the function's return value, but in other contexts, it could be assigned to a variable and used elsewhere. In general, the result of a <code>for</code> expression can be used in the same manner as any other expression's result.</p>"},{"location":"tutorials/float_to_int/","title":"Tutorial: basic logic","text":"<p>This tutorial demonstrates how to use XLS to create a simple combinational module, in this case one that performs floating-point-to-integer conversion.</p> <p>The first task is to define the full semantics of the module. We wish for the module to accept a IEEE-754 floating-point number and to output the integer representing the same. All fractional elements will be discarded. Overflow, NaN, and infinite values will be clamped to the maximum or minimum representable integer value with the sign of the input number.</p> <ul> <li>Tutorial: basic logic<ul> <li>1. Bootstrapping</li> <li>2. Simple logic</li> <li>3. Conclusion</li> </ul> </li> </ul>"},{"location":"tutorials/float_to_int/#1-bootstrapping","title":"1. Bootstrapping","text":"<p>When creating a module, one first needs to define the signature and skeleton of the entry function. If you recall, a IEEE binary32 (the C <code>float</code> type) has 1 sign bit, 8 [biased] exponent bits, and 23 fractional bits. These values can be packed into a tuple, and so, the signature of our function can be defined as:</p> <pre><code>pub fn float_to_int(\nx: (u1, u8, u23))\n-&gt; s32 {\ns32:0xbeef\n}\n</code></pre> <p>DSLX syntax is intended to follow Rust syntax as much as possible, so this may look familiar if you're a Rustacean. In any case, let's walk through this code, line-by-line:</p> <ol> <li>This line declares a public function (<code>pub fn</code>), named <code>float_to_int</code>. Since     this function is \"public\", it can be referenced from other modules (i.e.,     files) if     imported     therein.</li> <li>Function parameter declarations! This function only takes one parameter,     <code>x</code>, whose type follows its name. In this case, it's a <code>tuple</code>: a grouping     of potentially disparate elements into a single quantity. A tuple is     specified by listing a set of types in parentheses, as here. Our tuple has a     1-bit element for the sign, an 8-bit element for the biased     exponent, and a 23-bit element for the fractional part. In what is the     complete opposite of a coincidence, these fields match those of an IEEE     float32 number. If a function takes more than one argument, they'll be     comma-separated.     -   u1, u8, and u23 are all shortcuts for the type uN[1], uN[8], and uN[23].         The uN[X] construct declares an X-bit wide unsigned type. There is also         sN[X], which declares an X-bit wide signed type.     -   Other type shortcuts exist such as bitsX, bool (alias         for uN[1]), and u[1-64] and s[1-64], being aliases for uN[1] through         uN[64] and sN[1] through sN[64].</li> <li>Function return type. This function returns a signed 32-bit type, matching     the intentions of float-to-int conversion (since floats are signed).</li> <li>Finally, the last line: the final statement in a function is its return     value. Here, we're unconditionally returning a signed 32-bit number with     the value <code>48879</code>. This is only temporary to     make the function syntactically valid - we're still learning the basics!     Gimme a second!</li> </ol> <p>As an aside, it's a good idea to keep a bookmark to the DSLX language reference handy. It has the full details on language features and syntax and even we XLS devs frequently reference it.</p> <p>Anyway...the tuple representation of our input is a bit cumbersome, so let's define our floating-point number as a struct instead:</p> <pre><code>pub struct float32 {\nsign: u1,\nbexp: u8,\nfraction: u23,\n}\n\npub fn float_to_int(x: float32) -&gt; s32 {\ns32:0xbeef\n}\n</code></pre> <p>Finally, let's write a quick test to make sure things work. Add the following code to your file.</p> <pre><code>#[test]\nfn float_to_int_test() {\n// 0xbeef in float32.\nlet test_input = float32 {\nsign: u1:0x0,\nbexp: u8:0x8e,\nfraction: u23:0x3eef00\n};\nassert_eq(s32:0xbeef, float_to_int(test_input))\n}\n</code></pre> <p>Now run the test through the DSLX interpreter:</p> <pre><code>$ ./bazel-bin/xls/dslx/interpreter_main float_to_int.x\n</code></pre> <p>You should see something like the following:</p> <pre><code>[ RUN UNITTEST  ] float_to_int_test\n[            OK ]\n[===============] 1 test(s) ran; 0 failed; 0 skipped.\n</code></pre> <p>If so, then congrats! You've written - and tested - your first DSLX module! Next up: let's make it do something more interesting.</p>"},{"location":"tutorials/float_to_int/#2-simple-logic","title":"2. Simple logic","text":"<p>After getting the trivial module up and running, the next step is to add real logic to the implementation. Recall that a floating-point number's fractional part has an implicit leading <code>1</code>, so a floating-point number is representable as an integer if its exponent is &lt; 30, that is to say, if its value is between [-2^31, 2^31).</p> <p>To get that exponent, we need to unbias it. In its binary representation, a valid floating-point number's exponent is a value from 0 to 254, being an 8-bit value (an exponent of 255 indicates either NaN or an infinity). The range of a floating-point number's exponent is from -128 to 127, though, so we need to subtract 127 from that value to get the actual exponent. Let's write a function to do just that:</p> <pre><code>fn unbias_exponent(exp: u8) -&gt; s9 {\nexp as s9 - s9:127\n}\n</code></pre> <p>Notice that we need to expand the exponent to add on the sign bit before the subtraction!</p> <p>Note: The repeated <code>s9</code> type specifications are a bit redundant. They're needed because we've not yet fully built out DSLX' type inference capabilities, but this is an area targeted for improvement.</p> <p>Now that we can get the proper exponent, we can code up the rest of the simple in-bound cases. To do that, we need to prepend that leading <code>1</code> and shift the fractional part into its proper location in the final integer. Here's what that looks like when we add that to our original function:</p> <pre><code>pub struct float32 {\nsign: u1,\nbexp: u8,\nfraction: u23,\n}\n\nfn unbias_exponent(exp: u8) -&gt; s9 {\nexp as s9 - s9:127\n}\n\npub fn float_to_int(x: float32) -&gt; s32 {\nlet exp = unbias_exponent(x.bexp);\n\n// Add the implicit leading one.\n// Note that we need to add one bit to the fraction to hold it.\nlet fraction = u33:1 &lt;&lt; 23 | (x.fraction as u33);\n\n// Shift the result to the right if the exponent is less than 23.\nlet fraction =\nif (exp as u8) &lt; u8:23 { fraction &gt;&gt; (u8:23 - (exp as u8)) }\nelse { fraction };\n\n// Shift the result to the left if the exponent is greater than 23.\nlet fraction =\nif (exp as u8) &gt; u8:23 { fraction &lt;&lt; ((exp as u8) - u8:23) }\nelse { fraction };\n\nlet result = fraction as s32;\nlet result = if x.sign { -result } else { result };\nresult\n}\n</code></pre> <p>If we run this function with our original test case, it still works! Of course, one should run additional test cases to see what happens with other inputs, particularly because this implementation will fail for some important values.</p> <p>Try adding tests on your own to find these cases - and to fix them! If you're stumped, hints (and answers) are hidden below:</p> Missing case 1 What if the input is 0.0? What should the result be?  To fix this, add a specific check for a zero exponent and fractional part.  Missing case 2 Are NaNs or infinite numbers handled correctly?  To fix, add a special check for NaN or infinities at function end. Consider making `is_inf` and `is_nan` functions!"},{"location":"tutorials/float_to_int/#3-conclusion","title":"3. Conclusion","text":"<p>I hope that these examples help you get a better grasp on DSLX and writing modules in them. While our float-to-int function correctly handles <code>float</code>-to-<code>int32_t</code> conversions, what if we wanted to convert <code>double</code> to <code>int64_t</code>? Or even <code>float</code> to <code>int64_t</code>? Even worse, will we have to write separate floating-point operators for every floating-point type we (or our users) wish to support?</p> <p>Fortunately, the answer is no! The next tutorial covers type parameterization, and demonstrates how we can write a single int-to-float routine that covers all our possible conversions. See you there!</p>"},{"location":"tutorials/hello_xls/","title":"Tutorial: Hello, XLS!","text":"<p>So, you're interested in learning more about XLS and DSLX! Super! This tutorial is aimed at the very basics of getting started with XLS: getting your execution environment set up and running the most trivial of DSLX examples: printing the standard \"Hello, world!\" message to the terminal.</p> <p>Yes, even though XLS is a hardware synthesis language, it still needs basic printing and string support, if only for debugging!</p>"},{"location":"tutorials/hello_xls/#1-installation-and-building","title":"1. Installation and building","text":"<p>First things first: if you haven't yet done so, download the XLS sources from Github:</p> <pre><code>git clone https://github.com/google/xls.git xls\n</code></pre> <p>Next, build the project tree. XLS includes several dependencies that can take a while to build, so the first build may take a while; subsequent builds will be much shorter.</p> <p>NOTE: If you don't have Bazel installed, install it: check the Bazel website for instructions. The other prerequisites are a C++20-compliant compiler toolchain and a Python3 interpreter; check with your distribution for installation instructions for both.</p> <p>Start the XLS build by running:</p> <pre><code>bazel build -c opt xls/...\n</code></pre> <p>Then go get a cup of coffee. LLVM and Z3 are big projects, and will take a while to compile (but only the first time). Binary releases are coming soon: they'll avoid the need for long local compiles.</p>"},{"location":"tutorials/hello_xls/#2-create-your-module","title":"2. Create your module","text":"<p>With your toolchain built, let's get to coding! Open up an editor and create a file called <code>hello_xls.x</code> in your XLS checkout root directory. Populate it with the following:</p> <pre><code>fn hello_xls(hello_string: u8[11]) {\nlet _ = trace!(hello_string);\n()\n}\n</code></pre> <p>Let's go over this, line-by-line:</p> <ol> <li>This first line declares a fn (<code>fn</code>) named \"<code>hello_xls</code>\". This function     accepts an array of eleven characters (u8) called <code>hello_string</code>, and returns     no value (the return type would be specified after the argument list's     closing parenthesis and before the function-opening curly brace, if the     function returned a value).</li> <li>This second line invokes the built-in <code>trace!</code> directive, passing it the     function's input string, and throws away the result (assignment to <code>_</code>).</li> <li>The final line terminates the function, exiting with the empty return value     <code>()</code>, representing an empty tuple.</li> </ol>"},{"location":"tutorials/hello_xls/#3-say-hello-xls","title":"3. Say hello, XLS!","text":"<p>Let's run (and test) our code!</p> <p>First thing, though, we should make sure our module parses and passes type checking. The fastest way to do that is via the DSLX \"repl\", conveniently called <code>repl</code>. You can run it against the above example with the command:</p> <pre><code>$ ./bazel-bin/xls/tools/repl hello_xls.x\n</code></pre> <p>This tool first examines the specified module for language correctness, and will print an <code>INVALID_ARGUMENT</code> error if it fails to parse or typecheck. In that case, fix the errors and type <code>:reload</code> to try again. <code>repl</code> supports other features (IR, Verilog, and LLVM code examination), but those are outside the scope of this tutorial.</p> <p>Once you have a parsing DSLX file, the best way to \"smoke test\" a module is via the DSLX interpreter. First, though, we need a test case for it to execute. Add the following to the end of your <code>hello_xls.x</code> file:</p> <pre><code>#[test]\nfn hello_test() {\nhello_xls(\"Hello, XLS!\")\n}\n</code></pre> <p>Again, going line-by-line:</p> <ol> <li>This directive tells the interpreter that the next function is a test     function, meaning that it shouldn't be passed down the synthesis chain and     that it should be executed by the interpreter.</li> <li>This line declares the [test] function <code>hello_test</code>, which takes no args and     returns no value.</li> <li>The only line in this function invokes the <code>hello_xls</code> function and passes     it a chipper greeting.</li> </ol> <p>With both the function and its corresponding test/driver in place, let's fire it up! Open a terminal and execute the following in the XLS checkout root directory:</p> <pre><code>$ ./bazel-bin/xls/dslx/interpreter_main hello_xls.x\n</code></pre> <p>You should see the following output:</p> <pre><code>[ RUN UNITTEST  ] hello_test\ntrace of hello_string @ hello.x:4:17-4:31: [72, 101, 108, 108, 111, 44, 32, 88, 76, 83, 33]\n[            OK ]\n[===============] 1 test(s) ran; 0 failed; 0 skipped.\n</code></pre> <p>Perfect! While this may not be what you initially expected, examine the output elements carefully: they correspond to the ASCII codes of the characters in \"Hello, XLS!\" When designing and debugging hardware, signals are more often numbers than strings, which is why they're represented as numbers here.</p> <p>Congrats! You've written your first piece of hardware in DSLX! It might be more satisfying, though, if your hardware actually did anything. For that, see the next tutorial, float-to-int conversion.</p>"},{"location":"tutorials/intro_to_parametrics/","title":"Tutorial: parametric types and functions","text":"<p>This tutorial demonstrates how types and functions can be parameterized to enable them to work on data of different formats and layouts, e.g., for a function <code>foo</code> to work on both u16 and u32 data types, and anywhere in between.</p> <p>It's recommended that you're familiar with the concepts in the previous tutorial, \"float-to-int conversion\" before following this tutorial.</p>"},{"location":"tutorials/intro_to_parametrics/#simple-parametrics","title":"Simple parametrics","text":"<p>Consider the simple example of the <code>umax</code> function in the DSLX standard library:</p> <pre><code>pub fn umax&lt;N: u32&gt;(x: uN[N], y: uN[N]) -&gt; uN[N] {\nif x &gt; y { x } else { y }\n}\n</code></pre> <p>Most of this function looks like other DSLX functions you may have seen, except for the new-style parameter, <code>N</code>. The declaration of <code>N</code> inside angle brackets denotes that <code>N</code> is a parametric value whose value is a build-time invariant that will be specified by the caller. In other words, changing regular function parameters pumps different values through the circuit, while changing parametric values changes the circuit itself.</p> <p>Here, <code>N</code> is used to define the widths of the input and output types. It's plain to see, then, that specifying <code>N = 16</code> would calculate the maximum of two 16-bit numbers, whereas <code>N = 273</code> would calculate the maximum of two 273-bit numbers. That being said, the smaller the circuit, the faster, smaller, and lower-power it will be, so <code>N</code> should be as small as possible (but no smaller!).</p> <p>There are two ways invoke a parametric function: the first is to explicitly specify all parametric values, and the second is to rely on the language to infer them:</p> <p>Explicit specification:</p> <pre><code>import std\n\nfn foo(a: u32, b: u16) -&gt; u64 {\nstd::umax&lt;u32:64&gt;(a as u64, b as u64)\n}\n</code></pre> <p>Here, the user has directly told the language what the values of all parametrics are.</p> <p>Parametric inference:</p> <pre><code>import std\n\nfn foo(a: u32, b: u16) -&gt; u64 {\nstd::umax(a as u64, b as u64)\n}\n</code></pre> <p>Here, though, the language is able to determine that <code>N</code> is 64, since that matches the types of the arguments to <code>umax</code>, and since both arg types agree. There may be times where inference isn't possible - for example, when there exist parametrics that aren't referenced in the argument list:</p> <pre><code>fn my_parametric_sum&lt;N: u32&gt;(a: u32, b: u32) -&gt; uN[N] {\nlet a_mod = a as uN[N];\nlet b_mod = a as uN[N];\na_mod + b_mod\n}\n</code></pre> <p>To invoke this function, explicit specification is required.</p>"},{"location":"tutorials/intro_to_parametrics/#derived-parametrics","title":"Derived parametrics","text":"<p>It's common, when using parametric types, to need types similar, but not identical to the parametric type. Consider calculating the unbiased floating-point exponent (from the previous tutorial): while the biased exponent was 8 bits wide, the calculated unbiased exponent was 9 bits wide due to the additional sign bit. In this situation, if <code>EXP_SZ</code> was 8, then it'd be handy to also have a <code>SIGNED_EXP_SZ</code> symbol that was equal to 9. This can be done as follows:</p> <pre><code>fn unbias_exponent&lt;EXP_SZ: u32, SIGNED_EXP_SZ: u32 = EXP_SZ + u32:1&gt;(\nexp: uN[EXP_SZ]) -&gt; sN[SIGNED_EXP_SZ] {\nexp as sN[SIGNED_EXP_SZ] - sN[SIGNED_EXP_SZ]:???\n}\n</code></pre> <p>Oh no! Specifying parametrics in this way has revealed a problem! If we parameterize types, then in some situations, we'll need to also parameterize values!</p> <p>Of course, we'd not be writing this tutorial if that wasn't possible. DSLX supports \"constexpr\"-style evaluation, whereby constant expressions can be evaluated at interpretation or compilation time. In this case, we just need an expression that can calculate the correct bias adjustment: <code>(sN[SIGNED_EXP_SZ]:1 &lt;&lt; (EXP_SZ - u32:1)) - sN[SIGNED_EXP_SZ]:1</code></p> <p>This is a bit unwieldy in practice, so we can wrap it in a function:</p> <pre><code>fn bias_scaler&lt;N: u32, WIDE_N: u32 = N + u32:1&gt;() -&gt; sN[WIDE_N] {\n(sN[WIDE_N]:1 &lt;&lt; (N - u32:1)) - sN[WIDE_N]:1\n}\n\nfn unbias_exponent&lt;EXP_SZ: u32, SIGNED_EXP_SZ: u32 = EXP_SZ + u32:1&gt;(\nexp: uN[EXP_SZ]) -&gt; sN[SIGNED_EXP_SZ] {\nexp as sN[SIGNED_EXP_SZ] - bias_scaler&lt;EXP_SZ&gt;()\n}\n</code></pre>"},{"location":"tutorials/intro_to_parametrics/#parameterized-float-to-int","title":"Parameterized float-to-int","text":"<p>Finally, consider the 32-bit float-to-int program from the previous tutorial. That program was restricted to converting from one specific type to another. If, however, we wanted to convert from, say a <code>double</code> to an <code>int32_t</code>, we'd have to write a new function, even though the basic logic would be the same.</p> <p>Instead, armed with parametrics, we can write a single function to handle all such conversions - even to floating-point formats we haven't considered!</p> <p>The first step in such a parameterization is to have a working single-typed example, which we take from the previous codelab:</p> <pre><code>pub struct float32 {\nsign: u1,\nbexp: u8,\nfraction: u23,\n}\n\nfn unbias_exponent(exp: u8) -&gt; s9 {\nexp as s9 - s9:127\n}\n\npub fn float_to_int(x: float32) -&gt; s32 {\nlet exp = unbias_exponent(x.bexp);\n\n// Add the implicit leading one.\n// Note that we need to add one bit to the fraction to hold it.\nlet fraction = u33:1 &lt;&lt; 23 | (x.fraction as u33);\n\n// Shift the result to the right if the exponent is less than 23.\nlet fraction =\nif (exp as u8) &lt; u8:23 { fraction &gt;&gt; (u8:23 - (exp as u8)) }\nelse { fraction };\n\n// Shift the result to the left if the exponent is greater than 23.\nlet fraction =\nif (exp as u8) &gt; u8:23 { fraction &lt;&lt; ((exp as u8) - u8:23) }\nelse { fraction };\n\nlet result = fraction as s32;\nlet result = if x.sign { -result } else { result };\nresult\n}\n</code></pre> <p>Next is to identify all types needing parameterization, here being the intended size of the result and the layout of the floating-point type itself; all other types flow from that base definition:</p> <ul> <li><code>exp:</code>float32::bexp` size + 1 sign bit</li> <li><code>fraction:</code>float32::fraction` size + 1 implicit leading bit</li> </ul> <p>Thus, the struct declaration and function signature will be:</p> <pre><code>pub struct float&lt;EXP_SZ: u32, FRACTION_SZ: u32&gt; {\nsign: u1,\nbexp: uN[EXP_SZ],\nfraction: uN[FRACTION_SZ],\n}\n\npub fn float_to_int&lt;EXP_SZ: u32, FRACTION_SZ: u32, RESULT_SZ: u32&gt;(\nx: float&lt;EXP_SZ, FRACTION_SZ&gt;) -&gt; sN[RESULT_SZ] {\n...\n}\n</code></pre> <p>From there, the rest of the function can be populated by replacing the types in the original implementation with the parameterized ones in the signature:</p> <pre><code>pub struct float&lt;EXP_SZ: u32, FRACTION_SZ: u32&gt; {\nsign: u1,\nbexp: uN[EXP_SZ],\nfraction: uN[FRACTION_SZ],\n}\n\nfn bias_scaler&lt;N: u32, WIDE_N: u32 = N + u32:1&gt;() -&gt; sN[WIDE_N] {\n(sN[WIDE_N]:1 &lt;&lt; (N - u32:1)) - sN[WIDE_N]:1\n}\n\nfn unbias_exponent&lt;EXP_SZ: u32, SIGNED_EXP_SZ: u32 = EXP_SZ + u32:1&gt;(\nexp: uN[EXP_SZ]) -&gt; sN[SIGNED_EXP_SZ] {\nexp as sN[SIGNED_EXP_SZ] - bias_scaler&lt;EXP_SZ&gt;()\n}\n\npub fn float_to_int&lt;\nEXP_SZ: u32, FRACTION_SZ: u32, RESULT_SZ: u32,\nWIDE_EXP_SZ: u32 = EXP_SZ + u32:1,\nWIDE_FRACTION_SZ: u32 = FRACTION_SZ + u32:1&gt;(\nx: float&lt;EXP_SZ, FRACTION_SZ&gt;) -&gt; sN[RESULT_SZ] {\nlet exp = unbias_exponent(x.bexp);\n\nlet fraction = uN[WIDE_FRACTION_SZ]:1 &lt;&lt; FRACTION_SZ |\n(x.fraction as uN[WIDE_FRACTION_SZ]);\n\nlet fraction =\nif (exp as u32) &lt; FRACTION_SZ { fraction &gt;&gt; (FRACTION_SZ - (exp as u32)) }\nelse { fraction };\n\nlet fraction =\nif (exp as u32) &gt; FRACTION_SZ { fraction &lt;&lt; ((exp as u32) - FRACTION_SZ) }\nelse { fraction };\n\nlet result = fraction as sN[RESULT_SZ];\nlet result = if x.sign { -result } else { result };\nresult\n}\n</code></pre> <p>Note that <code>unbias_exponent()</code> didn't need type specification, since the type could be inferred from the argument! (Also note that this implementation doesn't contain the fixes from the missing cases from the previous tutorial. Exercise to the reader: apply those fixes here, too!)</p> <p>This technique underlies all of XLS' floating-point libraries. Common operations are defined in common files, such as apfloat.x (general utilities) or apfloat_add_2.x (two-way addition) or apfloat_fma.x (fused multiply-add). Specializations of the above are then available in, e.g., float32.x, fp32_add_2.x, and fma_32.x, respectively, to hide internal implementation details from end users.</p> <p>With this technique, you can write single implementations of functionality that can be applicable across all sorts of hardware configurations for minimal additional cost. Try it out! Create an <code>0xbeef</code>-bit wide floating-point adder!</p>"},{"location":"tutorials/intro_to_procs/","title":"DSLX Tutorial: Intro to procs","text":"<p>Up to this point, our tutorials have described stateless, non-communicating, combinational modules. To add state or communication with other actors, we need to venture into the exciting land of procs!</p> <p>Procs, short for \"communicating sequential processes\", are the means by which DSLX models sequential and stateful modules. A proc contains:</p> <ul> <li>A <code>config</code> function that initializes constant proc state and spawns any     other dependent/child procs needed for execution.</li> <li>A recurrent (i.e., infinitely looping) <code>next</code> function that contains the     actual logic to be executed by the proc.</li> </ul> <p>A critical component of procs is communication: every proc needs a means to share data with other procs, or else it'd just be spinning dead code. These means are channels: entities into which data can be sent and from which data can be received. Each channel has a send and a receive endpoint: data inserted into a channel by a <code>send</code> op can be pulled out by a <code>recv</code> op.</p>"},{"location":"tutorials/intro_to_procs/#example-proc","title":"Example proc","text":"<p>Many concepts here are more easily explained via example, so here's a possible DSLX implementation of FMAC (fused multiply-accumulate), which computes <code>C = A * B + C</code>:</p> <pre><code>import xls.modules.fp.fp32_fma\n\nproc Fmac {\ninput_a_consumer: chan&lt;F32&gt; in;\ninput_b_consumer: chan&lt;F32&gt; in;\noutput_producer: chan&lt;F32&gt; out;\n\nconfig(input_a_consumer: chan&lt;F32&gt; in, input_b_consumer: chan&lt;F32&gt; in,\noutput_producer: chan&lt;F32&gt; out) {\n(input_a_consumer, input_b_consumer, output_producer)\n}\n\nnext(tok: token, state: F32) {\nlet (tok_a, input_a) = recv(tok, input_a_consumer);\nlet (tok_b, input_b) = recv(tok, input_b_consumer);\nlet result = fp32_fma::fp32_fma(input_a, input_b, state);\nlet tok = join(tok_a, tok_b);\nlet tok = send(tok, output_producer, result);\n(result,)\n}\n}\n</code></pre> <p>(In practice, a FMAC unit would want a reset signal, but we've leaving that out for simplicity.)</p> <p>There's a lot to unpack here, so we'll walk through the example.</p> <p>The first part of interest is the declaration of the proc member values: the three channels. Procs can have \"member\" state, similar to class data members in software. In DSLX, proc members are constant values, and are set by the output of the <code>config</code> function. Member values can be referred to inside the <code>next</code> function in the same way as locally-declared data.</p> <p>Next up is the <code>config</code> function itself. When a proc is \"spawned\", its given two sets of values: one set for the <code>config</code> function and one set to initialize <code>next</code> (following this example, we'll show how procs are spawned). Inside a <code>config</code> function, any constant values can be computed, any necessary procs can be spawned, and finally member values are set by the return value. Member values are assigned in declaration order: the first element of the return tuple corresponds to the first-declared member, and so on.</p> <p>After that, we encounter <code>next</code>. This function serves as the real \"body\" of the Proc. The <code>next</code> function maintains and evolves the proc's recurrent state and is responsible for communicating with the outside world, as well. In our example, the first two lines are that communication, receiving the input values for the computation. The token elements are used to sequence events: since the receives can happen in parallel, they can share the same token, but since sending the output must happen after that, their result tokens are \"joined\" (think joining two threads of execution in software), and the result is used to sequence the send. Between the communication routines is the actual computation.</p> <p>At the end of the proc, we terminate with the <code>result</code> value. This final value becomes the input state for the next iteration. This is how recurrent state is managed by procs: a state value is provided to the <code>next</code> function, and the result of that function is used as the next iteration's state input. Procs can have several state elements: in that case, there will be several input state args, e.g., <code>next(tok: token, state_a: F32, state_b: F32)</code>, and the output will be a tuple of values, corresponding in order to the input state values. Regardless of that, a <code>next</code> function will always take a token as the first parameter.</p>"},{"location":"tutorials/intro_to_procs/#spawning-procs","title":"Spawning procs","text":"<p>In any real design, procs will form a network1, where one proc will spawn any number of child procs, which themselves might spawn other procs. (The \"root\" proc will be instantiated by some outside component in the outside RTL environment.) Procs may only be spawned in <code>config</code> functions, as they're part of statically configuring the hardware network to construct.</p> <p>As an example, spawning a couple of our procs above would look as follows:</p> <pre><code>proc Spawner {\nfmac_1_a_producer = chan&lt;F32&gt; out;\nfmac_1_b_producer = chan&lt;F32&gt; out;\nfmac_1_output_consumer = chan&lt;F32&gt; in;\nfmac_2_a_producer = chan&lt;F32&gt; out;\nfmac_2_b_producer = chan&lt;F32&gt; out;\nfmac_2_output_consumer = chan&lt;F32&gt; in;\n\nconfig() {\nlet (fmac_1_a_p, fmac_1_a_c) = chan&lt;F32&gt;;\nlet (fmac_1_b_p, fmac_1_b_c) = chan&lt;F32&gt;;\nlet (fmac_1_output_p, fmac_1_output_c) = chan&lt;F32&gt;;\nspawn fmac(fmac_1_a_c, fmac_1_b_c, fmac_1_output_p)(float32::zero(false));\n\nlet (fmac_2_a_p, fmac_2_a_c) = chan&lt;F32&gt;;\nlet (fmac_2_b_p, fmac_2_b_c) = chan&lt;F32&gt;;\nlet (fmac_2_output_p, fmac_2_output_c) = chan&lt;F32&gt;;\nspawn fmac(fmac_2_a_c, fmac_2_b_c, fmac_2_output_p)(float32::zero(false));\n\n(fmac_1_a_p, fmac_1_b_p, fmac_1_output_c,\nfmac_2_a_p, fmac_2_b_p, fmac_2_output_c)\n}\n}\n</code></pre> <p>For each child proc, we first declare the necessary channels (each channel declaration produces a producer and consumer channel, respectively), then we actually spawn it. The first set of arguments is passed to the child's config function and the second is the initial state for the child proc. A spawn produces no value, hence no <code>let</code> on the left-hand side.</p>"},{"location":"tutorials/intro_to_procs/#advanced-features","title":"Advanced features","text":""},{"location":"tutorials/intro_to_procs/#channel-arrays-and-loop-based-spawning","title":"Channel arrays and loop-based spawning","text":"<p>Note: This feature is currently WIP and is not yet available.</p> <p>Many hardware layouts have regular arrays of components, such as systolic arrays, vector units, etc. Individually specifying these quickly grows cumbersome, so users can instead declare channels of arrays and spawn procs inside <code>for</code> loops. This looks as follows:</p> <pre><code>proc Spawner4x4 {\ninput_producers: chan&lt;F32&gt; out[4][4];\noutput_consumers: chan&lt;F32&gt; out[4][4];\n\nconfig() {\nlet (input_producers, input_consumers) = chan[4][4] F32;\nlet (output_producers, output_consumers) = chan[4][4] F32;\n\nfor (i) : (u32) in range(0, 4) {\nfor (j) : (u32) in range(0, 4) {\nspawn Node(input_consumers[i][j],\noutput_producers[i][j])(float32::zero(false))\n}()\n}()\n\n(input_producers, output_consumers)\n}\n}\n</code></pre>"},{"location":"tutorials/intro_to_procs/#parametric-procs","title":"Parametric procs","text":"<p>Just as with other DSLX constructs, Procs can be parameterized. Parametrics must be specified at the proc level, and not at the component function level (i.e., not on <code>config</code> or <code>next</code>). Building off of the previous example, this looks as follows:</p> <pre><code>proc Parametric&lt;N: u32, M: u32&gt; {\ninput_producers: chan&lt;F32&gt; out[N][M];\noutput_consumers: chan&lt;F32&gt; out[N][M];\n\nconfig() {\nlet (input_producers, input_consumers) = chan[N][M] F32;\nlet (output_producers, output_consumers) = chan[N][M] F32;\n\nfor (i) : (u32) in range(0, N) {\nfor (j) : (u32) in range(0, M) {\nspawn Node(input_consumers[i][j],\noutput_producers[i][j])(float32::zero(false))\n}()\n}()\n\n(input_producers, output_consumers)\n}\n}\n</code></pre> <p>These two features are very powerful together: users can specify a broad variety of designs simply by adjusting a few parametric values.</p>"},{"location":"tutorials/intro_to_procs/#proc-testing","title":"Proc testing","text":"<p>The DSLX interpreter supports testing procs via the test_proc construct. A test proc is very similar to a normal proc with the following changes:</p> <ul> <li>A test proc is preceded by the <code>#[test_proc()]</code> directive. This directive,     as one might expect, notifies the interpreter that the following proc is a     test proc. Any initial state needed by the test proc should go inside the     parentheses.</li> <li>A test proc's <code>config</code> function must accept a single argument: a boolean     input channel for terminating interpretation. When the test is complete, the     proc should send the test's status (<code>true</code> on success, <code>false</code> on failure)     on that channel (commonly called the \"terminator\" channel).</li> </ul> <p>A skeletal example:</p> <pre><code>#[test_proc(u32:0)]\nproc Tester {\nterminator: chan&lt;bool&gt; out;\n\nconfig(terminator: chan&lt;bool&gt; out) {\nspawn proc_under_test(...)(...);\n(terminator,)\n}\n\nnext(tok: token, state: u32) {\nnew_state = ...\n(new_state,)\n}\n}\n</code></pre> <p>The FP32 fmac module has a more complete proc test that may be used for reference.</p>"},{"location":"tutorials/intro_to_procs/#scheduling-constraints","title":"Scheduling constraints","text":"<p>If you want to interface with something in the outside world that is latency sensitive (for example, an SRAM -- though we have separate infrastructure for making SRAMs work that builds on top of this feature), you can create external channels representing the interface you want to use, e.g.:</p> <pre><code>proc main {\nreq: chan&lt;u32&gt; out;\nresp: chan&lt;u32&gt; in;\n\ninit { u32: 0 }\n\nconfig(req: chan&lt;u32&gt; out, resp: chan&lt;u32&gt; in) {\n(req, resp)\n}\n\nnext(tok: token, state: u32) {\nlet request = state * state;\nlet tok = send(tok, req, request);\nlet (tok, response) = recv(tok, resp);\nstate + u32:1\n}\n}\n</code></pre> <p>where the fact that <code>req</code> and <code>resp</code> are parameters of <code>config</code>, and <code>main</code> is the top proc during IR conversion, is what makes them \"external\".</p> <p>Then when you codegen this, you can pass in <code>--io_constraints=foo__req:send:foo__resp:recv:2:2</code> where <code>foo__req</code> is the mangled name of the channel, which you can see by examining the generated IR prior to codegen. That constraint means \"a send on any channel named <code>req</code> must occur exactly two cycles before a receive on any channel named <code>resp</code>\"; the <code>2</code> is specified twice because it is possible to give a range of allowed cycle differences.</p> <p>For more details on <code>--io_constraints</code>, check out the docs. For a complete example, see <code>//xls/examples:constraint_sv</code> and associated build targets; the target you'd build to get the mangled channel names is <code>:constraint_ir</code>.</p> <ol> <li> <p>The proc network itself will form a tree, but channels may make point-to-point connections between any two procs.\u00a0\u21a9</p> </li> </ol>"},{"location":"tutorials/prefix_scan/","title":"DSLX Tutorial: <code>enumerate</code> and <code>match</code> expressions","text":"<p>In this document we explain in detail the implementation of a 8 byte prefix scan computation. In order to understand the implementation, it is useful to understand the intended functionality first.</p> <p>For a given input of 8 bytes, the scan iterates from left to right over the input and produces an output of the same size. Each element in the output contains the count of duplicate values seen so far in the input. The counter resets to 0 if a new value is found.</p> <p>For example, for this input:</p> <pre><code>  let input = u32[8]:[0, ...]\n</code></pre> <p>the code should produce this output:</p> <pre><code>  u3[8]:[0, 1, 2, 3, 4, 5, 6, 7])\n</code></pre> <p>At index 0 it has not yet found any value, so it assigns a counter value of <code>0</code>.</p> <p>At index 1 it finds the second occurrence of the value '0' (which is the 1st duplicate) and therefore adds a 1 to the counter from index 0.</p> <p>At index 2 it finds the third occurrence of the value '0' (which is the 2nd duplicate) and therefore adds a 1 to the counter from index 1. And so on.</p> <p>Correspondingly, for this input:</p> <pre><code>  let input = u32[8]:[0, 0, 1, 1, 2, 2, 3, 3]\n</code></pre> <p>it should produce:</p> <pre><code>  assert_eq(result, u3[8]:[0, 1, 0, 1, 0, 1, 0, 1])\n</code></pre> <p>The full listing is in <code>examples/dslx_intro/prefix_scan_equality.x</code>.</p>"},{"location":"tutorials/prefix_scan/#function-prefix_scan_eq","title":"Function <code>prefix_scan_eq</code>","text":"<p>The implementation displays a few interesting language features.</p> <p>The function prototype is straight-forward. Input is an array of 8 values of type <code>u32</code>. Output is an array of size 8 holding 3-bit values (the maximum resulting count can only be 7, which fits in 3 bits).</p> <pre><code>fn prefix_scan_eq(x: u32[8]) -&gt; u3[8] {\n</code></pre> <p>The first let expression produces a tuple of 3 values. It only cares about the last value <code>result</code>, so it stubs out the other two elements via the 'ignore' placeholder <code>_</code>.</p> <pre><code>  let (_, _, result) =\n</code></pre> <p>Why a 3-Tuple? Because he following loop has tuple of three values as the accumulator. The return type of the loop is the type of the accumulator, so above let needs to be of the same type.</p>"},{"location":"tutorials/prefix_scan/#enumerated-loop","title":"Enumerated Loop","text":"<p>Using tuples as the accumulator is a convenient way to model multiple loop-carried values:</p> <pre><code>    for ((i, elem), (prior, count, result)): ((u32, u32), (u32, u3, u3[8]))\nin enumerate(x) {\n</code></pre> <p>The iterable of this loop is <code>enumerate(x)</code>. On each iteration, this construct delivers a tuple consisting of current index and current element. This is represented as the tuple <code>(i, elem)</code> in the <code>for</code> construct.</p> <p>The loop next specifies the accumulator, which is a 3-tuple consisting of the values named <code>prior</code>, <code>count</code>, and <code>result</code>.</p> <p>The types of the iterable and accumulator are specified next. The iterable is a tuple consisting of two <code>u32</code> values. The accumulator is more interesting, it is a tuple consisting of a <code>u32</code> value (<code>prior</code>), a <code>u3</code> value (<code>count</code>), and an array type <code>u3[8]</code>, which is an array holding 8 elements of bit-width 3. This is the type of <code>result</code> in the accumulator.</p> <p>Looping back to the prior <code>let</code> statement, it ignores the <code>prior</code> and <code>count</code> members of the tuple and will only return the <code>result</code> part.</p>"},{"location":"tutorials/prefix_scan/#a-match-expression","title":"A Match Expression","text":"<p>The next expression is an interesting <code>match</code> expression. The let expression binds the tuple <code>(to_place, new_count): (u3, u3)</code> to the result of the following match expression:</p> <pre><code>let (to_place, new_count): (u3, u3) = match (i == u32:0, prior == elem) {\n</code></pre> <p><code>to_place</code> will hold the value that is to be written at a given index. <code>new_count</code> will contain the updated counter value.</p> <p>The <code>match</code> expression evaluates two conditions in parallel:</p> <ul> <li>is <code>i</code> == 0?</li> <li>is the <code>prior</code> element the same as the current <code>elem</code></li> </ul> <p>Two tests mean there are four possible cases, which are all handled in the following four cases:</p> <pre><code>      // i == 0 (no matter whether prior == elem or not):\n//    we set position 0 to 0 and update the new_counter to 1\n(true, true) =&gt; (u3:0, u3:1),\n(true, false) =&gt; (u3:0, u3:1),\n\n// if i != 0 - if the current element is the same as pior,\n//    set to_place to the value of the current count\n//    update new_counter with the increased counter value\n(false, true) =&gt; (count, count + u3:1),\n\n// if i != 0 - if current element is different from prior,\n//     set to_place back to 0\n//     set new_counter back to 1\n(false, false) =&gt; (u3:0, u3:1),\n};\n</code></pre> <p>To update the result, we set index <code>i</code> in the <code>result</code> array to the value <code>to_place</code> via the built-in <code>update</code> function, which produces a new value <code>new_result</code>):</p> <pre><code>    let new_result: u3[8] = update(result, i, to_place);\n</code></pre> <p>Finally the updated accumulator value is constructed, it is the last expression in the loop:</p> <pre><code>    (elem, new_count, new_result)\n</code></pre> <p>Following the loop body, as an argument to the loop, we initialize the accumulator in the following way.</p> <ul> <li>set element <code>prior</code> to -1, in order to not match any other value.</li> <li>set element <code>count</code> to 0.</li> <li>set element <code>result</code> to 8 0's of size <code>u3</code>. (Note that the <code>...</code> syntax     is short for \"fill in the rest of the elements with the last value     specified\".)</li> </ul> <pre><code>}((u32:-1, u3:0, u3[8]:[0, ...]));\n</code></pre> <p>And, finally, the function simply returns <code>result</code>:</p> <pre><code>  result\n}\n</code></pre>"},{"location":"tutorials/prefix_scan/#testing","title":"Testing","text":"<p>To test the two cases we've described above, we add the following two test cases right to this implementation file:</p> <pre><code>#[test]\nfn test_prefix_scan_eq_all_zero() {\nlet input = u32[8]:[0, ...];\nlet result = prefix_scan_eq(input);\nassert_eq(result, u3[8]:[0, 1, 2, 3, 4, 5, 6, 7])\n}\n\n#[test]\nfn test_prefix_scan_eq_doubles() {\nlet input = u32[8]:[0, 0, 1, 1, 2, 2, 3, 3];\nlet result = prefix_scan_eq(input);\nassert_eq(result, u3[8]:[0, 1, 0, 1, 0, 1, 0, 1])\n}\n</code></pre> <p>To run tests against the file present in the repository:</p> <pre><code>xls$ bazel run -c opt //xls/dslx:interpreter_main -- \\\n       $PWD/xls/examples/dslx_intro/prefix_scan_equality.x \\\n--compare=none\n[ RUN UNITTEST  ] prefix_scan_eq_all_zero_test\n[            OK ]\n[ RUN UNITTEST  ] prefix_scan_eq_doubles_test\n[            OK ]\n[===============] 2 test(s) ran; 0 failed; 0 skipped.\n</code></pre> <p>(Note that <code>--compare=none</code> is currently required because <code>enumerate</code> ranges are not currently convertable to IR, otherwise running the DSLX interpreter would do implicit comparison to IR interpreter -- see google/xls#164.)</p>"},{"location":"tutorials/xlscc_channels/","title":"Tutorial: XLS[cc] channels, and fixed-width integers.","text":"<ul> <li>Tutorial: XLS[cc] channels, and fixed-width integers.<ul> <li>Introduction to channels.</li> <li>Introduction to fixed-width integers.</li> <li>Configuring XLS[cc] for channel interfaces.</li> <li>Configuring XLS[cc] for fixed-width integers.</li> <li>Translate into optimized XLS IR.</li> <li>Perform code-generation into a pipelined Verilog block.</li> </ul> </li> </ul> <p>This tutorial is aimed at walking you through the implementation and synthesis into Verilog of a C++ function containing channels and fixed-width integers.</p>"},{"location":"tutorials/xlscc_channels/#introduction-to-channels","title":"Introduction to channels.","text":"<p>XLS implements channels via a FIFO-based (ready/valid/data) interface.</p> <p>In C++, these channels are provided by a built-in template class called <code>__xls_channel</code> supporting two methods: <code>read()</code> and <code>write(val)</code>.</p> <p>To utilize channels include the special xls_builtin header file: <code>#include \"/xls_builtin.h\"</code>.</p> <p>An example of a usage is below, which reads an integer on the input channel, multiplies it by 3, and writes it to the output channel.</p> <pre><code>#include \"/xls_builtin.h\"\n\n#pragma hls_top\nvoid test_channels(__xls_channel&lt;int&gt;&amp; in,\n__xls_channel&lt;int&gt;&amp; out) {\nout.write(3*in.read());\n}\n</code></pre> <p>Note that an <code>ac_datatypes</code> compatibility layer is also provided so that the same C++ code can be used for both simulation and XLS[cc] synthesis with just a change in the include paths: ac_compat.</p>"},{"location":"tutorials/xlscc_channels/#introduction-to-fixed-width-integers","title":"Introduction to fixed-width integers.","text":"<p>XLS also provides a template class for fixed-width integers. These are declared using the template class <code>XlsInt&lt;int Width, bool Signed = true&gt;</code>.</p> <p>To utilize fixed with integer types, include xls_int.h.</p> <p>Create a <code>test_channels.cc</code> with the following contents for the rest of this tutorial.</p> <pre><code>#include \"/xls_builtin.h\"\n#include \"xls_int.h\"\n\n#pragma hls_top\nvoid test_channels(__xls_channel&lt;XlsInt&lt;17, false&gt;&gt;&amp; in,\n__xls_channel&lt;XlsInt&lt;22, false&gt;&gt;&amp; out) {\nout.write(3*in.read());\n}\n</code></pre> <p>NOTE <code>\"/xls_builtin.h\"</code> has a <code>/</code> in order to reduce the chance of collisions with other include files that may exist on the system.</p>"},{"location":"tutorials/xlscc_channels/#configuring-xlscc-for-channel-interfaces","title":"Configuring XLS[cc] for channel interfaces.","text":"<p>To support different of channel interfaces, a protofile is provided to XLS[cc] to configure the direction and interface of the top level function.</p> <p>The below textproto specifies that</p> <ol> <li> <p><code>in</code> is an input channel with FIFO (ready/valid) signaling</p> </li> <li> <p><code>out</code> is an output channel with FIFO (ready/valid) signaling.</p> </li> <li> <p>The IR should be created with a top-level proc named <code>xls_test_proc</code>.</p> </li> </ol> <p>Create a file <code>test_channels.textproto</code> with the following contents.</p> <pre><code>channels {\n  name: \"in\"\n  is_input: true\n  type: FIFO\n}\nchannels {\n  name: \"out\"\n  is_input: false\n  type: FIFO\n}\nname: \"xls_test\"\n</code></pre> <p>Then convert it to a protobin. This protobin will be later provided to <code>xlscc</code> with <code>--block_pb test_channels.pb</code>.</p> <pre><code>./bazel-bin/xls/tools/proto2bin test_channels.textproto --message xlscc.HLSBlock --output test_channels.pb\n</code></pre>"},{"location":"tutorials/xlscc_channels/#configuring-xlscc-for-fixed-width-integers","title":"Configuring XLS[cc] for fixed-width integers.","text":"<p>XLS[cc] fixed-width integers have a dependency on the <code>ac_datatypes</code> library. Clone the repository (https://github.com/hlslibs) into a directory named <code>ac_datatypes</code>.</p> <pre><code>git clone https://github.com/hlslibs/ac_types.git ac_datatypes\n</code></pre> <p>Then create the a <code>clang.args</code> file with the following contents to configure the include paths and pre-define the <code>__SYNTHESIS__</code> name as a macro.</p> <pre><code>-D__SYNTHESIS__\n-I/path/to/your/xls/contrib/xlscc/synth_only\n-I/path/containing/ac_datatypes/..\n</code></pre>"},{"location":"tutorials/xlscc_channels/#translate-into-optimized-xls-ir","title":"Translate into optimized XLS IR.","text":"<p>With the above setup complete, XLS IR can now be generated using a sequence of <code>xlscc</code> and <code>opt_main</code>.</p> <pre><code>$ ./bazel-bin/xls/contrib/xlscc/xlscc test_channels.cc \\\n--clang_args_file clang.args \\\n--block_pb test_channels.pb &gt; test_channels.ir\n$ ./bazel-bin/xls/tools/opt_main test_channels.ir &gt; test_channels.opt.ir\n</code></pre> <p>Note that unlike in the prior tutorial, XLS[cc] is used to generate XLS procs rather than functions. This is to support the additional interface requirements of channels.</p>"},{"location":"tutorials/xlscc_channels/#perform-code-generation-into-a-pipelined-verilog-block","title":"Perform code-generation into a pipelined Verilog block.","text":"<p>With the same IR, you can either generate a combinational block or a clocked pipelined block with the <code>codegen_main</code> tool. In this section, we'll demonstrate how to generate a pipelined block using the above C++ code.</p> <pre><code>$ ./bazel-bin/xls/tools/codegen_main test_channels.opt.ir \\\n--generator=pipeline \\\n--delay_model=\"sky130\" \\\n--output_verilog_path=test_channels.v \\\n--module_name=xls_test \\\n--top=xls_test_proc \\\n--reset=rst \\\n--reset_active_low=false \\\n--reset_asynchronous=false \\\n--reset_data_path=true \\\n--pipeline_stages=5 \\\n--flop_inputs=true \\\n--flop_outputs=true \\\n--flop_inputs_kind=skid \\\n--flop_outputs_kind=skid\n</code></pre> <p>Below is a quick summary of the new options.</p> <ol> <li><code>--delay_model=\"sky130\"</code> - use the sky130 delay model.</li> <li><code>--top=xls_test_proc</code> - the proc that is the top-level is named     <code>xls_test_proc</code>. This should be the name specified in the textproto given to     XLS[cc] with a <code>_proc</code> suffix appended.</li> <li><code>--flop_inputs_kind=skid</code> and <code>--flop_outputs_kind=skid</code> - control what type     of I/O buffering is used. In this case, we configure a skid buffer at both     the input and output.</li> </ol>"},{"location":"tutorials/xlscc_overview/","title":"Tutorial: XLS[cc] Overview","text":"<ul> <li>Tutorial: XLS[cc] Overview<ul> <li>Create your first C++ module.</li> <li>Translate into optimized XLS IR.</li> <li>Perform code-generation into a combinational Verilog block.</li> <li>Create your second C++ module and generate an optimized IR file.</li> <li>Perform code-generation into a pipelined Verilog block.</li> </ul> </li> </ul> <p>This tutorial is aimed at walking you through getting a function written in C++ and then compiling into a working Verilog module.</p> <p>This assumes that you've already been successful in building XLS. See Installing and building if not.</p>"},{"location":"tutorials/xlscc_overview/#create-your-first-c-module","title":"Create your first C++ module.","text":"<p>XLS[cc] takes as input a single translation unit -- one <code>.cc</code> file. Other files may be included in that one file, but only the top-level file should be provided.</p> <p>Create a file called <code>test.cc</code> with the following contents.</p> <pre><code>#pragma hls_top\nint add3(int input) { return input + 3; }\n</code></pre> <p>Note that <code>#pragma hls_top</code> denotes the top-level function for the module. The xls func or proc created will follow that function's interface.</p>"},{"location":"tutorials/xlscc_overview/#translate-into-optimized-xls-ir","title":"Translate into optimized XLS IR.","text":"<p>Now that the C++ function has been created, <code>xlscc</code> can be used to translate the C++ into XLS IR. <code>opt_main</code> is used afterwards to optimize and transform the IR into a form more easily synthesized into verilog.</p> <pre><code>$ ./bazel-bin/xls/contrib/xlscc/xlscc test.cc &gt; test.ir\n$ ./bazel-bin/xls/tools/opt_main test.ir &gt; test.opt.ir\n</code></pre> <p>The resulting <code>test.opt.ir</code> file should look something like the following</p> <pre><code>package my_package\n\nfile_number 1 \"./test.cc\"\n\ntop fn add3(input: bits[32]) -&gt; bits[32] {\n  literal.2: bits[32] = literal(value=3, id=2, pos=[(1,2,23)])\n  ret add.3: bits[32] = add(input, literal.2, id=3, pos=[(1,2,23)])\n}\n</code></pre>"},{"location":"tutorials/xlscc_overview/#perform-code-generation-into-a-combinational-verilog-block","title":"Perform code-generation into a combinational Verilog block.","text":"<p>With the same IR, you can either generate a combinational block or a clocked pipelined block with the <code>codegen_main</code> tool. In this section, we'll demonstrate how to generate a combinational block.</p> <pre><code>$ ./bazel-bin/xls/tools/codegen_main test.opt.ir \\\n--generator=combinational \\\n--delay_model=\"unit\" \\\n--output_verilog_path=test.v \\\n--module_name=xls_test \\\n--top=add3\n</code></pre> <p>Below is a quick summary of each option:</p> <ol> <li><code>--generator=combinational</code> states that <code>codegen_main</code> should generate a     combinational module.</li> <li><code>--delay_model=\"unit\"</code> states to use the unit delay model. Additional delay     models include asap7 and sky130.</li> <li><code>--output_verilog_path=test.v</code> is where the output verilog should be written     to.</li> <li><code>--module_name=xls_test</code> states that the generated verilog module should     have the name of <code>xls_test</code>.</li> <li><code>--top=add3</code> states that the function that should be used for codegen is     the function (<code>fn</code>) named <code>add3</code>.</li> </ol> <p>The resulting <code>test.v</code> should have contents similar to the following</p> <pre><code>module xls_test(\n  input wire [31:0] input,\n  output wire [31:0] out\n);\n  wire [31:0] add_6;\n  assign add_6 = input + 32'h0000_0003;\n  assign out = add_6;\nendmodule\n</code></pre>"},{"location":"tutorials/xlscc_overview/#create-your-second-c-module-and-generate-an-optimized-ir-file","title":"Create your second C++ module and generate an optimized IR file.","text":"<p>XLS[cc] supports two ways of handling looping C++ constructs -- it can unroll the loop, or convert the loop into sequential logic. In this section, we'll demonstrate loop unrolling.</p> <p>Unrolled loops are annotated with <code>#pragma hls_unroll yes</code>. For example, create a file called <code>test_unroll.cc</code> with the following contents.</p> <pre><code>#pragma hls_top\nint test_unroll(int x) {\nint ret = 0;\n#pragma hls_unroll yes\nfor(int i=0;i&lt;32;++i) {\nret += x * i;\n}\nreturn ret;\n}\n</code></pre> <p>Then compile, and optimize the resulting IR</p> <pre><code>$ ./bazel-bin/xls/contrib/xlscc/xlscc test_unroll.cc &gt; test_unroll.ir\n$ ./bazel-bin/xls/tools/opt_main test_unroll.ir &gt; test_unroll.opt.ir\n</code></pre>"},{"location":"tutorials/xlscc_overview/#perform-code-generation-into-a-pipelined-verilog-block","title":"Perform code-generation into a pipelined Verilog block.","text":"<p>The previous section should have left you with an IR file called <code>test_unroll.opt.ir</code> with a function with the signature <code>fn test_unroll(x: bits[32]) -&gt; bits[32]</code>. The function is likely too large to fit into a single clock cycle so we'll create a pipelined module.</p> <pre><code>$ ./bazel-bin/xls/tools/codegen_main test_unroll.opt.ir \\\n--generator=pipeline \\\n--delay_model=\"asap7\" \\\n--output_verilog_path=test_unroll.v \\\n--module_name=xls_test_unroll \\\n--entry=test_unroll \\\n--reset=rst \\\n--reset_active_low=false \\\n--reset_asynchronous=false \\\n--pipeline_stages=5 \\\n--flop_inputs=true \\\n--flop_outputs=true\n</code></pre> <p>Below is a quick summary of each option:</p> <ol> <li><code>--generator=pipeline</code> - <code>codegen_main</code> should generate a pipelined module.</li> <li><code>--delay_model=\"asap7\"</code> - use the asap7 delay model.</li> <li><code>--output_verilog_path=test_unroll.v</code> - where the output verilog should be     written to.</li> <li><code>--module_name=xls_test_unroll</code> - the generated verilog module should have     the name of <code>xls_unroll_test</code>.</li> <li><code>--entry=test_unroll</code> - the function that should be used for codegen is the     function (<code>fn</code>) named <code>test_unroll</code>.</li> <li><code>--reset=rst</code> - there should be a reset signal named <code>rst</code>.</li> <li><code>--reset_active_low=false</code> - a high reset signal means reset the module.</li> <li><code>--reset_asynchronous=false</code> - rst is a synchronous reset signal.</li> <li><code>--pipeline_stages=5</code> - create a 5 stage pipeline.</li> <li><code>--flop_inputs=true</code> and <code>--flop_outputs=true</code> - input and outputs for the     block are registered.</li> </ol>"},{"location":"tutorials/xlscc_state/","title":"Tutorial: XLS[cc] state.","text":"<ul> <li>Tutorial: XLS[cc] state.<ul> <li>C++ Source</li> <li>Generate optimized XLS IR.</li> <li>Perform code-generation into a pipelined Verilog block.</li> <li>Additional XLS[cc] examples.</li> </ul> </li> </ul> <p>This tutorial is aimed at walking you through the implementation and synthesis into Verilog of a C++ function containing state.</p> <p>XLS[cc] may infer that in order to achieve a particular implementation of a C++ function, operations may occur over multiple cycles and require additional proc state to be kept. Common constructs that may require this are static variables, or loops that aren't unrolled. In this tutorial we give an example using static variables.</p>"},{"location":"tutorials/xlscc_state/#c-source","title":"C++ Source","text":"<p>Create a file named <code>test_state.cc</code> with the following contents.</p> <pre><code>#include \"/xls_builtin.h\"\n\n#pragma hls_top\nvoid test_state(__xls_channel&lt;int&gt;&amp; out) {\nstatic int count = 0;\nout.write(count);\n++count;\n}\n</code></pre> <p>As the above function uses channels, a proto detailing the type of interface is required. Create a file named <code>test_state.textproto</code> with the following contents to configure <code>out</code> as an output FIFO (ready/valid) interface.</p> <pre><code>channels {\n  name: \"out\"\n  is_input: false\n  type: FIFO\n}\nname: \"xls_test_state\"\n</code></pre>"},{"location":"tutorials/xlscc_state/#generate-optimized-xls-ir","title":"Generate optimized XLS IR.","text":"<p>Use a combination of <code>proto2bin</code>, <code>xlscc</code> and <code>opt_main</code> to generate optimized XLS IR.</p> <pre><code>$ ./bazel-bin/xls/tools/proto2bin test_state.textproto --message xlscc.HLSBlock --output test_state.pb\n$ ./bazel-bin/xls/contrib/xlscc/xlscc test_state.cc \\\n--block_pb test_state.pb \\\n&gt; test_state.ir\n$ ./bazel-bin/xls/tools/opt_main test_state.ir &gt; test_state.opt.ir\n</code></pre>"},{"location":"tutorials/xlscc_state/#perform-code-generation-into-a-pipelined-verilog-block","title":"Perform code-generation into a pipelined Verilog block.","text":"<p>In this case, we will generate a single-stage pipeline without input and output flops. This will result in a module with a 32-bit increment adder along with 32-bit of state.</p> <pre><code>$ ./bazel-bin/xls/tools/codegen_main test_state.opt.ir \\\n--generator=pipeline \\\n--delay_model=\"sky130\" \\\n--output_verilog_path=xls_counter.v \\\n--module_name=xls_counter \\\n--top=xls_test_state_proc \\\n--reset=rst \\\n--reset_active_low=false \\\n--reset_asynchronous=false \\\n--reset_data_path=true \\\n--pipeline_stages=1  \\\n--flop_inputs=false \\\n--flop_outputs=false\n</code></pre> <p>After running codegen, you should see a file named <code>xls_counter.v</code> with contents similar to the following.</p> <pre><code>module xls_counter(\n  input wire clk,\n  input wire rst,\n  input wire out_rdy,\n  output wire [31:0] out,\n  output wire out_vld\n);\n  reg [31:0] __st__1;\n  wire literal_43;\n  wire literal_40;\n  wire [31:0] add_37;\n  wire pipeline_enable;\n  assign literal_43 = 1'h1;\n  assign literal_40 = 1'h1;\n  assign add_37 = __st__1 + 32'h0000_0001;\n  assign pipeline_enable = literal_43 &amp; literal_40 &amp; out_rdy &amp; (literal_43 &amp; literal_40 &amp; out_rdy);\n  always_ff @ (posedge clk) begin\n    if (rst) begin\n      __st__1 &lt;= 32'h0000_0000;\n    end else begin\n      __st__1 &lt;= pipeline_enable ? add_37 : __st__1;\n    end \n  end \n  assign out = __st__1;\n  assign out_vld = literal_40 &amp; literal_43 &amp; 1'h1;\nendmodule\n</code></pre>"},{"location":"tutorials/xlscc_state/#additional-xlscc-examples","title":"Additional XLS[cc] examples.","text":"<p>The above tutorials only touches upon the capabilities of XLS[cc]. XLS[cc] is based on libclang and supports many C++17 features. Notable unsupported features include pointers, function pointers, and virtual methods.</p> <p>For developers, it is possible to check if a specific feature is supported by checking translator_logic_test.cc for unit tests.</p>"}]}